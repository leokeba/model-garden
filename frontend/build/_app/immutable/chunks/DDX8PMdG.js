const r="/api/v1";class i{baseURL;constructor(e){this.baseURL=e}async request(e,t){const s=await fetch(`${this.baseURL}${e}`,{...t,headers:{"Content-Type":"application/json",...t?.headers}});if(!s.ok){const n=await s.text();throw new Error(`API Error: ${s.statusText} - ${n}`)}return s.json()}async getModels(){return this.request("/models")}async getModel(e){return this.request(`/models/${e}`)}async deleteModel(e){return this.request(`/models/${e}`,{method:"DELETE"})}async generateText(e,t){return this.request(`/models/${e}/generate`,{method:"POST",body:JSON.stringify(t)})}async createTrainingJob(e){return this.request("/training/jobs",{method:"POST",body:JSON.stringify(e)})}async getTrainingJobs(){return this.request("/training/jobs")}async getTrainingJob(e){return this.request(`/training/jobs/${e}`)}async cancelTrainingJob(e){return this.request(`/training/jobs/${e}`,{method:"DELETE"})}async getSystemStatus(){return this.request("/system/status")}async getHealth(){return(await fetch(`${this.baseURL.replace("/api/v1","")}/health`)).json()}async getInferenceStatus(){return this.request("/inference/status")}async loadModel(e){return this.request("/inference/load",{method:"POST",body:JSON.stringify({model_path:e.model_path,tensor_parallel_size:e.tensor_parallel_size||1,gpu_memory_utilization:e.gpu_memory_utilization||.9,max_model_len:e.max_model_len,dtype:e.dtype||"auto",quantization:e.quantization})})}async unloadModel(){return this.request("/inference/unload",{method:"POST"})}async get(e){return this.request(e)}async post(e,t){return this.request(e,{method:"POST",body:JSON.stringify(t)})}async put(e,t){return this.request(e,{method:"PUT",body:JSON.stringify(t)})}async delete(e){return this.request(e,{method:"DELETE"})}}const a=new i(r);export{a};
