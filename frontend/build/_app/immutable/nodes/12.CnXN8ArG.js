import"../chunks/DsnmJJEf.js";import{q as _r,p as cr,a as ca,s as ae,o as ur,E as ua,i as l,d as E,f as m,h as gr,b as d,c as br,$ as fr,t as D,e as t,g as e,l as q,w as yr,n as i,r,m as F,j as pe,k as H}from"../chunks/D_fozEd9.js";import{i as c}from"../chunks/C2ngLJft.js";import{r as _,s as ye,a as gt,b as xr,e as bt,i as ft}from"../chunks/489nzvkF.js";import{b as h,c as ie}from"../chunks/aZwOC-1j.js";import{b as I}from"../chunks/DV7skBy0.js";import{g as hr}from"../chunks/CgLW-aHr.js";import{a as ga}from"../chunks/GrWgsx-T.js";import{B as ba,C as kr}from"../chunks/DWJusdRQ.js";var wr=m('<div class="p-4 bg-red-50 border border-red-200 rounded-lg"><p class="text-red-700"> </p></div>'),Sr=(oe,j)=>j.model_type="text",Lr=m('<div class="w-full h-full rounded-full bg-white scale-50"></div>'),Mr=(oe,j)=>j.model_type="vision",Ar=m('<div class="w-full h-full rounded-full bg-white scale-50"></div>'),Br=m("<option>Loading models...</option>"),Cr=m("<option> </option>"),Rr=m("<option> </option>"),Er=m('<p class="text-xs text-yellow-600 mt-1"> </p>'),Tr=m('<p class="text-xs text-gray-500 mt-1">üé® Vision-language models can analyze images and text together</p>'),jr=m('<p class="text-xs text-blue-700"><strong>Context:</strong> </p>'),Or=m('<div class="space-y-1"><p class="text-xs text-blue-700"><strong>VRAM:</strong> </p> <!></div>'),Nr=m('<p class="text-xs text-blue-700 mt-2"><strong>Best for:</strong> </p>'),zr=m('<div class="mt-3 p-3 bg-blue-50 border border-blue-200 rounded-lg"><div class="flex items-start justify-between"><div class="flex-1"><h4 class="text-sm font-semibold text-blue-900 mb-1"> </h4> <p class="text-xs text-blue-800 mb-2"> </p> <!> <!></div></div></div>'),Fr=m(`Enter a HuggingFace dataset identifier (e.g.,
                  "username/dataset-name")<br/> For specific files, use: "username/repo::train.jsonl"`,1),Pr=m(`<p class="text-sm text-blue-800 mb-2">HuggingFace datasets should use OpenAI messages format with
                    base64 images:</p> <pre class="text-xs bg-blue-100 p-2 rounded overflow-x-auto"><code></code></pre> <p class="text-xs text-blue-700 mt-2"><strong>Example:</strong> <code>Barth371/train_pop_valet_no_wrong_doc</code></p>`,1),qr=m(`<p class="text-sm text-blue-800 mb-2">Your dataset should be in JSONL format with:</p> <pre class="text-xs bg-blue-100 p-2 rounded overflow-x-auto"><code></code></pre> <p class="text-xs text-blue-700 mt-2"><strong>Tip:</strong> Use <code>model-garden create-vision-dataset</code> CLI to generate
                    sample data</p>`,1),Qr=m('<div class="p-4 bg-blue-50 border border-blue-200 rounded-lg"><h4 class="text-sm font-semibold text-blue-900 mb-2">üìã Vision Dataset Format</h4> <!></div>'),Vr=m('<span class="text-xs text-green-600 bg-green-50 px-2 py-1 rounded">‚úì Using registry defaults</span>'),Ur=m(`<div class="mb-4 p-3 bg-yellow-50 border border-yellow-200 rounded-lg"><p class="text-sm text-yellow-800">‚ö†Ô∏è <strong>Vision models require:</strong> Lower batch size (1-2),
                higher gradient accumulation (8+), and lower learning rate (2e-5)</p></div>`),$r=m('<div class="mb-6"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üìä Evaluation Settings</h4> <div class="grid grid-cols-2 gap-4"><div><label for="eval_strategy" class="block text-sm font-medium text-gray-700 mb-1">Evaluation Strategy</label> <select id="eval_strategy" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Every N steps</option><option>Every epoch</option><option>No evaluation</option></select></div> <div><label for="eval_steps" class="block text-sm font-medium text-gray-700 mb-1">Evaluation Steps</label> <input type="number" id="eval_steps" placeholder="Auto (same as save_steps)" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Evaluate every N steps (leave empty for auto)</p></div> <div><label for="metric_for_best_model" class="block text-sm font-medium text-gray-700 mb-1">Best Model Metric</label> <select id="metric_for_best_model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Validation Loss (lower is better)</option><option>Accuracy (higher is better)</option><option>F1 Score (higher is better)</option></select></div> <div><div class="flex items-center mt-6"><input type="checkbox" id="load_best_model_at_end" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="load_best_model_at_end" class="ml-2 block text-sm text-gray-700">Load best model at end</label></div> <p class="text-xs text-gray-500 mt-1">Automatically load checkpoint with best validation metric</p></div></div></div>'),Gr=(oe,j)=>E(j,!l(j)),Jr=m('<div class="mb-6 p-4 bg-gray-50 border border-gray-200 rounded-lg"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">‚öôÔ∏è Optimizer Settings</h4> <div class="grid grid-cols-2 gap-4 mb-6"><div><label for="weight_decay" class="block text-sm font-medium text-gray-700 mb-1">Weight Decay</label> <input type="number" id="weight_decay" step="0.001" min="0" max="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">L2 regularization strength (0.01 typical)</p></div> <div><label for="lr_scheduler_type" class="block text-sm font-medium text-gray-700 mb-1">LR Scheduler</label> <select id="lr_scheduler_type" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Linear (default)</option><option>Cosine (good for vision)</option><option>Constant</option><option>Constant with Warmup</option><option>Polynomial</option></select> <p class="text-xs text-gray-500 mt-1">Learning rate schedule type</p></div> <div><label for="warmup_steps" class="block text-sm font-medium text-gray-700 mb-1">Warmup Steps</label> <input type="number" id="warmup_steps" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Steps to warmup learning rate from 0</p></div> <div><label for="max_grad_norm" class="block text-sm font-medium text-gray-700 mb-1">Max Gradient Norm</label> <input type="number" id="max_grad_norm" step="0.1" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Gradient clipping threshold (1.0 standard)</p></div></div> <h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üéõÔ∏è Adam Optimizer Parameters</h4> <div class="grid grid-cols-3 gap-4 mb-6"><div><label for="adam_beta1" class="block text-sm font-medium text-gray-700 mb-1">Adam Beta1</label> <input type="number" id="adam_beta1" step="0.01" min="0" max="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Exponential decay rate for 1st moment (0.9 default)</p></div> <div><label for="adam_beta2" class="block text-sm font-medium text-gray-700 mb-1">Adam Beta2</label> <input type="number" id="adam_beta2" step="0.001" min="0" max="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Exponential decay rate for 2nd moment (0.999 default)</p></div> <div><label for="adam_epsilon" class="block text-sm font-medium text-gray-700 mb-1">Adam Epsilon</label> <input type="number" id="adam_epsilon" step="1e-9" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Small constant for numerical stability (1e-8 default)</p></div></div> <h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üîÑ Data Loading Settings</h4> <div class="grid grid-cols-2 gap-4"><div><label for="dataloader_num_workers" class="block text-sm font-medium text-gray-700 mb-1">Dataloader Workers</label> <input type="number" id="dataloader_num_workers" min="0" max="16" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Number of worker processes (0 = main process only)</p></div> <div><div class="flex items-center mt-6"><input type="checkbox" id="dataloader_pin_memory" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="dataloader_pin_memory" class="ml-2 block text-sm text-gray-700">Pin memory to GPU</label></div> <p class="text-xs text-gray-500 mt-1">Faster data transfer to GPU (recommended)</p></div></div></div>'),Dr=m('<span class="text-xs text-green-600 bg-green-50 px-2 py-1 rounded">‚úì Using registry defaults</span>'),Hr=(oe,j)=>E(j,!l(j)),Ir=(oe,j)=>{const a=oe.currentTarget.value.trim();a?j.lora_config.target_modules=a.split(",").map(W=>W.trim()).filter(W=>W.length>0):j.lora_config.target_modules=null},Wr=m(`<div class="p-4 bg-gray-50 border border-gray-200 rounded-lg"><div class="grid grid-cols-2 gap-4 mb-4"><div><label for="lora_bias" class="block text-sm font-medium text-gray-700 mb-1">LoRA Bias</label> <select id="lora_bias" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>None (default)</option><option>All bias terms</option><option>LoRA layers only</option></select> <p class="text-xs text-gray-500 mt-1">How to handle bias parameters in LoRA layers</p></div> <div><label for="use_gradient_checkpointing" class="block text-sm font-medium text-gray-700 mb-1">Gradient Checkpointing</label> <select id="use_gradient_checkpointing" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Unsloth (recommended)</option><option>Standard PyTorch</option><option>Disabled</option></select> <p class="text-xs text-gray-500 mt-1">Reduces memory at cost of compute time</p></div></div> <div class="grid grid-cols-2 gap-4 mb-4"><div><div class="flex items-center mt-2"><input type="checkbox" id="use_rslora" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="use_rslora" class="ml-2 block text-sm text-gray-700">Use RSLoRA (Rank-Stabilized LoRA)</label></div> <p class="text-xs text-gray-500 mt-1">Better stability for high ranks (r > 16)</p></div> <div><label for="random_state" class="block text-sm font-medium text-gray-700 mb-1">Random Seed</label> <input type="number" id="random_state" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Seed for reproducible results (42 is popular)</p></div></div> <div class="grid grid-cols-2 gap-4 mb-4"><div><label for="task_type" class="block text-sm font-medium text-gray-700 mb-1">Task Type</label> <select id="task_type" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Causal LM (Text Generation)</option><option>Sequence-to-Sequence</option><option>Token Classification</option><option>Sequence Classification</option><option>Question Answering</option></select> <p class="text-xs text-gray-500 mt-1">Type of task for PEFT optimization</p></div> <div><label for="target_modules_input" class="block text-sm font-medium text-gray-700 mb-1">Target Modules (Advanced)</label> <input type="text" id="target_modules_input" placeholder="q_proj, k_proj, v_proj (leave empty for auto)" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Comma-separated list of layers to apply LoRA (auto-detected
                    if empty)</p></div></div> <div class="p-3 bg-blue-50 border border-blue-200 rounded-lg"><h4 class="text-sm font-semibold text-blue-900 mb-2">üí° LoRA Tips</h4> <ul class="text-xs text-blue-800 space-y-1"><li><strong>Rank (r):</strong> Start with 16, increase to 64+ for
                    complex tasks or large datasets</li> <li><strong>Alpha:</strong> Usually equal to rank. Higher alpha =
                    stronger adaptation</li> <li><strong>Dropout:</strong> Add 0.1-0.3 if overfitting, keep 0
                    for small datasets</li> <li><strong>RSLoRA:</strong> Enable for ranks > 16 to improve training
                    stability</li> <li><strong>Target Modules:</strong> Leave empty for auto-detection.
                    Common: "q_proj,k_proj,v_proj,o_proj" for attention layers</li> <li><strong>Task Type:</strong> Use "CAUSAL_LM" for text generation,
                    "SEQ_2_SEQ_LM" for translation/summarization</li></ul></div></div>`),Kr=m(`<strong>‚úÖ Merged 16-bit (Recommended):</strong> Full model with
                  LoRA weights merged using Unsloth. Creates split files for vLLM
                  compatibility.`,1),Yr=m(`<strong>üì¶ Merged 4-bit:</strong> Full model with LoRA weights
                  merged in 4-bit quantized format. Smaller file size.`,1),Xr=m(`<strong>üîß LoRA Adapters Only (Advanced):</strong> Saves only the
                  adapter weights. Requires the base model to load.`,1),Zr=m(`<strong>Conservative:</strong> Masks JSON structural
                          characters: <code></code> and
                          whitespace. Masks ~31% of tokens. <em>Recommended for most cases.</em>`,1),es=m("<strong>Moderate:</strong> Conservative + masks <code>null</code> keyword. Good when null values are predictable.",1),as=m(`<strong>Aggressive:</strong> Moderate + masks schema field
                          names. Maximum focus on semantic content. Requires specifying
                          schema keys below.`,1),ts=m(`<div><label for="selective_loss_schema_keys" class="block text-sm font-medium text-gray-700 mb-1">Schema Keys to Mask</label> <input type="text" id="selective_loss_schema_keys" placeholder="Marque,Modele,contents,confidence_score" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Comma-separated list of JSON field names to mask (e.g.,
                        "name,address,phone")</p> <div class="mt-2 p-2 bg-yellow-50 border border-yellow-200 rounded"><p class="text-xs text-yellow-800">‚ö†Ô∏è Only mask keys that are predictable and don't carry
                          semantic meaning. The model should still learn what
                          values go with each key.</p></div></div>`),rs=m(`<br/><em>Currently: Masking starts immediately (traditional
                            approach)</em>`,1),ss=m("<br/><em> </em>",1),os=m(`<div class="ml-6 space-y-4 p-4 bg-white border border-gray-200 rounded-lg"><div><label for="selective_loss_level" class="block text-sm font-medium text-gray-700 mb-2">Masking Level</label> <select id="selective_loss_level" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Conservative (Structure Only)</option><option>Moderate (Structure + null)</option><option>Aggressive (Structure + null + Schema Keys)</option></select> <div class="mt-2 p-3 bg-gray-50 rounded-lg"><p class="text-xs text-gray-700"><!></p></div></div> <!> <div><label for="selective_loss_masking_start_step" class="block text-sm font-medium text-gray-700 mb-2"> </label> <input type="range" id="selective_loss_masking_start_step" min="0" max="500" step="10" class="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer accent-primary-500"/> <div class="flex justify-between text-xs text-gray-500 mt-1"><span>0 (Immediate)</span> <span>100</span> <span>200</span> <span>500 steps</span></div> <div class="mt-2 p-3 bg-blue-50 rounded-lg"><p class="text-xs text-blue-700"><strong>üí° Tip:</strong> Setting this to 50-200 lets the
                        model learn JSON structure first before applying
                        selective masking. This can prevent degeneration issues
                        with aggressive masking. <!></p></div></div> <div><div class="flex items-center"><input type="checkbox" id="selective_loss_verbose" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="selective_loss_verbose" class="ml-2 block text-sm text-gray-700">Verbose mode (print masking statistics)</label></div> <p class="text-xs text-gray-500 mt-1">Display detailed token masking stats during training</p></div> <div class="p-3 bg-blue-50 border border-blue-200 rounded-lg"><h4 class="text-sm font-semibold text-blue-900 mb-2">üìä What Gets Masked?</h4> <ul class="text-xs text-blue-800 space-y-1"><li>‚úì Structural: <code></code> and whitespace
                        (spaces, newlines, tabs)</li> <li>‚úì Quotes: <code>"</code> (string delimiters - purely structural)</li> <li>‚úì Null keyword: <code>null</code> (moderate/aggressive only)</li> <li>‚úó NOT masked: <code>true</code>, <code>false</code> (can
                        be semantic)</li> <li>‚úì Schema keys: Field names like <code>name</code> (aggressive
                        only)</li></ul> <p class="text-xs text-blue-700 mt-2"><strong>Example:</strong> In <code></code>, conservative
                      mode masks <code></code> and spaces (~31% of tokens),
                      trains on <code>name John age 30</code></p></div></div>`),is=m(`<div><h3 class="text-lg font-semibold text-gray-900 mb-4">üéØ Selective Loss (Structured Outputs)</h3> <div class="p-4 bg-gradient-to-r from-purple-50 to-blue-50 border border-purple-200 rounded-lg mb-4"><p class="text-sm text-gray-800 mb-2"><strong>üî¨ Experimental Feature:</strong> Optimize training for structured
                outputs (JSON, forms, etc.)</p> <p class="text-xs text-gray-700">Masks structural tokens (braces, colons, whitespace) so the
                model focuses on semantic content. Useful for form extraction,
                structured data generation, and similar tasks.</p></div> <div class="space-y-4"><div><div class="flex items-center"><input type="checkbox" id="selective_loss" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="selective_loss" class="ml-2 block text-sm font-medium text-gray-700">Enable Selective Loss Masking</label></div> <p class="text-xs text-gray-500 mt-1 ml-6">Automatically mask JSON structural tokens during training</p></div> <!></div></div>`),ls=m(`<form class="space-y-6"><!> <div><h3 class="text-lg font-semibold text-gray-900 mb-4">Basic Configuration</h3> <div class="grid grid-cols-1 gap-4"><div><div class="block text-sm font-medium text-gray-700 mb-2">Model Type *</div> <div class="grid grid-cols-2 gap-3"><button type="button"><div class="flex items-center gap-2"><div><!></div> <span class="font-medium">Text-Only (LLM)</span></div> <p class="text-sm text-gray-600 mt-2 ml-6">Fine-tune language models for text generation tasks</p></button> <button type="button"><div class="flex items-center gap-2"><div><!></div> <span class="font-medium">Vision-Language (VLM)</span></div> <p class="text-sm text-gray-600 mt-2 ml-6">Fine-tune multimodal models for image + text tasks</p></button></div></div> <div><label for="name" class="block text-sm font-medium text-gray-700 mb-1">Model Name *</label> <input type="text" id="name" placeholder="my-finance-model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500" required/></div> <div><label for="base_model" class="block text-sm font-medium text-gray-700 mb-1">Base Model *</label> <select id="base_model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500" required><!></select> <!> <!> <!></div> <div><label for="dataset_path" class="block text-sm font-medium text-gray-700 mb-1">Dataset Path *</label> <input type="text" id="dataset_path" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500" required/> <div class="mt-2 flex items-center"><input type="checkbox" id="from_hub" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="from_hub" class="ml-2 block text-sm text-gray-700">Load from HuggingFace Hub</label></div> <p class="text-xs text-gray-500 mt-1"><!></p></div> <div><label for="validation_dataset_path" class="block text-sm font-medium text-gray-700 mb-1">Validation Dataset Path (Optional)</label> <input type="text" id="validation_dataset_path" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <div class="mt-2 flex items-center"><input type="checkbox" id="validation_from_hub" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="validation_from_hub" class="ml-2 block text-sm text-gray-700">Load validation dataset from HuggingFace Hub</label></div> <p class="text-xs text-gray-500 mt-1">üìä Optional: Provide a validation dataset to track validation
                loss during training<br/> <!></p></div> <!> <div><label for="output_dir" class="block text-sm font-medium text-gray-700 mb-1">Output Directory</label> <input type="text" id="output_dir" placeholder="./models/my-model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/></div></div></div> <div><div class="flex items-center justify-between mb-4"><h3 class="text-lg font-semibold text-gray-900">Training Hyperparameters</h3> <!></div> <!> <div class="mb-6"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üéØ Essential Parameters</h4> <div class="grid grid-cols-2 gap-4"><div><label for="learning_rate" class="block text-sm font-medium text-gray-700 mb-1">Learning Rate</label> <input type="number" id="learning_rate" step="0.00001" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1"><!></p></div> <div><label for="num_epochs" class="block text-sm font-medium text-gray-700 mb-1">Number of Epochs</label> <input type="number" id="num_epochs" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Number of complete passes through dataset</p></div> <div><label for="batch_size" class="block text-sm font-medium text-gray-700 mb-1">Batch Size per GPU</label> <input type="number" id="batch_size" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1"><!></p></div> <div><label for="gradient_accumulation" class="block text-sm font-medium text-gray-700 mb-1">Gradient Accumulation Steps</label> <input type="number" id="gradient_accumulation" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Effective batch size = batch_size √ó
                  gradient_accumulation_steps</p></div> <div><label for="max_steps" class="block text-sm font-medium text-gray-700 mb-1">Max Steps (Optional)</label> <input type="number" id="max_steps" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Override epochs with exact step count (-1 for full epochs)</p></div> <div><label for="optim" class="block text-sm font-medium text-gray-700 mb-1">Optimizer</label> <select id="optim" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>AdamW 8-bit (Recommended - Memory Efficient)</option><option>AdamW (PyTorch)</option><option>AdamW Fused (Faster)</option><option>Adafactor (Very Memory Efficient)</option><option>SGD</option></select> <p class="text-xs text-gray-500 mt-1">8-bit AdamW reduces memory usage significantly</p></div></div></div> <div class="mb-6"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üíæ Checkpoints & Logging</h4> <div class="grid grid-cols-3 gap-4"><div><label for="logging_steps" class="block text-sm font-medium text-gray-700 mb-1">Logging Steps</label> <input type="number" id="logging_steps" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Log metrics every N steps</p></div> <div><label for="save_steps" class="block text-sm font-medium text-gray-700 mb-1">Save Steps</label> <input type="number" id="save_steps" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Save checkpoint every N steps</p></div> <div><label for="save_total_limit" class="block text-sm font-medium text-gray-700 mb-1">Max Checkpoints</label> <input type="number" id="save_total_limit" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Keep only N most recent checkpoints</p></div></div></div> <!> <div class="mb-4"><button type="button" class="flex items-center gap-2 px-4 py-2 text-sm font-medium text-primary-700 bg-primary-50 border border-primary-200 rounded-lg hover:bg-primary-100 transition-colors"><span> </span> Advanced Hyperparameters</button></div> <!></div> <div><div class="flex items-center justify-between mb-4"><h3 class="text-lg font-semibold text-gray-900">LoRA Configuration</h3> <!></div> <div class="grid grid-cols-3 gap-4 mb-4"><div><label for="lora_r" class="block text-sm font-medium text-gray-700 mb-1">LoRA Rank (r)</label> <input type="number" id="lora_r" min="1" max="256" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Higher = more parameters (16 typical, 64+ for complex tasks)</p></div> <div><label for="lora_alpha" class="block text-sm font-medium text-gray-700 mb-1">LoRA Alpha</label> <input type="number" id="lora_alpha" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Scaling factor (typically equal to rank)</p></div> <div><label for="lora_dropout" class="block text-sm font-medium text-gray-700 mb-1">LoRA Dropout</label> <input type="number" id="lora_dropout" min="0" max="0.5" step="0.05" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Regularization (0.0-0.3, 0 = no dropout)</p></div></div> <div class="mb-4"><button type="button" class="flex items-center gap-2 px-4 py-2 text-sm font-medium text-primary-700 bg-primary-50 border border-primary-200 rounded-lg hover:bg-primary-100 transition-colors"><span> </span> Advanced LoRA Settings</button></div> <!></div> <div><h3 class="text-lg font-semibold text-gray-900 mb-4">Model Save Options</h3> <div><label for="save_method" class="block text-sm font-medium text-gray-700 mb-2">Save Method</label> <select id="save_method" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Save Merged Model (16-bit) - Recommended</option><option>Save Merged Model (4-bit) - Smaller Size</option><option>Save LoRA Adapters Only - Advanced</option></select> <div class="mt-3 p-3 bg-blue-50 border border-blue-200 rounded-lg"><p class="text-sm text-blue-800"><!></p></div></div></div> <!> <div class="flex gap-4 pt-4"><!> <!></div></form>`),ds=m('<div class="min-h-screen bg-gray-50"><div class="bg-white shadow"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex justify-between items-center py-6"><div class="flex items-center"><!> <h1 class="text-3xl font-bold text-gray-900 ml-4">New Training Job</h1></div></div></div></div> <div class="max-w-3xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><!></div></div>');function fs(oe,j){cr(j,!0);let a=ca({name:"",model_type:"text",base_model:"unsloth/tinyllama-bnb-4bit",dataset_path:"./data/sample.jsonl",validation_dataset_path:"",output_dir:"",hyperparameters:{learning_rate:2e-4,num_epochs:3,batch_size:2,max_steps:-1,gradient_accumulation_steps:4,warmup_steps:10,logging_steps:10,save_steps:100,eval_steps:null,optim:"adamw_8bit",weight_decay:.01,lr_scheduler_type:"linear",max_grad_norm:1,adam_beta1:.9,adam_beta2:.999,adam_epsilon:1e-8,dataloader_num_workers:0,dataloader_pin_memory:!0,eval_strategy:"steps",load_best_model_at_end:!0,metric_for_best_model:"eval_loss",save_total_limit:3},lora_config:{r:16,lora_alpha:16,lora_dropout:0,lora_bias:"none",use_rslora:!1,use_gradient_checkpointing:"unsloth",random_state:42,target_modules:null,task_type:"CAUSAL_LM",loftq_config:null},from_hub:!1,validation_from_hub:!1,save_method:"merged_16bit",selective_loss:!1,selective_loss_level:"conservative",selective_loss_schema_keys:"",selective_loss_masking_start_step:0,selective_loss_verbose:!1}),W=ae(!1),le=ae(""),K=ae(ca([])),Y=ae(ca([])),B=ae(null),me=ae(!0),xe=ae("");ur(async()=>{try{E(me,!0);const[O,C]=await Promise.all([ga.getRegistryModels("text-llm"),ga.getRegistryModels("vision-vlm")]);E(K,O.models,!0),E(Y,C.models,!0),a.model_type==="text"&&l(K).length>0?(E(B,l(K)[0],!0),a.base_model=l(K)[0].id):a.model_type==="vision"&&l(Y).length>0&&(E(B,l(Y)[0],!0),a.base_model=l(Y)[0].id)}catch(O){E(xe,O instanceof Error?O.message:"Failed to load models from registry",!0),console.error("Failed to load registry models:",O),E(K,[{id:"unsloth/tinyllama-bnb-4bit",name:"TinyLlama 1.1B (4-bit)",parameters:"1.1B"},{id:"unsloth/phi-2-bnb-4bit",name:"Phi-2 2.7B (4-bit)",parameters:"2.7B"},{id:"unsloth/mistral-7b-bnb-4bit",name:"Mistral 7B (4-bit)",parameters:"7B"},{id:"unsloth/llama-2-7b-bnb-4bit",name:"Llama 2 7B (4-bit)",parameters:"7B"},{id:"unsloth/llama-3-8b-bnb-4bit",name:"Llama 3 8B (4-bit)",parameters:"8B"}],!0),E(Y,[{id:"Qwen/Qwen2.5-VL-3B-Instruct",name:"Qwen2.5-VL 3B",parameters:"3B"},{id:"Qwen/Qwen2.5-VL-7B-Instruct",name:"Qwen2.5-VL 7B",parameters:"7B"},{id:"Qwen/Qwen2.5-VL-72B-Instruct",name:"Qwen2.5-VL 72B",parameters:"72B"},{id:"unsloth/Qwen2.5-VL-3B-Instruct-bnb-4bit",name:"Qwen2.5-VL 3B (4-bit)",parameters:"3B"},{id:"unsloth/Qwen2.5-VL-7B-Instruct-bnb-4bit",name:"Qwen2.5-VL 7B (4-bit)",parameters:"7B"}],!0)}finally{E(me,!1)}}),ua(()=>{const O=a.model_type==="vision"?l(Y):l(K);if(E(B,O.find(C=>C.id===a.base_model)||null,!0),l(B)?.training_defaults){const C=l(B).training_defaults;C.hyperparameters&&(a.hyperparameters={...a.hyperparameters,...C.hyperparameters}),C.lora_config&&(a.lora_config={...a.lora_config,...C.lora_config}),C.save_method&&(a.save_method=C.save_method)}}),ua(()=>{a.model_type==="vision"?(l(Y).length>0&&(a.base_model=l(Y)[0].id),a.dataset_path="./data/vision_dataset.jsonl"):(l(K).length>0&&(a.base_model=l(K)[0].id),a.dataset_path="./data/sample.jsonl")});let he=ae(!1),ke=ae(!1);ua(()=>{a.name&&(a.output_dir=`./models/${a.name.toLowerCase().replace(/[^a-z0-9]/g,"-")}`)});async function yt(O){if(O.preventDefault(),!a.name||!a.base_model||!a.dataset_path){E(le,"Please fill in all required fields");return}E(W,!0),E(le,"");try{let C=null;a.selective_loss_schema_keys&&a.selective_loss_schema_keys.trim()&&(C=a.selective_loss_schema_keys.split(",").map(de=>de.trim()).filter(de=>de.length>0));const X=await ga.createTrainingJob({...a,is_vision:a.model_type==="vision",selective_loss:a.selective_loss,selective_loss_level:a.selective_loss_level,selective_loss_schema_keys:C,selective_loss_masking_start_step:a.selective_loss_masking_start_step,selective_loss_verbose:a.selective_loss_verbose});X.success?hr(`/training/${X.data.job_id}`):E(le,"Failed to create training job")}catch(C){E(le,C instanceof Error?C.message:"Failed to create training job",!0)}finally{E(W,!1)}}var we=ds();gr(O=>{fr.title="New Training Job - Model Garden"});var Se=t(we),fa=t(Se),ya=t(fa),xa=t(ya),xt=t(xa);ba(xt,{href:"/training",variant:"ghost",size:"sm",children:(O,C)=>{i();var X=D("‚Üê Training Jobs");d(O,X)},$$slots:{default:!0}}),i(2),r(xa),r(ya),r(fa),r(Se);var ha=e(Se,2),ht=t(ha);kr(ht,{children:(O,C)=>{var X=ls(),de=t(X);{var kt=s=>{var o=wr(),v=t(o),b=t(v,!0);r(v),r(o),q(()=>F(b,l(le))),d(s,o)};c(de,s=>{l(le)&&s(kt)})}var Le=e(de,2),ka=e(t(Le),2),Me=t(ka),wa=e(t(Me),2),ve=t(wa);ve.__click=[Sr,a];var Sa=t(ve),Ae=t(Sa),wt=t(Ae);{var St=s=>{var o=Lr();d(s,o)};c(wt,s=>{a.model_type==="text"&&s(St)})}r(Ae),i(2),r(Sa),i(2),r(ve);var ue=e(ve,2);ue.__click=[Mr,a];var La=t(ue),Be=t(La),Lt=t(Be);{var Mt=s=>{var o=Ar();d(s,o)};c(Lt,s=>{a.model_type==="vision"&&s(Mt)})}r(Be),i(2),r(La),i(2),r(ue),r(wa),r(Me);var Ce=e(Me,2),Ma=e(t(Ce),2);_(Ma),r(Ce);var Re=e(Ce,2),_e=e(t(Re),2),At=t(_e);{var Bt=s=>{var o=Br();o.value=o.__value="",d(s,o)},Ct=s=>{var o=pe(),v=H(o);{var b=n=>{var p=pe(),w=H(p);bt(w,17,()=>l(K),ft,(y,x)=>{var g=Cr(),M=t(g);r(g);var f={};q(()=>{F(M,`${l(x).name??""} (${l(x).parameters??""})`),f!==(f=l(x).id)&&(g.value=(g.__value=l(x).id)??"")}),d(y,g)}),d(n,p)},k=n=>{var p=pe(),w=H(p);bt(w,17,()=>l(Y),ft,(y,x)=>{var g=Rr(),M=t(g);r(g);var f={};q(()=>{F(M,`${l(x).name??""} (${l(x).parameters??""})`),f!==(f=l(x).id)&&(g.value=(g.__value=l(x).id)??"")}),d(y,g)}),d(n,p)};c(v,n=>{a.model_type==="text"?n(b):n(k,!1)},!0)}d(s,o)};c(At,s=>{l(me)?s(Bt):s(Ct,!1)})}r(_e);var Aa=e(_e,2);{var Rt=s=>{var o=Er(),v=t(o);r(o),q(()=>F(v,`‚ö†Ô∏è Using fallback models: ${l(xe)??""}`)),d(s,o)};c(Aa,s=>{l(xe)&&s(Rt)})}var Ba=e(Aa,2);{var Et=s=>{var o=Tr();d(s,o)};c(Ba,s=>{a.model_type==="vision"&&s(Et)})}var Tt=e(Ba,2);{var jt=s=>{var o=zr(),v=t(o),b=t(v),k=t(b),n=t(k);r(k);var p=e(k,2),w=t(p,!0);r(p);var y=e(p,2);{var x=f=>{var L=Or(),R=t(L),T=e(t(R));r(R);var N=e(R,2);{var P=A=>{var Q=jr(),V=e(t(Q));r(Q),q(U=>F(V,` ${U??""}
                              tokens`),[()=>l(B).capabilities.context_window.toLocaleString()]),d(A,Q)};c(N,A=>{l(B).capabilities?.context_window&&A(P)})}r(L),q(()=>F(T,` ${l(B).requirements.min_vram_gb??""}GB
                            minimum,
                            ${l(B).requirements.recommended_vram_gb??""}GB recommended`)),d(f,L)};c(y,f=>{l(B).requirements&&f(x)})}var g=e(y,2);{var M=f=>{var L=Nr(),R=e(t(L));r(L),q(T=>F(R,` ${T??""}`),[()=>l(B).recommended_for.join(", ")]),d(f,L)};c(g,f=>{l(B).recommended_for&&l(B).recommended_for.length>0&&f(M)})}r(b),r(v),r(o),q(()=>{F(n,`üìä ${l(B).name??""}`),F(w,l(B).description)}),d(s,o)};c(Tt,s=>{l(B)&&!l(me)&&s(jt)})}r(Re);var Ee=e(Re,2),ge=e(t(Ee),2);_(ge);var Te=e(ge,2),Ca=t(Te);_(Ca),i(2),r(Te);var Ra=e(Te,2),Ot=t(Ra);{var Nt=s=>{var o=Fr();i(2),d(s,o)},zt=s=>{var o=pe(),v=H(o);{var b=n=>{var p=D(`Path to your JSONL dataset with image paths/base64 or local
                  file`);d(n,p)},k=n=>{var p=D("Path to your JSONL dataset file");d(n,p)};c(v,n=>{a.model_type==="vision"?n(b):n(k,!1)},!0)}d(s,o)};c(Ot,s=>{a.from_hub?s(Nt):s(zt,!1)})}r(Ra),r(Ee);var je=e(Ee,2),be=e(t(je),2);_(be);var Oe=e(be,2),Ea=t(Oe);_(Ea),i(2),r(Oe);var Ta=e(Oe,2),Ft=e(t(Ta),3);{var Pt=s=>{var o=D(`Use HuggingFace format: "username/repo" or
                  "username/repo::validation.jsonl"`);d(s,o)};c(Ft,s=>{a.validation_from_hub&&s(Pt)})}r(Ta),r(je);var ja=e(je,2);{var qt=s=>{var o=Qr(),v=e(t(o),2);{var b=n=>{var p=Pr(),w=e(H(p),2),y=t(w);y.textContent='{"messages": [{"role": "user", "content": [{"type": "image", "image": "data:image/jpeg;base64,..."}, {"type": "text", "text": "What is shown?"}]}]}',r(w),i(2),d(n,p)},k=n=>{var p=qr(),w=e(H(p),2),y=t(w);y.textContent='{"text": "What is in this image?", "image": "/path/to/image.jpg", "response": "A cat sitting on a table"}',r(w),i(2),d(n,p)};c(v,n=>{a.from_hub?n(b):n(k,!1)})}r(o),d(s,o)};c(ja,s=>{a.model_type==="vision"&&s(qt)})}var Oa=e(ja,2),Na=e(t(Oa),2);_(Na),r(Oa),r(ka),r(Le);var Ne=e(Le,2),ze=t(Ne),Qt=e(t(ze),2);{var Vt=s=>{var o=Vr();d(s,o)};c(Qt,s=>{l(B)?.training_defaults&&s(Vt)})}r(ze);var za=e(ze,2);{var Ut=s=>{var o=Ur();d(s,o)};c(za,s=>{a.model_type==="vision"&&s(Ut)})}var Fe=e(za,2),Fa=e(t(Fe),2),Pe=t(Fa),qe=e(t(Pe),2);_(qe);var Pa=e(qe,2),$t=t(Pa);{var Gt=s=>{var o=D(`2e-5 recommended for
                    vision models`);d(s,o)},Jt=s=>{var o=D("2e-4 typical for text models");d(s,o)};c($t,s=>{a.model_type==="vision"?s(Gt):s(Jt,!1)})}r(Pa),r(Pe);var Qe=e(Pe,2),qa=e(t(Qe),2);_(qa),i(2),r(Qe);var Ve=e(Qe,2),Ue=e(t(Ve),2);_(Ue);var Qa=e(Ue,2),Dt=t(Qa);{var Ht=s=>{var o=D("Use 1 for vision models");d(s,o)},It=s=>{var o=D(`2-4
                    typical for text models`);d(s,o)};c(Dt,s=>{a.model_type==="vision"?s(Ht):s(It,!1)})}r(Qa),r(Ve);var $e=e(Ve,2),Va=e(t($e),2);_(Va),i(2),r($e);var Ge=e($e,2),Ua=e(t(Ge),2);_(Ua),i(2),r(Ge);var $a=e(Ge,2),Je=e(t($a),2),De=t(Je);De.value=De.__value="adamw_8bit";var He=e(De);He.value=He.__value="adamw_torch";var Ie=e(He);Ie.value=Ie.__value="adamw_torch_fused";var We=e(Ie);We.value=We.__value="adafactor";var Ga=e(We);Ga.value=Ga.__value="sgd",r(Je),i(2),r($a),r(Fa),r(Fe);var Ke=e(Fe,2),Ja=e(t(Ke),2),Ye=t(Ja),Da=e(t(Ye),2);_(Da),i(2),r(Ye);var Xe=e(Ye,2),Ha=e(t(Xe),2);_(Ha),i(2),r(Xe);var Ia=e(Xe,2),Wa=e(t(Ia),2);_(Wa),i(2),r(Ia),r(Ja),r(Ke);var Ka=e(Ke,2);{var Wt=s=>{var o=$r(),v=e(t(o),2),b=t(v),k=e(t(b),2),n=t(k);n.value=n.__value="steps";var p=e(n);p.value=p.__value="epoch";var w=e(p);w.value=w.__value="no",r(k),r(b);var y=e(b,2),x=e(t(y),2);_(x),i(2),r(y);var g=e(y,2),M=e(t(g),2),f=t(M);f.value=f.__value="eval_loss";var L=e(f);L.value=L.__value="eval_accuracy";var R=e(L);R.value=R.__value="eval_f1",r(M),r(g);var T=e(g,2),N=t(T),P=t(N);_(P),i(2),r(N),i(2),r(T),r(v),r(o),I(k,()=>a.hyperparameters.eval_strategy,A=>a.hyperparameters.eval_strategy=A),h(x,()=>a.hyperparameters.eval_steps,A=>a.hyperparameters.eval_steps=A),I(M,()=>a.hyperparameters.metric_for_best_model,A=>a.hyperparameters.metric_for_best_model=A),ie(P,()=>a.hyperparameters.load_best_model_at_end,A=>a.hyperparameters.load_best_model_at_end=A),d(s,o)};c(Ka,s=>{a.validation_dataset_path&&s(Wt)})}var Ze=e(Ka,2),ea=t(Ze);ea.__click=[Gr,he];var Ya=t(ea),Kt=t(Ya,!0);r(Ya),i(),r(ea),r(Ze);var Yt=e(Ze,2);{var Xt=s=>{var o=Jr(),v=e(t(o),2),b=t(v),k=e(t(b),2);_(k),i(2),r(b);var n=e(b,2),p=e(t(n),2),w=t(p);w.value=w.__value="linear";var y=e(w);y.value=y.__value="cosine";var x=e(y);x.value=x.__value="constant";var g=e(x);g.value=g.__value="constant_with_warmup";var M=e(g);M.value=M.__value="polynomial",r(p),i(2),r(n);var f=e(n,2),L=e(t(f),2);_(L),i(2),r(f);var R=e(f,2),T=e(t(R),2);_(T),i(2),r(R),r(v);var N=e(v,4),P=t(N),A=e(t(P),2);_(A),i(2),r(P);var Q=e(P,2),V=e(t(Q),2);_(V),i(2),r(Q);var U=e(Q,2),$=e(t(U),2);_($),i(2),r(U),r(N);var G=e(N,4),Z=t(G),J=e(t(Z),2);_(J),i(2),r(Z);var te=e(Z,2),re=t(te),se=t(re);_(se),i(2),r(re),i(2),r(te),r(G),r(o),h(k,()=>a.hyperparameters.weight_decay,u=>a.hyperparameters.weight_decay=u),I(p,()=>a.hyperparameters.lr_scheduler_type,u=>a.hyperparameters.lr_scheduler_type=u),h(L,()=>a.hyperparameters.warmup_steps,u=>a.hyperparameters.warmup_steps=u),h(T,()=>a.hyperparameters.max_grad_norm,u=>a.hyperparameters.max_grad_norm=u),h(A,()=>a.hyperparameters.adam_beta1,u=>a.hyperparameters.adam_beta1=u),h(V,()=>a.hyperparameters.adam_beta2,u=>a.hyperparameters.adam_beta2=u),h($,()=>a.hyperparameters.adam_epsilon,u=>a.hyperparameters.adam_epsilon=u),h(J,()=>a.hyperparameters.dataloader_num_workers,u=>a.hyperparameters.dataloader_num_workers=u),ie(se,()=>a.hyperparameters.dataloader_pin_memory,u=>a.hyperparameters.dataloader_pin_memory=u),d(s,o)};c(Yt,s=>{l(he)&&s(Xt)})}r(Ne);var aa=e(Ne,2),ta=t(aa),Zt=e(t(ta),2);{var er=s=>{var o=Dr();d(s,o)};c(Zt,s=>{l(B)?.training_defaults?.lora_config&&s(er)})}r(ta);var ra=e(ta,2),sa=t(ra),Xa=e(t(sa),2);_(Xa),i(2),r(sa);var oa=e(sa,2),Za=e(t(oa),2);_(Za),i(2),r(oa);var et=e(oa,2),at=e(t(et),2);_(at),i(2),r(et),r(ra);var ia=e(ra,2),la=t(ia);la.__click=[Hr,ke];var tt=t(la),ar=t(tt,!0);r(tt),i(),r(la),r(ia);var tr=e(ia,2);{var rr=s=>{var o=Wr(),v=t(o),b=t(v),k=e(t(b),2),n=t(k);n.value=n.__value="none";var p=e(n);p.value=p.__value="all";var w=e(p);w.value=w.__value="lora_only",r(k),i(2),r(b);var y=e(b,2),x=e(t(y),2),g=t(x);g.value=g.__value="unsloth";var M=e(g);M.value=M.__value="true";var f=e(M);f.value=f.__value="false",r(x),i(2),r(y),r(v);var L=e(v,2),R=t(L),T=t(R),N=t(T);_(N),i(2),r(T),i(2),r(R);var P=e(R,2),A=e(t(P),2);_(A),i(2),r(P),r(L);var Q=e(L,2),V=t(Q),U=e(t(V),2),$=t(U);$.value=$.__value="CAUSAL_LM";var G=e($);G.value=G.__value="SEQ_2_SEQ_LM";var Z=e(G);Z.value=Z.__value="TOKEN_CLS";var J=e(Z);J.value=J.__value="SEQ_CLS";var te=e(J);te.value=te.__value="QUESTION_ANS",r(U),i(2),r(V);var re=e(V,2),se=e(t(re),2);_(se),se.__input=[Ir,a],i(2),r(re),r(Q),i(2),r(o),q(u=>xr(se,u),[()=>a.lora_config.target_modules?.join(", ")||""]),I(k,()=>a.lora_config.lora_bias,u=>a.lora_config.lora_bias=u),I(x,()=>a.lora_config.use_gradient_checkpointing,u=>a.lora_config.use_gradient_checkpointing=u),ie(N,()=>a.lora_config.use_rslora,u=>a.lora_config.use_rslora=u),h(A,()=>a.lora_config.random_state,u=>a.lora_config.random_state=u),I(U,()=>a.lora_config.task_type,u=>a.lora_config.task_type=u),d(s,o)};c(tr,s=>{l(ke)&&s(rr)})}r(aa);var da=e(aa,2),rt=e(t(da),2),fe=e(t(rt),2),na=t(fe);na.value=na.__value="merged_16bit";var pa=e(na);pa.value=pa.__value="merged_4bit";var st=e(pa);st.value=st.__value="lora",r(fe);var ot=e(fe,2),it=t(ot),sr=t(it);{var or=s=>{var o=Kr();i(),d(s,o)},ir=s=>{var o=pe(),v=H(o);{var b=n=>{var p=Yr();i(),d(n,p)},k=n=>{var p=Xr();i(),d(n,p)};c(v,n=>{a.save_method==="merged_4bit"?n(b):n(k,!1)},!0)}d(s,o)};c(sr,s=>{a.save_method==="merged_16bit"?s(or):s(ir,!1)})}r(it),r(ot),r(rt),r(da);var lt=e(da,2);{var lr=s=>{var o=is(),v=e(t(o),4),b=t(v),k=t(b),n=t(k);_(n),i(2),r(k),i(2),r(b);var p=e(b,2);{var w=y=>{var x=os(),g=t(x),M=e(t(g),2),f=t(M);f.value=f.__value="conservative";var L=e(f);L.value=L.__value="moderate";var R=e(L);R.value=R.__value="aggressive",r(M);var T=e(M,2),N=t(T),P=t(N);{var A=S=>{var z=Zr(),ee=e(H(z),2);ee.textContent='{, }, [, ], :, ,, "',i(2),d(S,z)},Q=S=>{var z=pe(),ee=H(z);{var ce=ne=>{var _a=es();i(3),d(ne,_a)},vr=ne=>{var _a=as();i(),d(ne,_a)};c(ee,ne=>{a.selective_loss_level==="moderate"?ne(ce):ne(vr,!1)},!0)}d(S,z)};c(P,S=>{a.selective_loss_level==="conservative"?S(A):S(Q,!1)})}r(N),r(T),r(g);var V=e(g,2);{var U=S=>{var z=ts(),ee=e(t(z),2);_(ee),i(4),r(z),h(ee,()=>a.selective_loss_schema_keys,ce=>a.selective_loss_schema_keys=ce),d(S,z)};c(V,S=>{a.selective_loss_level==="aggressive"&&S(U)})}var $=e(V,2),G=t($),Z=t(G);r(G);var J=e(G,2);_(J);var te=e(J,4),re=t(te),se=e(t(re),2);{var u=S=>{var z=rs();i(),d(S,z)},nr=S=>{var z=ss(),ee=e(H(z)),ce=t(ee);r(ee),q(()=>F(ce,`Currently: Model learns structure for ${a.selective_loss_masking_start_step??""}
                            steps, then masking begins`)),d(S,z)};c(se,S=>{a.selective_loss_masking_start_step===0?S(u):S(nr,!1)})}r(re),r(te),r($);var ma=e($,2),pt=t(ma),mt=t(pt);_(mt),i(2),r(pt),i(2),r(ma);var vt=e(ma,2),va=e(t(vt),2),_t=t(va),pr=e(t(_t));pr.textContent="{ } [ ] : ,",i(),r(_t),i(8),r(va);var ct=e(va,2),ut=e(t(ct),2);ut.textContent='{"name": "John", "age": 30}';var mr=e(ut,2);mr.textContent='{ } : , "',i(2),r(ct),r(vt),r(x),q(()=>F(Z,`Masking Start Step: ${a.selective_loss_masking_start_step??""}`)),I(M,()=>a.selective_loss_level,S=>a.selective_loss_level=S),h(J,()=>a.selective_loss_masking_start_step,S=>a.selective_loss_masking_start_step=S),ie(mt,()=>a.selective_loss_verbose,S=>a.selective_loss_verbose=S),d(y,x)};c(p,y=>{a.selective_loss&&y(w)})}r(v),r(o),ie(n,()=>a.selective_loss,y=>a.selective_loss=y),d(s,o)};c(lt,s=>{a.model_type==="vision"&&s(lr)})}var dt=e(lt,2),nt=t(dt);ba(nt,{type:"submit",variant:"primary",get loading(){return l(W)},get disabled(){return l(W)},children:(s,o)=>{i();var v=D();q(()=>F(v,l(W)?"Creating...":"Start Training")),d(s,v)},$$slots:{default:!0}});var dr=e(nt,2);ba(dr,{href:"/training",variant:"secondary",children:(s,o)=>{i();var v=D("Cancel");d(s,v)},$$slots:{default:!0}}),r(dt),r(X),q(()=>{ye(ve,1,`p-4 border-2 rounded-lg text-left transition-all ${a.model_type==="text"?"border-primary-500 bg-primary-50":"border-gray-300 hover:border-gray-400"}`),ye(Ae,1,`w-4 h-4 rounded-full border-2 ${a.model_type==="text"?"border-primary-500 bg-primary-500":"border-gray-400"}`),ye(ue,1,`p-4 border-2 rounded-lg text-left transition-all ${a.model_type==="vision"?"border-primary-500 bg-primary-50":"border-gray-300 hover:border-gray-400"}`),ye(Be,1,`w-4 h-4 rounded-full border-2 ${a.model_type==="vision"?"border-primary-500 bg-primary-500":"border-gray-400"}`),_e.disabled=l(me),gt(ge,"placeholder",a.from_hub?"username/dataset-name":a.model_type==="vision"?"./data/vision_dataset.jsonl":"./data/my-dataset.jsonl"),gt(be,"placeholder",a.validation_from_hub?"username/val-dataset-name":a.model_type==="vision"?"./data/vision_val_dataset.jsonl":"./data/my-val-dataset.jsonl"),F(Kt,l(he)?"‚ñº":"‚ñ∂"),F(ar,l(ke)?"‚ñº":"‚ñ∂")}),yr("submit",X,yt),h(Ma,()=>a.name,s=>a.name=s),I(_e,()=>a.base_model,s=>a.base_model=s),h(ge,()=>a.dataset_path,s=>a.dataset_path=s),ie(Ca,()=>a.from_hub,s=>a.from_hub=s),h(be,()=>a.validation_dataset_path,s=>a.validation_dataset_path=s),ie(Ea,()=>a.validation_from_hub,s=>a.validation_from_hub=s),h(Na,()=>a.output_dir,s=>a.output_dir=s),h(qe,()=>a.hyperparameters.learning_rate,s=>a.hyperparameters.learning_rate=s),h(qa,()=>a.hyperparameters.num_epochs,s=>a.hyperparameters.num_epochs=s),h(Ue,()=>a.hyperparameters.batch_size,s=>a.hyperparameters.batch_size=s),h(Va,()=>a.hyperparameters.gradient_accumulation_steps,s=>a.hyperparameters.gradient_accumulation_steps=s),h(Ua,()=>a.hyperparameters.max_steps,s=>a.hyperparameters.max_steps=s),I(Je,()=>a.hyperparameters.optim,s=>a.hyperparameters.optim=s),h(Da,()=>a.hyperparameters.logging_steps,s=>a.hyperparameters.logging_steps=s),h(Ha,()=>a.hyperparameters.save_steps,s=>a.hyperparameters.save_steps=s),h(Wa,()=>a.hyperparameters.save_total_limit,s=>a.hyperparameters.save_total_limit=s),h(Xa,()=>a.lora_config.r,s=>a.lora_config.r=s),h(Za,()=>a.lora_config.lora_alpha,s=>a.lora_config.lora_alpha=s),h(at,()=>a.lora_config.lora_dropout,s=>a.lora_config.lora_dropout=s),I(fe,()=>a.save_method,s=>a.save_method=s),d(O,X)},$$slots:{default:!0}}),r(ha),r(we),d(oe,we),br()}_r(["click","input"]);export{fs as component};
