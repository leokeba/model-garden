import"../chunks/DsnmJJEf.js";import{q as _r,p as cr,a as ua,s as ae,o as ur,E as ut,i as l,d as T,f as m,h as gr,b as d,c as br,$ as fr,t as H,e as t,g as e,l as q,w as yr,n as i,r,m as F,j as pe,k as D}from"../chunks/D_fozEd9.js";import{i as c}from"../chunks/C2ngLJft.js";import{r as _,s as ye,a as gt,b as xr,e as bt,i as ft}from"../chunks/489nzvkF.js";import{b as h,c as ie}from"../chunks/aZwOC-1j.js";import{b as I}from"../chunks/DV7skBy0.js";import{g as hr}from"../chunks/Byvzo9pf.js";import{a as ga}from"../chunks/GrWgsx-T.js";import{B as ba,C as kr}from"../chunks/DWJusdRQ.js";function wr(te,A){A.name&&!A.output_dir&&(A.output_dir=`./models/${A.name.toLowerCase().replace(/[^a-z0-9]/g,"-")}`)}var Sr=m('<div class="p-4 bg-red-50 border border-red-200 rounded-lg"><p class="text-red-700"> </p></div>'),Lr=(te,A)=>A.model_type="text",Mr=m('<div class="w-full h-full rounded-full bg-white scale-50"></div>'),Ar=(te,A)=>A.model_type="vision",Br=m('<div class="w-full h-full rounded-full bg-white scale-50"></div>'),Cr=m("<option>Loading models...</option>"),Rr=m("<option> </option>"),Er=m("<option> </option>"),Tr=m('<p class="text-xs text-yellow-600 mt-1"> </p>'),jr=m('<p class="text-xs text-gray-500 mt-1">üé® Vision-language models can analyze images and text together</p>'),Or=m('<p class="text-xs text-blue-700"><strong>Context:</strong> </p>'),Nr=m('<div class="space-y-1"><p class="text-xs text-blue-700"><strong>VRAM:</strong> </p> <!></div>'),zr=m('<p class="text-xs text-blue-700 mt-2"><strong>Best for:</strong> </p>'),Fr=m('<div class="mt-3 p-3 bg-blue-50 border border-blue-200 rounded-lg"><div class="flex items-start justify-between"><div class="flex-1"><h4 class="text-sm font-semibold text-blue-900 mb-1"> </h4> <p class="text-xs text-blue-800 mb-2"> </p> <!> <!></div></div></div>'),Pr=m(`Enter a HuggingFace dataset identifier (e.g.,
                  "username/dataset-name")<br/> For specific files, use: "username/repo::train.jsonl"`,1),qr=m(`<p class="text-sm text-blue-800 mb-2">HuggingFace datasets should use OpenAI messages format with
                    base64 images:</p> <pre class="text-xs bg-blue-100 p-2 rounded overflow-x-auto"><code></code></pre> <p class="text-xs text-blue-700 mt-2"><strong>Example:</strong> <code>Barth371/train_pop_valet_no_wrong_doc</code></p>`,1),Qr=m(`<p class="text-sm text-blue-800 mb-2">Your dataset should be in JSONL format with:</p> <pre class="text-xs bg-blue-100 p-2 rounded overflow-x-auto"><code></code></pre> <p class="text-xs text-blue-700 mt-2"><strong>Tip:</strong> Use <code>model-garden create-vision-dataset</code> CLI to generate
                    sample data</p>`,1),Vr=m('<div class="p-4 bg-blue-50 border border-blue-200 rounded-lg"><h4 class="text-sm font-semibold text-blue-900 mb-2">üìã Vision Dataset Format</h4> <!></div>'),Ur=m('<span class="text-xs text-green-600 bg-green-50 px-2 py-1 rounded">‚úì Using registry defaults</span>'),$r=m(`<div class="mb-4 p-3 bg-yellow-50 border border-yellow-200 rounded-lg"><p class="text-sm text-yellow-800">‚ö†Ô∏è <strong>Vision models require:</strong> Lower batch size (1-2),
                higher gradient accumulation (8+), and lower learning rate (2e-5)</p></div>`),Gr=m('<div class="mb-6"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üìä Evaluation Settings</h4> <div class="grid grid-cols-2 gap-4"><div><label for="eval_strategy" class="block text-sm font-medium text-gray-700 mb-1">Evaluation Strategy</label> <select id="eval_strategy" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Every N steps</option><option>Every epoch</option><option>No evaluation</option></select></div> <div><label for="eval_steps" class="block text-sm font-medium text-gray-700 mb-1">Evaluation Steps</label> <input type="number" id="eval_steps" placeholder="Auto (same as save_steps)" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Evaluate every N steps (leave empty for auto)</p></div> <div><label for="metric_for_best_model" class="block text-sm font-medium text-gray-700 mb-1">Best Model Metric</label> <select id="metric_for_best_model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Validation Loss (lower is better)</option><option>Accuracy (higher is better)</option><option>F1 Score (higher is better)</option></select></div> <div><div class="flex items-center mt-6"><input type="checkbox" id="load_best_model_at_end" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="load_best_model_at_end" class="ml-2 block text-sm text-gray-700">Load best model at end</label></div> <p class="text-xs text-gray-500 mt-1">Automatically load checkpoint with best validation metric</p></div></div></div>'),Jr=(te,A)=>T(A,!l(A)),Hr=m('<div class="mb-6 p-4 bg-gray-50 border border-gray-200 rounded-lg"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">‚öôÔ∏è Optimizer Settings</h4> <div class="grid grid-cols-2 gap-4 mb-6"><div><label for="weight_decay" class="block text-sm font-medium text-gray-700 mb-1">Weight Decay</label> <input type="number" id="weight_decay" step="0.001" min="0" max="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">L2 regularization strength (0.01 typical)</p></div> <div><label for="lr_scheduler_type" class="block text-sm font-medium text-gray-700 mb-1">LR Scheduler</label> <select id="lr_scheduler_type" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Linear (default)</option><option>Cosine (good for vision)</option><option>Constant</option><option>Constant with Warmup</option><option>Polynomial</option></select> <p class="text-xs text-gray-500 mt-1">Learning rate schedule type</p></div> <div><label for="warmup_steps" class="block text-sm font-medium text-gray-700 mb-1">Warmup Steps</label> <input type="number" id="warmup_steps" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Steps to warmup learning rate from 0</p></div> <div><label for="max_grad_norm" class="block text-sm font-medium text-gray-700 mb-1">Max Gradient Norm</label> <input type="number" id="max_grad_norm" step="0.1" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Gradient clipping threshold (1.0 standard)</p></div></div> <h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üéõÔ∏è Adam Optimizer Parameters</h4> <div class="grid grid-cols-3 gap-4 mb-6"><div><label for="adam_beta1" class="block text-sm font-medium text-gray-700 mb-1">Adam Beta1</label> <input type="number" id="adam_beta1" step="0.01" min="0" max="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Exponential decay rate for 1st moment (0.9 default)</p></div> <div><label for="adam_beta2" class="block text-sm font-medium text-gray-700 mb-1">Adam Beta2</label> <input type="number" id="adam_beta2" step="0.001" min="0" max="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Exponential decay rate for 2nd moment (0.999 default)</p></div> <div><label for="adam_epsilon" class="block text-sm font-medium text-gray-700 mb-1">Adam Epsilon</label> <input type="number" id="adam_epsilon" step="1e-9" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Small constant for numerical stability (1e-8 default)</p></div></div> <h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üîÑ Data Loading Settings</h4> <div class="grid grid-cols-2 gap-4"><div><label for="dataloader_num_workers" class="block text-sm font-medium text-gray-700 mb-1">Dataloader Workers</label> <input type="number" id="dataloader_num_workers" min="0" max="16" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Number of worker processes (0 = main process only)</p></div> <div><div class="flex items-center mt-6"><input type="checkbox" id="dataloader_pin_memory" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="dataloader_pin_memory" class="ml-2 block text-sm text-gray-700">Pin memory to GPU</label></div> <p class="text-xs text-gray-500 mt-1">Faster data transfer to GPU (recommended)</p></div></div></div>'),Dr=m('<span class="text-xs text-green-600 bg-green-50 px-2 py-1 rounded">‚úì Using registry defaults</span>'),Ir=(te,A)=>T(A,!l(A)),Wr=(te,A)=>{const a=te.currentTarget.value.trim();a?A.lora_config.target_modules=a.split(",").map(W=>W.trim()).filter(W=>W.length>0):A.lora_config.target_modules=null},Kr=m(`<div class="p-4 bg-gray-50 border border-gray-200 rounded-lg"><div class="grid grid-cols-2 gap-4 mb-4"><div><label for="lora_bias" class="block text-sm font-medium text-gray-700 mb-1">LoRA Bias</label> <select id="lora_bias" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>None (default)</option><option>All bias terms</option><option>LoRA layers only</option></select> <p class="text-xs text-gray-500 mt-1">How to handle bias parameters in LoRA layers</p></div> <div><label for="use_gradient_checkpointing" class="block text-sm font-medium text-gray-700 mb-1">Gradient Checkpointing</label> <select id="use_gradient_checkpointing" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Unsloth (recommended)</option><option>Standard PyTorch</option><option>Disabled</option></select> <p class="text-xs text-gray-500 mt-1">Reduces memory at cost of compute time</p></div></div> <div class="grid grid-cols-2 gap-4 mb-4"><div><div class="flex items-center mt-2"><input type="checkbox" id="use_rslora" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="use_rslora" class="ml-2 block text-sm text-gray-700">Use RSLoRA (Rank-Stabilized LoRA)</label></div> <p class="text-xs text-gray-500 mt-1">Better stability for high ranks (r > 16)</p></div> <div><label for="random_state" class="block text-sm font-medium text-gray-700 mb-1">Random Seed</label> <input type="number" id="random_state" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Seed for reproducible results (42 is popular)</p></div></div> <div class="grid grid-cols-2 gap-4 mb-4"><div><label for="task_type" class="block text-sm font-medium text-gray-700 mb-1">Task Type</label> <select id="task_type" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Causal LM (Text Generation)</option><option>Sequence-to-Sequence</option><option>Token Classification</option><option>Sequence Classification</option><option>Question Answering</option></select> <p class="text-xs text-gray-500 mt-1">Type of task for PEFT optimization</p></div> <div><label for="target_modules_input" class="block text-sm font-medium text-gray-700 mb-1">Target Modules (Advanced)</label> <input type="text" id="target_modules_input" placeholder="q_proj, k_proj, v_proj (leave empty for auto)" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Comma-separated list of layers to apply LoRA (auto-detected
                    if empty)</p></div></div> <div class="p-3 bg-blue-50 border border-blue-200 rounded-lg"><h4 class="text-sm font-semibold text-blue-900 mb-2">üí° LoRA Tips</h4> <ul class="text-xs text-blue-800 space-y-1"><li><strong>Rank (r):</strong> Start with 16, increase to 64+ for
                    complex tasks or large datasets</li> <li><strong>Alpha:</strong> Usually equal to rank. Higher alpha =
                    stronger adaptation</li> <li><strong>Dropout:</strong> Add 0.1-0.3 if overfitting, keep 0
                    for small datasets</li> <li><strong>RSLoRA:</strong> Enable for ranks > 16 to improve training
                    stability</li> <li><strong>Target Modules:</strong> Leave empty for auto-detection.
                    Common: "q_proj,k_proj,v_proj,o_proj" for attention layers</li> <li><strong>Task Type:</strong> Use "CAUSAL_LM" for text generation,
                    "SEQ_2_SEQ_LM" for translation/summarization</li></ul></div></div>`),Yr=m(`<strong>‚úÖ Merged 16-bit (Recommended):</strong> Full model with
                  LoRA weights merged using Unsloth. Creates split files for vLLM
                  compatibility.`,1),Xr=m(`<strong>üì¶ Merged 4-bit:</strong> Full model with LoRA weights
                  merged in 4-bit quantized format. Smaller file size.`,1),Zr=m(`<strong>üîß LoRA Adapters Only (Advanced):</strong> Saves only the
                  adapter weights. Requires the base model to load.`,1),es=m(`<strong>Conservative:</strong> Masks JSON structural
                          characters: <code></code> and
                          whitespace. Masks ~31% of tokens. <em>Recommended for most cases.</em>`,1),as=m("<strong>Moderate:</strong> Conservative + masks <code>null</code> keyword. Good when null values are predictable.",1),ts=m(`<strong>Aggressive:</strong> Moderate + masks schema field
                          names. Maximum focus on semantic content. Requires specifying
                          schema keys below.`,1),rs=m(`<div><label for="selective_loss_schema_keys" class="block text-sm font-medium text-gray-700 mb-1">Schema Keys to Mask</label> <input type="text" id="selective_loss_schema_keys" placeholder="Marque,Modele,contents,confidence_score" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Comma-separated list of JSON field names to mask (e.g.,
                        "name,address,phone")</p> <div class="mt-2 p-2 bg-yellow-50 border border-yellow-200 rounded"><p class="text-xs text-yellow-800">‚ö†Ô∏è Only mask keys that are predictable and don't carry
                          semantic meaning. The model should still learn what
                          values go with each key.</p></div></div>`),ss=m(`<br/><em>Currently: Masking starts immediately (traditional
                            approach)</em>`,1),os=m("<br/><em> </em>",1),is=m(`<div class="ml-6 space-y-4 p-4 bg-white border border-gray-200 rounded-lg"><div><label for="selective_loss_level" class="block text-sm font-medium text-gray-700 mb-2">Masking Level</label> <select id="selective_loss_level" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Conservative (Structure Only)</option><option>Moderate (Structure + null)</option><option>Aggressive (Structure + null + Schema Keys)</option></select> <div class="mt-2 p-3 bg-gray-50 rounded-lg"><p class="text-xs text-gray-700"><!></p></div></div> <!> <div><label for="selective_loss_masking_start_step" class="block text-sm font-medium text-gray-700 mb-2"> </label> <input type="range" id="selective_loss_masking_start_step" min="0" max="500" step="10" class="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer accent-primary-500"/> <div class="flex justify-between text-xs text-gray-500 mt-1"><span>0 (Immediate)</span> <span>100</span> <span>200</span> <span>500 steps</span></div> <div class="mt-2 p-3 bg-blue-50 rounded-lg"><p class="text-xs text-blue-700"><strong>üí° Tip:</strong> Setting this to 50-200 lets the
                        model learn JSON structure first before applying
                        selective masking. This can prevent degeneration issues
                        with aggressive masking. <!></p></div></div> <div><div class="flex items-center"><input type="checkbox" id="selective_loss_verbose" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="selective_loss_verbose" class="ml-2 block text-sm text-gray-700">Verbose mode (print masking statistics)</label></div> <p class="text-xs text-gray-500 mt-1">Display detailed token masking stats during training</p></div> <div class="p-3 bg-blue-50 border border-blue-200 rounded-lg"><h4 class="text-sm font-semibold text-blue-900 mb-2">üìä What Gets Masked?</h4> <ul class="text-xs text-blue-800 space-y-1"><li>‚úì Structural: <code></code> and whitespace
                        (spaces, newlines, tabs)</li> <li>‚úì Quotes: <code>"</code> (string delimiters - purely structural)</li> <li>‚úì Null keyword: <code>null</code> (moderate/aggressive only)</li> <li>‚úó NOT masked: <code>true</code>, <code>false</code> (can
                        be semantic)</li> <li>‚úì Schema keys: Field names like <code>name</code> (aggressive
                        only)</li></ul> <p class="text-xs text-blue-700 mt-2"><strong>Example:</strong> In <code></code>, conservative
                      mode masks <code></code> and spaces (~31% of tokens),
                      trains on <code>name John age 30</code></p></div></div>`),ls=m(`<div><h3 class="text-lg font-semibold text-gray-900 mb-4">üéØ Selective Loss (Structured Outputs)</h3> <div class="p-4 bg-gradient-to-r from-purple-50 to-blue-50 border border-purple-200 rounded-lg mb-4"><p class="text-sm text-gray-800 mb-2"><strong>üî¨ Experimental Feature:</strong> Optimize training for structured
                outputs (JSON, forms, etc.)</p> <p class="text-xs text-gray-700">Masks structural tokens (braces, colons, whitespace) so the
                model focuses on semantic content. Useful for form extraction,
                structured data generation, and similar tasks.</p></div> <div class="space-y-4"><div><div class="flex items-center"><input type="checkbox" id="selective_loss" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="selective_loss" class="ml-2 block text-sm font-medium text-gray-700">Enable Selective Loss Masking</label></div> <p class="text-xs text-gray-500 mt-1 ml-6">Automatically mask JSON structural tokens during training</p></div> <!></div></div>`),ds=m(`<form class="space-y-6"><!> <div><h3 class="text-lg font-semibold text-gray-900 mb-4">Basic Configuration</h3> <div class="grid grid-cols-1 gap-4"><div><div class="block text-sm font-medium text-gray-700 mb-2">Model Type *</div> <div class="grid grid-cols-2 gap-3"><button type="button"><div class="flex items-center gap-2"><div><!></div> <span class="font-medium">Text-Only (LLM)</span></div> <p class="text-sm text-gray-600 mt-2 ml-6">Fine-tune language models for text generation tasks</p></button> <button type="button"><div class="flex items-center gap-2"><div><!></div> <span class="font-medium">Vision-Language (VLM)</span></div> <p class="text-sm text-gray-600 mt-2 ml-6">Fine-tune multimodal models for image + text tasks</p></button></div></div> <div><label for="name" class="block text-sm font-medium text-gray-700 mb-1">Model Name *</label> <input type="text" id="name" placeholder="my-finance-model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500" required/></div> <div><label for="base_model" class="block text-sm font-medium text-gray-700 mb-1">Base Model *</label> <select id="base_model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500" required><!></select> <!> <!> <!></div> <div><label for="dataset_path" class="block text-sm font-medium text-gray-700 mb-1">Dataset Path *</label> <input type="text" id="dataset_path" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500" required/> <div class="mt-2 flex items-center"><input type="checkbox" id="from_hub" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="from_hub" class="ml-2 block text-sm text-gray-700">Load from HuggingFace Hub</label></div> <p class="text-xs text-gray-500 mt-1"><!></p></div> <div><label for="validation_dataset_path" class="block text-sm font-medium text-gray-700 mb-1">Validation Dataset Path (Optional)</label> <input type="text" id="validation_dataset_path" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <div class="mt-2 flex items-center"><input type="checkbox" id="validation_from_hub" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="validation_from_hub" class="ml-2 block text-sm text-gray-700">Load validation dataset from HuggingFace Hub</label></div> <p class="text-xs text-gray-500 mt-1">üìä Optional: Provide a validation dataset to track validation
                loss during training<br/> <!></p></div> <!> <div><label for="output_dir" class="block text-sm font-medium text-gray-700 mb-1">Output Directory</label> <input type="text" id="output_dir" placeholder="./models/my-model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/></div></div></div> <div><div class="flex items-center justify-between mb-4"><h3 class="text-lg font-semibold text-gray-900">Training Hyperparameters</h3> <!></div> <!> <div class="mb-6"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üéØ Essential Parameters</h4> <div class="grid grid-cols-2 gap-4"><div><label for="learning_rate" class="block text-sm font-medium text-gray-700 mb-1">Learning Rate</label> <input type="number" id="learning_rate" step="0.00001" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1"><!></p></div> <div><label for="num_epochs" class="block text-sm font-medium text-gray-700 mb-1">Number of Epochs</label> <input type="number" id="num_epochs" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Number of complete passes through dataset</p></div> <div><label for="batch_size" class="block text-sm font-medium text-gray-700 mb-1">Batch Size per GPU</label> <input type="number" id="batch_size" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1"><!></p></div> <div><label for="gradient_accumulation" class="block text-sm font-medium text-gray-700 mb-1">Gradient Accumulation Steps</label> <input type="number" id="gradient_accumulation" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Effective batch size = batch_size √ó
                  gradient_accumulation_steps</p></div> <div><label for="max_steps" class="block text-sm font-medium text-gray-700 mb-1">Max Steps (Optional)</label> <input type="number" id="max_steps" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Override epochs with exact step count (-1 for full epochs)</p></div> <div><label for="optim" class="block text-sm font-medium text-gray-700 mb-1">Optimizer</label> <select id="optim" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>AdamW 8-bit (Recommended - Memory Efficient)</option><option>AdamW (PyTorch)</option><option>AdamW Fused (Faster)</option><option>Adafactor (Very Memory Efficient)</option><option>SGD</option></select> <p class="text-xs text-gray-500 mt-1">8-bit AdamW reduces memory usage significantly</p></div></div></div> <div class="mb-6"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üíæ Checkpoints & Logging</h4> <div class="grid grid-cols-3 gap-4"><div><label for="logging_steps" class="block text-sm font-medium text-gray-700 mb-1">Logging Steps</label> <input type="number" id="logging_steps" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Log metrics every N steps</p></div> <div><label for="save_steps" class="block text-sm font-medium text-gray-700 mb-1">Save Steps</label> <input type="number" id="save_steps" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Save checkpoint every N steps</p></div> <div><label for="save_total_limit" class="block text-sm font-medium text-gray-700 mb-1">Max Checkpoints</label> <input type="number" id="save_total_limit" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Keep only N most recent checkpoints</p></div></div></div> <!> <div class="mb-4"><button type="button" class="flex items-center gap-2 px-4 py-2 text-sm font-medium text-primary-700 bg-primary-50 border border-primary-200 rounded-lg hover:bg-primary-100 transition-colors"><span> </span> Advanced Hyperparameters</button></div> <!></div> <div><div class="flex items-center justify-between mb-4"><h3 class="text-lg font-semibold text-gray-900">LoRA Configuration</h3> <!></div> <div class="grid grid-cols-3 gap-4 mb-4"><div><label for="lora_r" class="block text-sm font-medium text-gray-700 mb-1">LoRA Rank (r)</label> <input type="number" id="lora_r" min="1" max="256" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Higher = more parameters (16 typical, 64+ for complex tasks)</p></div> <div><label for="lora_alpha" class="block text-sm font-medium text-gray-700 mb-1">LoRA Alpha</label> <input type="number" id="lora_alpha" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Scaling factor (typically equal to rank)</p></div> <div><label for="lora_dropout" class="block text-sm font-medium text-gray-700 mb-1">LoRA Dropout</label> <input type="number" id="lora_dropout" min="0" max="0.5" step="0.05" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Regularization (0.0-0.3, 0 = no dropout)</p></div></div> <div class="mb-4"><button type="button" class="flex items-center gap-2 px-4 py-2 text-sm font-medium text-primary-700 bg-primary-50 border border-primary-200 rounded-lg hover:bg-primary-100 transition-colors"><span> </span> Advanced LoRA Settings</button></div> <!></div> <div><h3 class="text-lg font-semibold text-gray-900 mb-4">Model Save Options</h3> <div><label for="save_method" class="block text-sm font-medium text-gray-700 mb-2">Save Method</label> <select id="save_method" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Save Merged Model (16-bit) - Recommended</option><option>Save Merged Model (4-bit) - Smaller Size</option><option>Save LoRA Adapters Only - Advanced</option></select> <div class="mt-3 p-3 bg-blue-50 border border-blue-200 rounded-lg"><p class="text-sm text-blue-800"><!></p></div></div></div> <!> <div class="flex gap-4 pt-4"><!> <!></div></form>`),ns=m('<div class="min-h-screen bg-gray-50"><div class="bg-white shadow"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex justify-between items-center py-6"><div class="flex items-center"><!> <h1 class="text-3xl font-bold text-gray-900 ml-4">New Training Job</h1></div></div></div></div> <div class="max-w-3xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><!></div></div>');function ys(te,A){cr(A,!0);let a=ua({name:"",model_type:"text",base_model:"unsloth/tinyllama-bnb-4bit",dataset_path:"./data/sample.jsonl",validation_dataset_path:"",output_dir:"",hyperparameters:{learning_rate:2e-4,num_epochs:3,batch_size:2,max_steps:-1,gradient_accumulation_steps:4,warmup_steps:10,logging_steps:10,save_steps:100,eval_steps:null,optim:"adamw_8bit",weight_decay:.01,lr_scheduler_type:"linear",max_grad_norm:1,adam_beta1:.9,adam_beta2:.999,adam_epsilon:1e-8,dataloader_num_workers:0,dataloader_pin_memory:!0,eval_strategy:"steps",load_best_model_at_end:!0,metric_for_best_model:"eval_loss",save_total_limit:3},lora_config:{r:16,lora_alpha:16,lora_dropout:0,lora_bias:"none",use_rslora:!1,use_gradient_checkpointing:"unsloth",random_state:42,target_modules:null,task_type:"CAUSAL_LM",loftq_config:null},from_hub:!1,validation_from_hub:!1,save_method:"merged_16bit",selective_loss:!1,selective_loss_level:"conservative",selective_loss_schema_keys:"",selective_loss_masking_start_step:0,selective_loss_verbose:!1}),W=ae(!1),le=ae(""),K=ae(ua([])),Y=ae(ua([])),C=ae(null),me=ae(!0),xe=ae("");ur(async()=>{try{T(me,!0);const[O,R]=await Promise.all([ga.getRegistryModels("text-llm"),ga.getRegistryModels("vision-vlm")]);T(K,O.models,!0),T(Y,R.models,!0),a.model_type==="text"&&l(K).length>0?(T(C,l(K)[0],!0),a.base_model=l(K)[0].id):a.model_type==="vision"&&l(Y).length>0&&(T(C,l(Y)[0],!0),a.base_model=l(Y)[0].id)}catch(O){T(xe,O instanceof Error?O.message:"Failed to load models from registry",!0),console.error("Failed to load registry models:",O),T(K,[{id:"unsloth/tinyllama-bnb-4bit",name:"TinyLlama 1.1B (4-bit)",parameters:"1.1B"},{id:"unsloth/phi-2-bnb-4bit",name:"Phi-2 2.7B (4-bit)",parameters:"2.7B"},{id:"unsloth/mistral-7b-bnb-4bit",name:"Mistral 7B (4-bit)",parameters:"7B"},{id:"unsloth/llama-2-7b-bnb-4bit",name:"Llama 2 7B (4-bit)",parameters:"7B"},{id:"unsloth/llama-3-8b-bnb-4bit",name:"Llama 3 8B (4-bit)",parameters:"8B"}],!0),T(Y,[{id:"Qwen/Qwen2.5-VL-3B-Instruct",name:"Qwen2.5-VL 3B",parameters:"3B"},{id:"Qwen/Qwen2.5-VL-7B-Instruct",name:"Qwen2.5-VL 7B",parameters:"7B"},{id:"Qwen/Qwen2.5-VL-72B-Instruct",name:"Qwen2.5-VL 72B",parameters:"72B"},{id:"unsloth/Qwen2.5-VL-3B-Instruct-bnb-4bit",name:"Qwen2.5-VL 3B (4-bit)",parameters:"3B"},{id:"unsloth/Qwen2.5-VL-7B-Instruct-bnb-4bit",name:"Qwen2.5-VL 7B (4-bit)",parameters:"7B"}],!0)}finally{T(me,!1)}}),ut(()=>{const O=a.model_type==="vision"?l(Y):l(K);if(T(C,O.find(R=>R.id===a.base_model)||null,!0),l(C)?.training_defaults){const R=l(C).training_defaults;R.hyperparameters&&(a.hyperparameters={...a.hyperparameters,...R.hyperparameters}),R.lora_config&&(a.lora_config={...a.lora_config,...R.lora_config}),R.save_method&&(a.save_method=R.save_method)}}),ut(()=>{a.model_type==="vision"?(l(Y).length>0&&(a.base_model=l(Y)[0].id),a.dataset_path="./data/vision_dataset.jsonl"):(l(K).length>0&&(a.base_model=l(K)[0].id),a.dataset_path="./data/sample.jsonl")});let he=ae(!1),ke=ae(!1);async function yt(O){if(O.preventDefault(),!a.name||!a.base_model||!a.dataset_path){T(le,"Please fill in all required fields");return}T(W,!0),T(le,"");try{let R=null;a.selective_loss_schema_keys&&a.selective_loss_schema_keys.trim()&&(R=a.selective_loss_schema_keys.split(",").map(de=>de.trim()).filter(de=>de.length>0));const X=await ga.createTrainingJob({...a,is_vision:a.model_type==="vision",selective_loss:a.selective_loss,selective_loss_level:a.selective_loss_level,selective_loss_schema_keys:R,selective_loss_masking_start_step:a.selective_loss_masking_start_step,selective_loss_verbose:a.selective_loss_verbose});X.success?hr(`/training/${X.data.job_id}`):T(le,"Failed to create training job")}catch(R){T(le,R instanceof Error?R.message:"Failed to create training job",!0)}finally{T(W,!1)}}var we=ns();gr(O=>{fr.title="New Training Job - Model Garden"});var Se=t(we),fa=t(Se),ya=t(fa),xa=t(ya),xt=t(xa);ba(xt,{href:"/training",variant:"ghost",size:"sm",children:(O,R)=>{i();var X=H("‚Üê Training Jobs");d(O,X)},$$slots:{default:!0}}),i(2),r(xa),r(ya),r(fa),r(Se);var ha=e(Se,2),ht=t(ha);kr(ht,{children:(O,R)=>{var X=ds(),de=t(X);{var kt=s=>{var o=Sr(),v=t(o),b=t(v,!0);r(v),r(o),q(()=>F(b,l(le))),d(s,o)};c(de,s=>{l(le)&&s(kt)})}var Le=e(de,2),ka=e(t(Le),2),Me=t(ka),wa=e(t(Me),2),ve=t(wa);ve.__click=[Lr,a];var Sa=t(ve),Ae=t(Sa),wt=t(Ae);{var St=s=>{var o=Mr();d(s,o)};c(wt,s=>{a.model_type==="text"&&s(St)})}r(Ae),i(2),r(Sa),i(2),r(ve);var ue=e(ve,2);ue.__click=[Ar,a];var La=t(ue),Be=t(La),Lt=t(Be);{var Mt=s=>{var o=Br();d(s,o)};c(Lt,s=>{a.model_type==="vision"&&s(Mt)})}r(Be),i(2),r(La),i(2),r(ue),r(wa),r(Me);var Ce=e(Me,2),Re=e(t(Ce),2);_(Re),Re.__input=[wr,a],r(Ce);var Ee=e(Ce,2),_e=e(t(Ee),2),At=t(_e);{var Bt=s=>{var o=Cr();o.value=o.__value="",d(s,o)},Ct=s=>{var o=pe(),v=D(o);{var b=n=>{var p=pe(),w=D(p);bt(w,17,()=>l(K),ft,(y,x)=>{var g=Rr(),M=t(g);r(g);var f={};q(()=>{F(M,`${l(x).name??""} (${l(x).parameters??""})`),f!==(f=l(x).id)&&(g.value=(g.__value=l(x).id)??"")}),d(y,g)}),d(n,p)},k=n=>{var p=pe(),w=D(p);bt(w,17,()=>l(Y),ft,(y,x)=>{var g=Er(),M=t(g);r(g);var f={};q(()=>{F(M,`${l(x).name??""} (${l(x).parameters??""})`),f!==(f=l(x).id)&&(g.value=(g.__value=l(x).id)??"")}),d(y,g)}),d(n,p)};c(v,n=>{a.model_type==="text"?n(b):n(k,!1)},!0)}d(s,o)};c(At,s=>{l(me)?s(Bt):s(Ct,!1)})}r(_e);var Ma=e(_e,2);{var Rt=s=>{var o=Tr(),v=t(o);r(o),q(()=>F(v,`‚ö†Ô∏è Using fallback models: ${l(xe)??""}`)),d(s,o)};c(Ma,s=>{l(xe)&&s(Rt)})}var Aa=e(Ma,2);{var Et=s=>{var o=jr();d(s,o)};c(Aa,s=>{a.model_type==="vision"&&s(Et)})}var Tt=e(Aa,2);{var jt=s=>{var o=Fr(),v=t(o),b=t(v),k=t(b),n=t(k);r(k);var p=e(k,2),w=t(p,!0);r(p);var y=e(p,2);{var x=f=>{var L=Nr(),E=t(L),j=e(t(E));r(E);var N=e(E,2);{var P=B=>{var Q=Or(),V=e(t(Q));r(Q),q(U=>F(V,` ${U??""}
                              tokens`),[()=>l(C).capabilities.context_window.toLocaleString()]),d(B,Q)};c(N,B=>{l(C).capabilities?.context_window&&B(P)})}r(L),q(()=>F(j,` ${l(C).requirements.min_vram_gb??""}GB
                            minimum,
                            ${l(C).requirements.recommended_vram_gb??""}GB recommended`)),d(f,L)};c(y,f=>{l(C).requirements&&f(x)})}var g=e(y,2);{var M=f=>{var L=zr(),E=e(t(L));r(L),q(j=>F(E,` ${j??""}`),[()=>l(C).recommended_for.join(", ")]),d(f,L)};c(g,f=>{l(C).recommended_for&&l(C).recommended_for.length>0&&f(M)})}r(b),r(v),r(o),q(()=>{F(n,`üìä ${l(C).name??""}`),F(w,l(C).description)}),d(s,o)};c(Tt,s=>{l(C)&&!l(me)&&s(jt)})}r(Ee);var Te=e(Ee,2),ge=e(t(Te),2);_(ge);var je=e(ge,2),Ba=t(je);_(Ba),i(2),r(je);var Ca=e(je,2),Ot=t(Ca);{var Nt=s=>{var o=Pr();i(2),d(s,o)},zt=s=>{var o=pe(),v=D(o);{var b=n=>{var p=H(`Path to your JSONL dataset with image paths/base64 or local
                  file`);d(n,p)},k=n=>{var p=H("Path to your JSONL dataset file");d(n,p)};c(v,n=>{a.model_type==="vision"?n(b):n(k,!1)},!0)}d(s,o)};c(Ot,s=>{a.from_hub?s(Nt):s(zt,!1)})}r(Ca),r(Te);var Oe=e(Te,2),be=e(t(Oe),2);_(be);var Ne=e(be,2),Ra=t(Ne);_(Ra),i(2),r(Ne);var Ea=e(Ne,2),Ft=e(t(Ea),3);{var Pt=s=>{var o=H(`Use HuggingFace format: "username/repo" or
                  "username/repo::validation.jsonl"`);d(s,o)};c(Ft,s=>{a.validation_from_hub&&s(Pt)})}r(Ea),r(Oe);var Ta=e(Oe,2);{var qt=s=>{var o=Vr(),v=e(t(o),2);{var b=n=>{var p=qr(),w=e(D(p),2),y=t(w);y.textContent='{"messages": [{"role": "user", "content": [{"type": "image", "image": "data:image/jpeg;base64,..."}, {"type": "text", "text": "What is shown?"}]}]}',r(w),i(2),d(n,p)},k=n=>{var p=Qr(),w=e(D(p),2),y=t(w);y.textContent='{"text": "What is in this image?", "image": "/path/to/image.jpg", "response": "A cat sitting on a table"}',r(w),i(2),d(n,p)};c(v,n=>{a.from_hub?n(b):n(k,!1)})}r(o),d(s,o)};c(Ta,s=>{a.model_type==="vision"&&s(qt)})}var ja=e(Ta,2),Oa=e(t(ja),2);_(Oa),r(ja),r(ka),r(Le);var ze=e(Le,2),Fe=t(ze),Qt=e(t(Fe),2);{var Vt=s=>{var o=Ur();d(s,o)};c(Qt,s=>{l(C)?.training_defaults&&s(Vt)})}r(Fe);var Na=e(Fe,2);{var Ut=s=>{var o=$r();d(s,o)};c(Na,s=>{a.model_type==="vision"&&s(Ut)})}var Pe=e(Na,2),za=e(t(Pe),2),qe=t(za),Qe=e(t(qe),2);_(Qe);var Fa=e(Qe,2),$t=t(Fa);{var Gt=s=>{var o=H(`2e-5 recommended for
                    vision models`);d(s,o)},Jt=s=>{var o=H("2e-4 typical for text models");d(s,o)};c($t,s=>{a.model_type==="vision"?s(Gt):s(Jt,!1)})}r(Fa),r(qe);var Ve=e(qe,2),Pa=e(t(Ve),2);_(Pa),i(2),r(Ve);var Ue=e(Ve,2),$e=e(t(Ue),2);_($e);var qa=e($e,2),Ht=t(qa);{var Dt=s=>{var o=H("Use 1 for vision models");d(s,o)},It=s=>{var o=H(`2-4
                    typical for text models`);d(s,o)};c(Ht,s=>{a.model_type==="vision"?s(Dt):s(It,!1)})}r(qa),r(Ue);var Ge=e(Ue,2),Qa=e(t(Ge),2);_(Qa),i(2),r(Ge);var Je=e(Ge,2),Va=e(t(Je),2);_(Va),i(2),r(Je);var Ua=e(Je,2),He=e(t(Ua),2),De=t(He);De.value=De.__value="adamw_8bit";var Ie=e(De);Ie.value=Ie.__value="adamw_torch";var We=e(Ie);We.value=We.__value="adamw_torch_fused";var Ke=e(We);Ke.value=Ke.__value="adafactor";var $a=e(Ke);$a.value=$a.__value="sgd",r(He),i(2),r(Ua),r(za),r(Pe);var Ye=e(Pe,2),Ga=e(t(Ye),2),Xe=t(Ga),Ja=e(t(Xe),2);_(Ja),i(2),r(Xe);var Ze=e(Xe,2),Ha=e(t(Ze),2);_(Ha),i(2),r(Ze);var Da=e(Ze,2),Ia=e(t(Da),2);_(Ia),i(2),r(Da),r(Ga),r(Ye);var Wa=e(Ye,2);{var Wt=s=>{var o=Gr(),v=e(t(o),2),b=t(v),k=e(t(b),2),n=t(k);n.value=n.__value="steps";var p=e(n);p.value=p.__value="epoch";var w=e(p);w.value=w.__value="no",r(k),r(b);var y=e(b,2),x=e(t(y),2);_(x),i(2),r(y);var g=e(y,2),M=e(t(g),2),f=t(M);f.value=f.__value="eval_loss";var L=e(f);L.value=L.__value="eval_accuracy";var E=e(L);E.value=E.__value="eval_f1",r(M),r(g);var j=e(g,2),N=t(j),P=t(N);_(P),i(2),r(N),i(2),r(j),r(v),r(o),I(k,()=>a.hyperparameters.eval_strategy,B=>a.hyperparameters.eval_strategy=B),h(x,()=>a.hyperparameters.eval_steps,B=>a.hyperparameters.eval_steps=B),I(M,()=>a.hyperparameters.metric_for_best_model,B=>a.hyperparameters.metric_for_best_model=B),ie(P,()=>a.hyperparameters.load_best_model_at_end,B=>a.hyperparameters.load_best_model_at_end=B),d(s,o)};c(Wa,s=>{a.validation_dataset_path&&s(Wt)})}var ea=e(Wa,2),aa=t(ea);aa.__click=[Jr,he];var Ka=t(aa),Kt=t(Ka,!0);r(Ka),i(),r(aa),r(ea);var Yt=e(ea,2);{var Xt=s=>{var o=Hr(),v=e(t(o),2),b=t(v),k=e(t(b),2);_(k),i(2),r(b);var n=e(b,2),p=e(t(n),2),w=t(p);w.value=w.__value="linear";var y=e(w);y.value=y.__value="cosine";var x=e(y);x.value=x.__value="constant";var g=e(x);g.value=g.__value="constant_with_warmup";var M=e(g);M.value=M.__value="polynomial",r(p),i(2),r(n);var f=e(n,2),L=e(t(f),2);_(L),i(2),r(f);var E=e(f,2),j=e(t(E),2);_(j),i(2),r(E),r(v);var N=e(v,4),P=t(N),B=e(t(P),2);_(B),i(2),r(P);var Q=e(P,2),V=e(t(Q),2);_(V),i(2),r(Q);var U=e(Q,2),$=e(t(U),2);_($),i(2),r(U),r(N);var G=e(N,4),Z=t(G),J=e(t(Z),2);_(J),i(2),r(Z);var re=e(Z,2),se=t(re),oe=t(se);_(oe),i(2),r(se),i(2),r(re),r(G),r(o),h(k,()=>a.hyperparameters.weight_decay,u=>a.hyperparameters.weight_decay=u),I(p,()=>a.hyperparameters.lr_scheduler_type,u=>a.hyperparameters.lr_scheduler_type=u),h(L,()=>a.hyperparameters.warmup_steps,u=>a.hyperparameters.warmup_steps=u),h(j,()=>a.hyperparameters.max_grad_norm,u=>a.hyperparameters.max_grad_norm=u),h(B,()=>a.hyperparameters.adam_beta1,u=>a.hyperparameters.adam_beta1=u),h(V,()=>a.hyperparameters.adam_beta2,u=>a.hyperparameters.adam_beta2=u),h($,()=>a.hyperparameters.adam_epsilon,u=>a.hyperparameters.adam_epsilon=u),h(J,()=>a.hyperparameters.dataloader_num_workers,u=>a.hyperparameters.dataloader_num_workers=u),ie(oe,()=>a.hyperparameters.dataloader_pin_memory,u=>a.hyperparameters.dataloader_pin_memory=u),d(s,o)};c(Yt,s=>{l(he)&&s(Xt)})}r(ze);var ta=e(ze,2),ra=t(ta),Zt=e(t(ra),2);{var er=s=>{var o=Dr();d(s,o)};c(Zt,s=>{l(C)?.training_defaults?.lora_config&&s(er)})}r(ra);var sa=e(ra,2),oa=t(sa),Ya=e(t(oa),2);_(Ya),i(2),r(oa);var ia=e(oa,2),Xa=e(t(ia),2);_(Xa),i(2),r(ia);var Za=e(ia,2),et=e(t(Za),2);_(et),i(2),r(Za),r(sa);var la=e(sa,2),da=t(la);da.__click=[Ir,ke];var at=t(da),ar=t(at,!0);r(at),i(),r(da),r(la);var tr=e(la,2);{var rr=s=>{var o=Kr(),v=t(o),b=t(v),k=e(t(b),2),n=t(k);n.value=n.__value="none";var p=e(n);p.value=p.__value="all";var w=e(p);w.value=w.__value="lora_only",r(k),i(2),r(b);var y=e(b,2),x=e(t(y),2),g=t(x);g.value=g.__value="unsloth";var M=e(g);M.value=M.__value="true";var f=e(M);f.value=f.__value="false",r(x),i(2),r(y),r(v);var L=e(v,2),E=t(L),j=t(E),N=t(j);_(N),i(2),r(j),i(2),r(E);var P=e(E,2),B=e(t(P),2);_(B),i(2),r(P),r(L);var Q=e(L,2),V=t(Q),U=e(t(V),2),$=t(U);$.value=$.__value="CAUSAL_LM";var G=e($);G.value=G.__value="SEQ_2_SEQ_LM";var Z=e(G);Z.value=Z.__value="TOKEN_CLS";var J=e(Z);J.value=J.__value="SEQ_CLS";var re=e(J);re.value=re.__value="QUESTION_ANS",r(U),i(2),r(V);var se=e(V,2),oe=e(t(se),2);_(oe),oe.__input=[Wr,a],i(2),r(se),r(Q),i(2),r(o),q(u=>xr(oe,u),[()=>a.lora_config.target_modules?.join(", ")||""]),I(k,()=>a.lora_config.lora_bias,u=>a.lora_config.lora_bias=u),I(x,()=>a.lora_config.use_gradient_checkpointing,u=>a.lora_config.use_gradient_checkpointing=u),ie(N,()=>a.lora_config.use_rslora,u=>a.lora_config.use_rslora=u),h(B,()=>a.lora_config.random_state,u=>a.lora_config.random_state=u),I(U,()=>a.lora_config.task_type,u=>a.lora_config.task_type=u),d(s,o)};c(tr,s=>{l(ke)&&s(rr)})}r(ta);var na=e(ta,2),tt=e(t(na),2),fe=e(t(tt),2),pa=t(fe);pa.value=pa.__value="merged_16bit";var ma=e(pa);ma.value=ma.__value="merged_4bit";var rt=e(ma);rt.value=rt.__value="lora",r(fe);var st=e(fe,2),ot=t(st),sr=t(ot);{var or=s=>{var o=Yr();i(),d(s,o)},ir=s=>{var o=pe(),v=D(o);{var b=n=>{var p=Xr();i(),d(n,p)},k=n=>{var p=Zr();i(),d(n,p)};c(v,n=>{a.save_method==="merged_4bit"?n(b):n(k,!1)},!0)}d(s,o)};c(sr,s=>{a.save_method==="merged_16bit"?s(or):s(ir,!1)})}r(ot),r(st),r(tt),r(na);var it=e(na,2);{var lr=s=>{var o=ls(),v=e(t(o),4),b=t(v),k=t(b),n=t(k);_(n),i(2),r(k),i(2),r(b);var p=e(b,2);{var w=y=>{var x=is(),g=t(x),M=e(t(g),2),f=t(M);f.value=f.__value="conservative";var L=e(f);L.value=L.__value="moderate";var E=e(L);E.value=E.__value="aggressive",r(M);var j=e(M,2),N=t(j),P=t(N);{var B=S=>{var z=es(),ee=e(D(z),2);ee.textContent='{, }, [, ], :, ,, "',i(2),d(S,z)},Q=S=>{var z=pe(),ee=D(z);{var ce=ne=>{var ca=as();i(3),d(ne,ca)},vr=ne=>{var ca=ts();i(),d(ne,ca)};c(ee,ne=>{a.selective_loss_level==="moderate"?ne(ce):ne(vr,!1)},!0)}d(S,z)};c(P,S=>{a.selective_loss_level==="conservative"?S(B):S(Q,!1)})}r(N),r(j),r(g);var V=e(g,2);{var U=S=>{var z=rs(),ee=e(t(z),2);_(ee),i(4),r(z),h(ee,()=>a.selective_loss_schema_keys,ce=>a.selective_loss_schema_keys=ce),d(S,z)};c(V,S=>{a.selective_loss_level==="aggressive"&&S(U)})}var $=e(V,2),G=t($),Z=t(G);r(G);var J=e(G,2);_(J);var re=e(J,4),se=t(re),oe=e(t(se),2);{var u=S=>{var z=ss();i(),d(S,z)},nr=S=>{var z=os(),ee=e(D(z)),ce=t(ee);r(ee),q(()=>F(ce,`Currently: Model learns structure for ${a.selective_loss_masking_start_step??""}
                            steps, then masking begins`)),d(S,z)};c(oe,S=>{a.selective_loss_masking_start_step===0?S(u):S(nr,!1)})}r(se),r(re),r($);var va=e($,2),nt=t(va),pt=t(nt);_(pt),i(2),r(nt),i(2),r(va);var mt=e(va,2),_a=e(t(mt),2),vt=t(_a),pr=e(t(vt));pr.textContent="{ } [ ] : ,",i(),r(vt),i(8),r(_a);var _t=e(_a,2),ct=e(t(_t),2);ct.textContent='{"name": "John", "age": 30}';var mr=e(ct,2);mr.textContent='{ } : , "',i(2),r(_t),r(mt),r(x),q(()=>F(Z,`Masking Start Step: ${a.selective_loss_masking_start_step??""}`)),I(M,()=>a.selective_loss_level,S=>a.selective_loss_level=S),h(J,()=>a.selective_loss_masking_start_step,S=>a.selective_loss_masking_start_step=S),ie(pt,()=>a.selective_loss_verbose,S=>a.selective_loss_verbose=S),d(y,x)};c(p,y=>{a.selective_loss&&y(w)})}r(v),r(o),ie(n,()=>a.selective_loss,y=>a.selective_loss=y),d(s,o)};c(it,s=>{a.model_type==="vision"&&s(lr)})}var lt=e(it,2),dt=t(lt);ba(dt,{type:"submit",variant:"primary",get loading(){return l(W)},get disabled(){return l(W)},children:(s,o)=>{i();var v=H();q(()=>F(v,l(W)?"Creating...":"Start Training")),d(s,v)},$$slots:{default:!0}});var dr=e(dt,2);ba(dr,{href:"/training",variant:"secondary",children:(s,o)=>{i();var v=H("Cancel");d(s,v)},$$slots:{default:!0}}),r(lt),r(X),q(()=>{ye(ve,1,`p-4 border-2 rounded-lg text-left transition-all ${a.model_type==="text"?"border-primary-500 bg-primary-50":"border-gray-300 hover:border-gray-400"}`),ye(Ae,1,`w-4 h-4 rounded-full border-2 ${a.model_type==="text"?"border-primary-500 bg-primary-500":"border-gray-400"}`),ye(ue,1,`p-4 border-2 rounded-lg text-left transition-all ${a.model_type==="vision"?"border-primary-500 bg-primary-50":"border-gray-300 hover:border-gray-400"}`),ye(Be,1,`w-4 h-4 rounded-full border-2 ${a.model_type==="vision"?"border-primary-500 bg-primary-500":"border-gray-400"}`),_e.disabled=l(me),gt(ge,"placeholder",a.from_hub?"username/dataset-name":a.model_type==="vision"?"./data/vision_dataset.jsonl":"./data/my-dataset.jsonl"),gt(be,"placeholder",a.validation_from_hub?"username/val-dataset-name":a.model_type==="vision"?"./data/vision_val_dataset.jsonl":"./data/my-val-dataset.jsonl"),F(Kt,l(he)?"‚ñº":"‚ñ∂"),F(ar,l(ke)?"‚ñº":"‚ñ∂")}),yr("submit",X,yt),h(Re,()=>a.name,s=>a.name=s),I(_e,()=>a.base_model,s=>a.base_model=s),h(ge,()=>a.dataset_path,s=>a.dataset_path=s),ie(Ba,()=>a.from_hub,s=>a.from_hub=s),h(be,()=>a.validation_dataset_path,s=>a.validation_dataset_path=s),ie(Ra,()=>a.validation_from_hub,s=>a.validation_from_hub=s),h(Oa,()=>a.output_dir,s=>a.output_dir=s),h(Qe,()=>a.hyperparameters.learning_rate,s=>a.hyperparameters.learning_rate=s),h(Pa,()=>a.hyperparameters.num_epochs,s=>a.hyperparameters.num_epochs=s),h($e,()=>a.hyperparameters.batch_size,s=>a.hyperparameters.batch_size=s),h(Qa,()=>a.hyperparameters.gradient_accumulation_steps,s=>a.hyperparameters.gradient_accumulation_steps=s),h(Va,()=>a.hyperparameters.max_steps,s=>a.hyperparameters.max_steps=s),I(He,()=>a.hyperparameters.optim,s=>a.hyperparameters.optim=s),h(Ja,()=>a.hyperparameters.logging_steps,s=>a.hyperparameters.logging_steps=s),h(Ha,()=>a.hyperparameters.save_steps,s=>a.hyperparameters.save_steps=s),h(Ia,()=>a.hyperparameters.save_total_limit,s=>a.hyperparameters.save_total_limit=s),h(Ya,()=>a.lora_config.r,s=>a.lora_config.r=s),h(Xa,()=>a.lora_config.lora_alpha,s=>a.lora_config.lora_alpha=s),h(et,()=>a.lora_config.lora_dropout,s=>a.lora_config.lora_dropout=s),I(fe,()=>a.save_method,s=>a.save_method=s),d(O,X)},$$slots:{default:!0}}),r(ha),r(we),d(te,we),br()}_r(["click","input"]);export{ys as component};
