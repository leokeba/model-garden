import"../chunks/DsnmJJEf.js";import{q as Br,p as Cr,a as Bt,s as le,o as Er,E as Ct,i as n,d as T,f as m,h as Tr,b as l,c as zr,$ as jr,t as ee,e as a,g as t,l as H,w as Or,n as i,r,m as O,j as be,k as X}from"../chunks/D_fozEd9.js";import{i as c}from"../chunks/C2ngLJft.js";import{r as p,s as Be,a as Ta,b as Vr,e as za,i as ja}from"../chunks/489nzvkF.js";import{b,c as V}from"../chunks/aZwOC-1j.js";import{b as te}from"../chunks/DV7skBy0.js";import{g as Nr}from"../chunks/B0bYBD0L.js";import{a as Et}from"../chunks/GrWgsx-T.js";import{B as Tt,C as Qr}from"../chunks/DWJusdRQ.js";var Fr=m('<div class="p-4 bg-red-50 border border-red-200 rounded-lg"><p class="text-red-700"> </p></div>'),Pr=(ne,N)=>N.model_type="text",Dr=m('<div class="w-full h-full rounded-full bg-white scale-50"></div>'),Ur=(ne,N)=>N.model_type="vision",$r=m('<div class="w-full h-full rounded-full bg-white scale-50"></div>'),Gr=m("<option>Loading models...</option>"),Jr=m("<option> </option>"),Hr=m("<option> </option>"),Ir=m('<p class="text-xs text-yellow-600 mt-1"> </p>'),Wr=m('<p class="text-xs text-gray-500 mt-1">üé® Vision-language models can analyze images and text together</p>'),Kr=m('<p class="text-xs text-blue-700"><strong>Context:</strong> </p>'),Yr=m('<div class="space-y-1"><p class="text-xs text-blue-700"><strong>VRAM:</strong> </p> <!></div>'),Xr=m('<p class="text-xs text-blue-700 mt-2"><strong>Best for:</strong> </p>'),Zr=m('<div class="mt-3 p-3 bg-blue-50 border border-blue-200 rounded-lg"><div class="flex items-start justify-between"><div class="flex-1"><h4 class="text-sm font-semibold text-blue-900 mb-1"> </h4> <p class="text-xs text-blue-800 mb-2"> </p> <!> <!></div></div></div>'),es=m(`Enter a HuggingFace dataset identifier (e.g.,
                  "username/dataset-name")<br/> For specific files, use: "username/repo::train.jsonl"`,1),ts=m(`<p class="text-sm text-blue-800 mb-2">HuggingFace datasets should use OpenAI messages format with
                    base64 images:</p> <pre class="text-xs bg-blue-100 p-2 rounded overflow-x-auto"><code></code></pre> <p class="text-xs text-blue-700 mt-2"><strong>Example:</strong> <code>Barth371/train_pop_valet_no_wrong_doc</code></p>`,1),as=m(`<p class="text-sm text-blue-800 mb-2">Your dataset should be in JSONL format with:</p> <pre class="text-xs bg-blue-100 p-2 rounded overflow-x-auto"><code></code></pre> <p class="text-xs text-blue-700 mt-2"><strong>Tip:</strong> Use <code>model-garden create-vision-dataset</code> CLI to generate
                    sample data</p>`,1),rs=m('<div class="p-4 bg-blue-50 border border-blue-200 rounded-lg"><h4 class="text-sm font-semibold text-blue-900 mb-2">üìã Vision Dataset Format</h4> <!></div>'),ss=m('<span class="text-xs text-green-600 bg-green-50 px-2 py-1 rounded">‚úì Using registry defaults</span>'),is=m(`<div class="mb-4 p-3 bg-yellow-50 border border-yellow-200 rounded-lg"><p class="text-sm text-yellow-800">‚ö†Ô∏è <strong>Vision models require:</strong> Lower batch size (1-2),
                higher gradient accumulation (8+), and lower learning rate (2e-5)</p></div>`),os=m(`<div class="ml-6 space-y-4 p-4 bg-white border border-gray-200 rounded-lg"><div><label for="early_stopping_patience" class="block text-sm font-medium text-gray-700 mb-1">Patience (evaluations)</label> <input type="number" id="early_stopping_patience" min="1" max="20" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Number of evaluations with no improvement before
                        stopping (3-5 typical)</p></div> <div><label for="early_stopping_threshold" class="block text-sm font-medium text-gray-700 mb-1">Improvement Threshold</label> <input type="number" id="early_stopping_threshold" min="0" step="0.0001" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Minimum change to qualify as improvement (0.0001 =
                        0.01%, smaller = more sensitive)</p></div> <div class="p-3 bg-green-50 border border-green-200 rounded-lg"><p class="text-xs text-green-800"><strong>üí° Example:</strong> With patience=3 and threshold=0.0001,
                        training stops if validation loss doesn't improve by at least
                        0.01% for 3 consecutive evaluations.</p></div></div>`),ls=m(`<div class="mb-6"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üìä Evaluation Settings</h4> <div class="grid grid-cols-2 gap-4"><div><label for="eval_strategy" class="block text-sm font-medium text-gray-700 mb-1">Evaluation Strategy</label> <select id="eval_strategy" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Every N steps</option><option>Every epoch</option><option>No evaluation</option></select></div> <div><label for="eval_steps" class="block text-sm font-medium text-gray-700 mb-1">Evaluation Steps</label> <input type="number" id="eval_steps" placeholder="Auto (same as save_steps)" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Evaluate every N steps (leave empty for auto)</p></div> <div><label for="metric_for_best_model" class="block text-sm font-medium text-gray-700 mb-1">Best Model Metric</label> <select id="metric_for_best_model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Validation Loss (lower is better)</option><option>Accuracy (higher is better)</option><option>F1 Score (higher is better)</option></select></div> <div><div class="flex items-center mt-6"><input type="checkbox" id="load_best_model_at_end" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="load_best_model_at_end" class="ml-2 block text-sm text-gray-700">Load best model at end</label></div> <p class="text-xs text-gray-500 mt-1">Automatically load checkpoint with best validation metric</p></div></div></div> <div class="mb-6"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">‚è∏Ô∏è Automatic Early Stopping</h4> <div class="p-4 bg-blue-50 border border-blue-200 rounded-lg mb-4"><p class="text-sm text-blue-800 mb-2"><strong>Automatic Early Stopping:</strong> Stops training when
                  validation loss stops improving, preventing overfitting and saving
                  compute time.</p> <p class="text-xs text-blue-700">This is different from the manual "Stop Early" button on the
                  training page. This monitors validation metrics and stops
                  automatically.</p></div> <div class="space-y-4"><div><div class="flex items-center"><input type="checkbox" id="early_stopping_enabled" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="early_stopping_enabled" class="ml-2 block text-sm font-medium text-gray-700">Enable Automatic Early Stopping</label></div> <p class="text-xs text-gray-500 mt-1 ml-6">Monitor validation loss and stop when it stops improving</p></div> <!></div></div>`,1),ns=(ne,N)=>T(N,!n(N)),ds=m('<div class="mb-6 p-4 bg-gray-50 border border-gray-200 rounded-lg"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">‚öôÔ∏è Optimizer Settings</h4> <div class="grid grid-cols-2 gap-4 mb-6"><div><label for="weight_decay" class="block text-sm font-medium text-gray-700 mb-1">Weight Decay</label> <input type="number" id="weight_decay" step="0.001" min="0" max="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">L2 regularization strength (0.01 typical)</p></div> <div><label for="lr_scheduler_type" class="block text-sm font-medium text-gray-700 mb-1">LR Scheduler</label> <select id="lr_scheduler_type" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Linear (default)</option><option>Cosine (good for vision)</option><option>Constant</option><option>Constant with Warmup</option><option>Polynomial</option></select> <p class="text-xs text-gray-500 mt-1">Learning rate schedule type</p></div> <div><label for="warmup_steps" class="block text-sm font-medium text-gray-700 mb-1">Warmup Steps</label> <input type="number" id="warmup_steps" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Steps to warmup learning rate from 0</p></div> <div><label for="max_grad_norm" class="block text-sm font-medium text-gray-700 mb-1">Max Gradient Norm</label> <input type="number" id="max_grad_norm" step="0.1" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Gradient clipping threshold (1.0 standard)</p></div></div> <h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üéõÔ∏è Adam Optimizer Parameters</h4> <div class="grid grid-cols-3 gap-4 mb-6"><div><label for="adam_beta1" class="block text-sm font-medium text-gray-700 mb-1">Adam Beta1</label> <input type="number" id="adam_beta1" step="0.01" min="0" max="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Exponential decay rate for 1st moment (0.9 default)</p></div> <div><label for="adam_beta2" class="block text-sm font-medium text-gray-700 mb-1">Adam Beta2</label> <input type="number" id="adam_beta2" step="0.001" min="0" max="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Exponential decay rate for 2nd moment (0.999 default)</p></div> <div><label for="adam_epsilon" class="block text-sm font-medium text-gray-700 mb-1">Adam Epsilon</label> <input type="number" id="adam_epsilon" step="1e-9" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Small constant for numerical stability (1e-8 default)</p></div></div> <h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üîÑ Data Loading Settings</h4> <div class="grid grid-cols-2 gap-4"><div><label for="dataloader_num_workers" class="block text-sm font-medium text-gray-700 mb-1">Dataloader Workers</label> <input type="number" id="dataloader_num_workers" min="0" max="16" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Number of worker processes (0 = main process only)</p></div> <div><div class="flex items-center mt-6"><input type="checkbox" id="dataloader_pin_memory" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="dataloader_pin_memory" class="ml-2 block text-sm text-gray-700">Pin memory to GPU</label></div> <p class="text-xs text-gray-500 mt-1">Faster data transfer to GPU (recommended)</p></div></div></div>'),ps=m('<div class="text-xs text-gray-600 bg-blue-50 border border-blue-100 rounded px-3 py-2">‚ÑπÔ∏è Using default 4-bit quantization (most memory efficient)</div>'),ms=m('<span class="text-xs text-green-600 bg-green-50 px-2 py-1 rounded">‚úì Using registry defaults</span>'),vs=(ne,N)=>T(N,!n(N)),_s=(ne,N)=>{const e=ne.currentTarget.value.trim();e?N.lora_config.target_modules=e.split(",").map(ae=>ae.trim()).filter(ae=>ae.length>0):N.lora_config.target_modules=null},cs=m(`<div class="mb-4 p-4 bg-purple-50 border border-purple-200 rounded-lg"><h4 class="text-md font-medium text-purple-900 mb-3 flex items-center gap-2">üé® Selective Layer Fine-tuning (Vision Models)</h4> <p class="text-sm text-purple-800 mb-4">Control which parts of the vision-language model to train.
                    Disable layers you don't want to modify:</p> <div class="space-y-3"><div class="flex items-start gap-3"><input type="checkbox" id="finetune_vision_layers" class="h-4 w-4 mt-0.5 text-purple-600 focus:ring-purple-500 border-gray-300 rounded"/> <div class="flex-1"><label for="finetune_vision_layers" class="text-sm font-medium text-gray-700">Fine-tune Vision Encoder Layers</label> <p class="text-xs text-gray-500 mt-0.5">Train the image processing layers. Disable to freeze
                          vision encoder and only adapt language model.</p></div></div> <div class="flex items-start gap-3"><input type="checkbox" id="finetune_language_layers" class="h-4 w-4 mt-0.5 text-purple-600 focus:ring-purple-500 border-gray-300 rounded"/> <div class="flex-1"><label for="finetune_language_layers" class="text-sm font-medium text-gray-700">Fine-tune Language Model Layers</label> <p class="text-xs text-gray-500 mt-0.5">Train the text generation layers. Disable to freeze
                          language model and only adapt vision encoder.</p></div></div> <div class="flex items-start gap-3"><input type="checkbox" id="finetune_attention_modules" class="h-4 w-4 mt-0.5 text-purple-600 focus:ring-purple-500 border-gray-300 rounded"/> <div class="flex-1"><label for="finetune_attention_modules" class="text-sm font-medium text-gray-700">Fine-tune Attention Modules</label> <p class="text-xs text-gray-500 mt-0.5">Train attention layers (Q, K, V, O projections).
                          Disable for faster training with slightly lower
                          quality.</p></div></div> <div class="flex items-start gap-3"><input type="checkbox" id="finetune_mlp_modules" class="h-4 w-4 mt-0.5 text-purple-600 focus:ring-purple-500 border-gray-300 rounded"/> <div class="flex-1"><label for="finetune_mlp_modules" class="text-sm font-medium text-gray-700">Fine-tune MLP Modules</label> <p class="text-xs text-gray-500 mt-0.5">Train feed-forward layers (gate, up, down
                          projections). Disable for faster training with
                          slightly lower quality.</p></div></div></div> <div class="mt-4 p-3 bg-purple-100 border border-purple-300 rounded-lg"><p class="text-xs text-purple-900 font-medium mb-2">üí° Common Configurations:</p> <ul class="text-xs text-purple-800 space-y-1"><li><strong>All enabled (default):</strong> Full model fine-tuning
                        - best quality, slowest</li> <li><strong>Language only:</strong> Disable vision layers - adapt
                        text generation while keeping vision frozen</li> <li><strong>Vision only:</strong> Disable language layers - adapt
                        image understanding while keeping language frozen</li> <li><strong>Attention only:</strong> Disable MLPs - focus on
                        cross-modal attention mechanisms</li></ul></div></div>`),us=m(`<div class="p-4 bg-gray-50 border border-gray-200 rounded-lg"><div class="grid grid-cols-2 gap-4 mb-4"><div><label for="lora_bias" class="block text-sm font-medium text-gray-700 mb-1">LoRA Bias</label> <select id="lora_bias" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>None (default)</option><option>All bias terms</option><option>LoRA layers only</option></select> <p class="text-xs text-gray-500 mt-1">How to handle bias parameters in LoRA layers</p></div> <div><label for="use_gradient_checkpointing" class="block text-sm font-medium text-gray-700 mb-1">Gradient Checkpointing</label> <select id="use_gradient_checkpointing" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Unsloth (30% less VRAM, minor quality loss)</option><option>Standard (better quality)</option><option>Disabled (best quality, most VRAM)</option></select> <p class="text-xs text-gray-500 mt-1">Tradeoff between memory usage and training quality</p></div></div> <div class="grid grid-cols-2 gap-4 mb-4"><div><div class="flex items-center mt-2"><input type="checkbox" id="use_rslora" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="use_rslora" class="ml-2 block text-sm text-gray-700">Use RSLoRA (Rank-Stabilized LoRA)</label></div> <p class="text-xs text-gray-500 mt-1">Better stability for high ranks (r > 16)</p></div> <div><label for="random_state" class="block text-sm font-medium text-gray-700 mb-1">Random Seed</label> <input type="number" id="random_state" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Seed for reproducible results (42 is popular)</p></div></div> <div class="grid grid-cols-2 gap-4 mb-4"><div><label for="task_type" class="block text-sm font-medium text-gray-700 mb-1">Task Type</label> <select id="task_type" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Causal LM (Text Generation)</option><option>Sequence-to-Sequence</option><option>Token Classification</option><option>Sequence Classification</option><option>Question Answering</option></select> <p class="text-xs text-gray-500 mt-1">Type of task for PEFT optimization</p></div> <div><label for="target_modules_input" class="block text-sm font-medium text-gray-700 mb-1">Target Modules (Advanced)</label> <input type="text" id="target_modules_input" placeholder="q_proj, k_proj, v_proj (leave empty for auto)" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Comma-separated list of layers to apply LoRA (auto-detected
                    if empty)</p></div></div> <!> <div class="p-3 bg-blue-50 border border-blue-200 rounded-lg"><h4 class="text-sm font-semibold text-blue-900 mb-2">üí° LoRA Tips</h4> <ul class="text-xs text-blue-800 space-y-1"><li><strong>Rank (r):</strong> Start with 16, increase to 64+ for
                    complex tasks or large datasets</li> <li><strong>Alpha:</strong> Usually equal to rank. Higher alpha =
                    stronger adaptation</li> <li><strong>Dropout:</strong> Add 0.1-0.3 if overfitting, keep 0
                    for small datasets</li> <li><strong>RSLoRA:</strong> Enable for ranks > 16 to improve training
                    stability</li> <li><strong>Target Modules:</strong> Leave empty for auto-detection.
                    Common: "q_proj,k_proj,v_proj,o_proj" for attention layers</li> <li><strong>Task Type:</strong> Use "CAUSAL_LM" for text generation,
                    "SEQ_2_SEQ_LM" for translation/summarization</li></ul></div></div>`),gs=m(`<strong>‚úÖ Merged 16-bit (Recommended):</strong> Full model with
                  LoRA weights merged using Unsloth. Creates split files for vLLM
                  compatibility.`,1),bs=m(`<strong>üì¶ Merged 4-bit:</strong> Full model with LoRA weights
                  merged in 4-bit quantized format. Smaller file size.`,1),ys=m(`<strong>üîß LoRA Adapters Only (Advanced):</strong> Saves only the
                  adapter weights. Requires the base model to load.`,1),fs=m(`<strong>Conservative:</strong> Masks JSON structural
                          characters: <code></code> and
                          whitespace. Masks ~31% of tokens. <em>Recommended for most cases.</em>`,1),xs=m("<strong>Moderate:</strong> Conservative + masks <code>null</code> keyword. Good when null values are predictable.",1),hs=m(`<strong>Aggressive:</strong> Moderate + masks schema field
                          names. Maximum focus on semantic content. Requires specifying
                          schema keys below.`,1),ks=m(`<div><label for="selective_loss_schema_keys" class="block text-sm font-medium text-gray-700 mb-1">Schema Keys to Mask</label> <input type="text" id="selective_loss_schema_keys" placeholder="Marque,Modele,contents,confidence_score" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Comma-separated list of JSON field names to mask (e.g.,
                        "name,address,phone")</p> <div class="mt-2 p-2 bg-yellow-50 border border-yellow-200 rounded"><p class="text-xs text-yellow-800">‚ö†Ô∏è Only mask keys that are predictable and don't carry
                          semantic meaning. The model should still learn what
                          values go with each key.</p></div></div>`),ws=m(`<br/><em>Currently: Masking starts immediately (traditional
                            approach)</em>`,1),Ss=m("<br/><em> </em>",1),Ls=m(`<div class="ml-6 space-y-4 p-4 bg-white border border-gray-200 rounded-lg"><div><label for="selective_loss_level" class="block text-sm font-medium text-gray-700 mb-2">Masking Level</label> <select id="selective_loss_level" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Conservative (Structure Only)</option><option>Moderate (Structure + null)</option><option>Aggressive (Structure + null + Schema Keys)</option></select> <div class="mt-2 p-3 bg-gray-50 rounded-lg"><p class="text-xs text-gray-700"><!></p></div></div> <!> <div><label for="selective_loss_masking_start_step" class="block text-sm font-medium text-gray-700 mb-2"> </label> <input type="range" id="selective_loss_masking_start_step" min="0" max="500" step="10" class="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer accent-primary-500"/> <div class="flex justify-between text-xs text-gray-500 mt-1"><span>0 (Immediate)</span> <span>100</span> <span>200</span> <span>500 steps</span></div> <div class="mt-2 p-3 bg-blue-50 rounded-lg"><p class="text-xs text-blue-700"><strong>üí° Tip:</strong> Setting this to 50-200 lets the
                        model learn JSON structure first before applying
                        selective masking. This can prevent degeneration issues
                        with aggressive masking. <!></p></div></div> <div><div class="flex items-center"><input type="checkbox" id="selective_loss_verbose" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="selective_loss_verbose" class="ml-2 block text-sm text-gray-700">Verbose mode (print masking statistics)</label></div> <p class="text-xs text-gray-500 mt-1">Display detailed token masking stats during training</p></div> <div class="p-3 bg-blue-50 border border-blue-200 rounded-lg"><h4 class="text-sm font-semibold text-blue-900 mb-2">üìä What Gets Masked?</h4> <ul class="text-xs text-blue-800 space-y-1"><li>‚úì Structural: <code></code> and whitespace
                        (spaces, newlines, tabs)</li> <li>‚úì Quotes: <code>"</code> (string delimiters - purely structural)</li> <li>‚úì Null keyword: <code>null</code> (moderate/aggressive only)</li> <li>‚úó NOT masked: <code>true</code>, <code>false</code> (can
                        be semantic)</li> <li>‚úì Schema keys: Field names like <code>name</code> (aggressive
                        only)</li></ul> <p class="text-xs text-blue-700 mt-2"><strong>Example:</strong> In <code></code>, conservative
                      mode masks <code></code> and spaces (~31% of tokens),
                      trains on <code>name John age 30</code></p></div></div>`),Ms=m(`<div><h3 class="text-lg font-semibold text-gray-900 mb-4">üéØ Selective Loss (Structured Outputs)</h3> <div class="p-4 bg-gradient-to-r from-purple-50 to-blue-50 border border-purple-200 rounded-lg mb-4"><p class="text-sm text-gray-800 mb-2"><strong>üî¨ Experimental Feature:</strong> Optimize training for structured
                outputs (JSON, forms, etc.)</p> <p class="text-xs text-gray-700">Masks structural tokens (braces, colons, whitespace) so the
                model focuses on semantic content. Useful for form extraction,
                structured data generation, and similar tasks.</p></div> <div class="space-y-4"><div><div class="flex items-center"><input type="checkbox" id="selective_loss" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="selective_loss" class="ml-2 block text-sm font-medium text-gray-700">Enable Selective Loss Masking</label></div> <p class="text-xs text-gray-500 mt-1 ml-6">Automatically mask JSON structural tokens during training</p></div> <!></div></div>`),As=m(`<form class="space-y-6"><!> <div><h3 class="text-lg font-semibold text-gray-900 mb-4">Basic Configuration</h3> <div class="grid grid-cols-1 gap-4"><div><div class="block text-sm font-medium text-gray-700 mb-2">Model Type *</div> <div class="grid grid-cols-2 gap-3"><button type="button"><div class="flex items-center gap-2"><div><!></div> <span class="font-medium">Text-Only (LLM)</span></div> <p class="text-sm text-gray-600 mt-2 ml-6">Fine-tune language models for text generation tasks</p></button> <button type="button"><div class="flex items-center gap-2"><div><!></div> <span class="font-medium">Vision-Language (VLM)</span></div> <p class="text-sm text-gray-600 mt-2 ml-6">Fine-tune multimodal models for image + text tasks</p></button></div></div> <div><label for="name" class="block text-sm font-medium text-gray-700 mb-1">Model Name *</label> <input type="text" id="name" placeholder="my-finance-model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500" required/></div> <div><label for="base_model" class="block text-sm font-medium text-gray-700 mb-1">Base Model *</label> <select id="base_model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500" required><!></select> <!> <!> <!></div> <div><label for="dataset_path" class="block text-sm font-medium text-gray-700 mb-1">Dataset Path *</label> <input type="text" id="dataset_path" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500" required/> <div class="mt-2 flex items-center"><input type="checkbox" id="from_hub" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="from_hub" class="ml-2 block text-sm text-gray-700">Load from HuggingFace Hub</label></div> <p class="text-xs text-gray-500 mt-1"><!></p></div> <div><label for="validation_dataset_path" class="block text-sm font-medium text-gray-700 mb-1">Validation Dataset Path (Optional)</label> <input type="text" id="validation_dataset_path" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <div class="mt-2 flex items-center"><input type="checkbox" id="validation_from_hub" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="validation_from_hub" class="ml-2 block text-sm text-gray-700">Load validation dataset from HuggingFace Hub</label></div> <p class="text-xs text-gray-500 mt-1">üìä Optional: Provide a validation dataset to track validation
                loss during training<br/> <!></p></div> <!> <div><label for="output_dir" class="block text-sm font-medium text-gray-700 mb-1">Output Directory</label> <input type="text" id="output_dir" placeholder="my-model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="mt-1 text-sm text-gray-500"> </p></div></div></div> <div><div class="flex items-center justify-between mb-4"><h3 class="text-lg font-semibold text-gray-900">Training Hyperparameters</h3> <!></div> <!> <div class="mb-6"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üéØ Essential Parameters</h4> <div class="grid grid-cols-2 gap-4"><div><label for="learning_rate" class="block text-sm font-medium text-gray-700 mb-1">Learning Rate</label> <input type="number" id="learning_rate" step="0.00001" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1"><!></p></div> <div><label for="num_epochs" class="block text-sm font-medium text-gray-700 mb-1">Number of Epochs</label> <input type="number" id="num_epochs" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Number of complete passes through dataset</p></div> <div><label for="batch_size" class="block text-sm font-medium text-gray-700 mb-1">Batch Size per GPU</label> <input type="number" id="batch_size" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1"><!></p></div> <div><label for="gradient_accumulation" class="block text-sm font-medium text-gray-700 mb-1">Gradient Accumulation Steps</label> <input type="number" id="gradient_accumulation" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Effective batch size = batch_size √ó
                  gradient_accumulation_steps</p></div> <div><label for="max_steps" class="block text-sm font-medium text-gray-700 mb-1">Max Steps (Optional)</label> <input type="number" id="max_steps" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Override epochs with exact step count (-1 for full epochs)</p></div> <div><label for="optim" class="block text-sm font-medium text-gray-700 mb-1">Optimizer</label> <select id="optim" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>AdamW 8-bit (Memory Efficient)</option><option>AdamW (Better Quality)</option><option>AdamW Fused (Best Quality/Speed)</option><option>Adafactor (Most Memory Efficient)</option><option>SGD</option></select> <p class="text-xs text-gray-500 mt-1">8-bit saves memory, standard/fused offers better quality</p></div></div></div> <div class="mb-6"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üíæ Checkpoints & Logging</h4> <div class="grid grid-cols-3 gap-4"><div><label for="logging_steps" class="block text-sm font-medium text-gray-700 mb-1">Logging Steps</label> <input type="number" id="logging_steps" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Log metrics every N steps</p></div> <div><label for="save_steps" class="block text-sm font-medium text-gray-700 mb-1">Save Steps</label> <input type="number" id="save_steps" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Save checkpoint every N steps</p></div> <div><label for="save_total_limit" class="block text-sm font-medium text-gray-700 mb-1">Max Checkpoints</label> <input type="number" id="save_total_limit" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Keep only N most recent checkpoints</p></div></div></div> <!> <div class="mb-4"><button type="button" class="flex items-center gap-2 px-4 py-2 text-sm font-medium text-primary-700 bg-primary-50 border border-primary-200 rounded-lg hover:bg-primary-100 transition-colors"><span> </span> Advanced Hyperparameters</button></div> <!></div> <div><h3 class="text-lg font-semibold text-gray-900 mb-4 flex items-center gap-2">üéØ Quality Settings</h3> <div class="p-4 bg-blue-50 border border-blue-200 rounded-lg mb-4"><div class="flex items-start gap-3"><div class="flex-shrink-0"><svg class="w-5 h-5 text-blue-600 mt-0.5" fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M18 10a8 8 0 11-16 0 8 8 0 0116 0zm-7-4a1 1 0 11-2 0 1 1 0 012 0zM9 9a1 1 0 000 2v3a1 1 0 001 1h1a1 1 0 100-2v-3a1 1 0 00-1-1H9z" clip-rule="evenodd"></path></svg></div> <div class="flex-1"><p class="text-sm text-blue-800 font-medium mb-1">Quality vs Memory Tradeoff</p> <p class="text-xs text-blue-700">Default settings prioritize memory efficiency. Enable quality
                  mode or adjust individual settings for better accuracy at the
                  cost of 2-4x more VRAM.</p></div></div></div> <div class="space-y-4"><div class="p-4 bg-gradient-to-r from-purple-50 to-blue-50 border border-purple-200 rounded-lg"><div class="flex items-start justify-between"><div class="flex-1"><div class="flex items-center gap-3 mb-2"><input type="checkbox" id="quality_mode" class="h-5 w-5 text-purple-600 focus:ring-purple-500 border-gray-300 rounded"/> <label for="quality_mode" class="text-base font-semibold text-gray-900">üèÜ Quality Mode (Recommended for Production)</label></div> <p class="text-sm text-gray-700 ml-8">Automatically enables 16-bit precision, better optimizer,
                    and optimized settings for maximum accuracy.</p> <div class="mt-3 ml-8 p-3 bg-white border border-purple-100 rounded-lg"><p class="text-xs font-medium text-purple-900 mb-2">Quality mode includes:</p> <ul class="text-xs text-gray-600 space-y-1"><li>‚úì 16-bit precision (better than 4-bit)</li> <li>‚úì Standard gradient checkpointing (better than
                        "unsloth")</li> <li>‚úì AdamW optimizer (better than 8-bit version)</li> <li>‚úì RSLoRA for ranks ‚â• 32</li> <li>‚ö†Ô∏è Requires ~4x more VRAM</li></ul></div></div></div></div> <div class="p-4 bg-gray-50 border border-gray-200 rounded-lg"><h4 class="text-sm font-semibold text-gray-900 mb-3">Manual Precision Settings</h4> <p class="text-xs text-gray-600 mb-3">Override individual settings (quality mode will take precedence
                if enabled)</p> <div class="space-y-3"><div class="flex items-start gap-3"><input type="checkbox" id="load_in_16bit" class="h-4 w-4 mt-0.5 text-primary-600 focus:ring-primary-500 border-gray-300 rounded disabled:opacity-50"/> <div class="flex-1"><label for="load_in_16bit" class="text-sm font-medium text-gray-700">Load in 16-bit precision</label> <p class="text-xs text-gray-500 mt-0.5">Best quality, uses 4x more VRAM than 4-bit</p></div></div> <div class="flex items-start gap-3"><input type="checkbox" id="load_in_8bit" class="h-4 w-4 mt-0.5 text-primary-600 focus:ring-primary-500 border-gray-300 rounded disabled:opacity-50"/> <div class="flex-1"><label for="load_in_8bit" class="text-sm font-medium text-gray-700">Load in 8-bit precision</label> <p class="text-xs text-gray-500 mt-0.5">Balanced quality/memory, uses 2x more VRAM than 4-bit</p></div></div> <!></div></div></div></div> <div><div class="flex items-center justify-between mb-4"><h3 class="text-lg font-semibold text-gray-900">LoRA Configuration</h3> <!></div> <div class="grid grid-cols-3 gap-4 mb-4"><div><label for="lora_r" class="block text-sm font-medium text-gray-700 mb-1">LoRA Rank (r)</label> <input type="number" id="lora_r" min="1" max="256" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Higher = more parameters (16 typical, 64+ for complex tasks)</p></div> <div><label for="lora_alpha" class="block text-sm font-medium text-gray-700 mb-1">LoRA Alpha</label> <input type="number" id="lora_alpha" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Scaling factor (typically equal to rank)</p></div> <div><label for="lora_dropout" class="block text-sm font-medium text-gray-700 mb-1">LoRA Dropout</label> <input type="number" id="lora_dropout" min="0" max="0.5" step="0.05" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Regularization (0.0-0.3, 0 = no dropout)</p></div></div> <div class="mb-4"><button type="button" class="flex items-center gap-2 px-4 py-2 text-sm font-medium text-primary-700 bg-primary-50 border border-primary-200 rounded-lg hover:bg-primary-100 transition-colors"><span> </span> Advanced LoRA Settings</button></div> <!></div> <div><h3 class="text-lg font-semibold text-gray-900 mb-4">Model Save Options</h3> <div><label for="save_method" class="block text-sm font-medium text-gray-700 mb-2">Save Method</label> <select id="save_method" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Save Merged Model (16-bit) - Recommended</option><option>Save Merged Model (4-bit) - Smaller Size</option><option>Save LoRA Adapters Only - Advanced</option></select> <div class="mt-3 p-3 bg-blue-50 border border-blue-200 rounded-lg"><p class="text-sm text-blue-800"><!></p></div></div></div> <!> <div class="flex gap-4 pt-4"><!> <!></div></form>`),Rs=m('<div class="min-h-screen bg-gray-50"><div class="bg-white shadow"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex justify-between items-center py-6"><div class="flex items-center"><!> <h1 class="text-3xl font-bold text-gray-900 ml-4">New Training Job</h1></div></div></div></div> <div class="max-w-3xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><!></div></div>');function Ns(ne,N){Cr(N,!0);let e=Bt({name:"",model_type:"text",base_model:"unsloth/tinyllama-bnb-4bit",dataset_path:"./data/sample.jsonl",validation_dataset_path:"",output_dir:"",hyperparameters:{learning_rate:2e-5,num_epochs:3,batch_size:2,max_steps:-1,gradient_accumulation_steps:4,warmup_steps:10,logging_steps:10,save_steps:100,eval_steps:null,optim:"adamw_8bit",weight_decay:.01,lr_scheduler_type:"linear",max_grad_norm:1,adam_beta1:.9,adam_beta2:.999,adam_epsilon:1e-8,dataloader_num_workers:0,dataloader_pin_memory:!0,eval_strategy:"steps",load_best_model_at_end:!0,metric_for_best_model:"eval_loss",save_total_limit:3},lora_config:{r:16,lora_alpha:16,lora_dropout:0,lora_bias:"none",use_rslora:!1,use_gradient_checkpointing:"unsloth",random_state:42,target_modules:null,task_type:"CAUSAL_LM",loftq_config:null,finetune_vision_layers:!0,finetune_language_layers:!0,finetune_attention_modules:!0,finetune_mlp_modules:!0},from_hub:!1,validation_from_hub:!1,save_method:"merged_16bit",selective_loss:!1,selective_loss_level:"conservative",selective_loss_schema_keys:"",selective_loss_masking_start_step:0,selective_loss_verbose:!1,early_stopping_enabled:!1,early_stopping_patience:3,early_stopping_threshold:1e-4,quality_mode:!1,load_in_16bit:!1,load_in_8bit:!1}),ae=le(!1),de=le(""),re=le(Bt([])),se=le(Bt([])),C=le(null),ye=le(!0),Ce=le("");Er(async()=>{try{T(ye,!0);const[Q,E]=await Promise.all([Et.getRegistryModels("text-llm"),Et.getRegistryModels("vision-vlm")]);T(re,Q.models,!0),T(se,E.models,!0),e.model_type==="text"&&n(re).length>0?(T(C,n(re)[0],!0),e.base_model=n(re)[0].id):e.model_type==="vision"&&n(se).length>0&&(T(C,n(se)[0],!0),e.base_model=n(se)[0].id)}catch(Q){T(Ce,Q instanceof Error?Q.message:"Failed to load models from registry",!0),console.error("Failed to load registry models:",Q),T(re,[{id:"unsloth/tinyllama-bnb-4bit",name:"TinyLlama 1.1B (4-bit)",parameters:"1.1B"},{id:"unsloth/phi-2-bnb-4bit",name:"Phi-2 2.7B (4-bit)",parameters:"2.7B"},{id:"unsloth/mistral-7b-bnb-4bit",name:"Mistral 7B (4-bit)",parameters:"7B"},{id:"unsloth/llama-2-7b-bnb-4bit",name:"Llama 2 7B (4-bit)",parameters:"7B"},{id:"unsloth/llama-3-8b-bnb-4bit",name:"Llama 3 8B (4-bit)",parameters:"8B"}],!0),T(se,[{id:"Qwen/Qwen2.5-VL-3B-Instruct",name:"Qwen2.5-VL 3B",parameters:"3B"},{id:"Qwen/Qwen2.5-VL-7B-Instruct",name:"Qwen2.5-VL 7B",parameters:"7B"},{id:"Qwen/Qwen2.5-VL-72B-Instruct",name:"Qwen2.5-VL 72B",parameters:"72B"},{id:"unsloth/Qwen2.5-VL-3B-Instruct-bnb-4bit",name:"Qwen2.5-VL 3B (4-bit)",parameters:"3B"},{id:"unsloth/Qwen2.5-VL-7B-Instruct-bnb-4bit",name:"Qwen2.5-VL 7B (4-bit)",parameters:"7B"}],!0)}finally{T(ye,!1)}}),Ct(()=>{const Q=e.model_type==="vision"?n(se):n(re);if(T(C,Q.find(E=>E.id===e.base_model)||null,!0),n(C)?.training_defaults){const E=n(C).training_defaults;E.hyperparameters&&(e.hyperparameters={...e.hyperparameters,...E.hyperparameters}),E.lora_config&&(e.lora_config={...e.lora_config,...E.lora_config}),E.save_method&&(e.save_method=E.save_method)}}),Ct(()=>{e.model_type==="vision"?(n(se).length>0&&(e.base_model=n(se)[0].id),e.dataset_path="./data/vision_dataset.jsonl"):(n(re).length>0&&(e.base_model=n(re)[0].id),e.dataset_path="./data/sample.jsonl")});let Ee=le(!1),Te=le(!1);Ct(()=>{e.name&&(e.output_dir=e.name.toLowerCase().replace(/[^a-z0-9]/g,"-"))});async function Oa(Q){if(Q.preventDefault(),!e.name||!e.base_model||!e.dataset_path){T(de,"Please fill in all required fields");return}T(ae,!0),T(de,"");try{let E=null;e.selective_loss_schema_keys&&e.selective_loss_schema_keys.trim()&&(E=e.selective_loss_schema_keys.split(",").map(pe=>pe.trim()).filter(pe=>pe.length>0));const ie=await Et.createTrainingJob({...e,is_vision:e.model_type==="vision",selective_loss:e.selective_loss,selective_loss_level:e.selective_loss_level,selective_loss_schema_keys:E,selective_loss_masking_start_step:e.selective_loss_masking_start_step,selective_loss_verbose:e.selective_loss_verbose,early_stopping_enabled:e.early_stopping_enabled,early_stopping_patience:e.early_stopping_patience,early_stopping_threshold:e.early_stopping_threshold});ie.success?Nr(`/training/${ie.data.job_id}`):T(de,"Failed to create training job")}catch(E){T(de,E instanceof Error?E.message:"Failed to create training job",!0)}finally{T(ae,!1)}}var ze=Rs();Tr(Q=>{jr.title="New Training Job - Model Garden"});var je=a(ze),zt=a(je),jt=a(zt),Ot=a(jt),Va=a(Ot);Tt(Va,{href:"/training",variant:"ghost",size:"sm",children:(Q,E)=>{i();var ie=ee("‚Üê Training Jobs");l(Q,ie)},$$slots:{default:!0}}),i(2),r(Ot),r(jt),r(zt),r(je);var Vt=t(je,2),Na=a(Vt);Qr(Na,{children:(Q,E)=>{var ie=As(),pe=a(ie);{var Qa=s=>{var o=Fr(),_=a(o),y=a(_,!0);r(_),r(o),H(()=>O(y,n(de))),l(s,o)};c(pe,s=>{n(de)&&s(Qa)})}var Oe=t(pe,2),Nt=t(a(Oe),2),Ve=a(Nt),Qt=t(a(Ve),2),fe=a(Qt);fe.__click=[Pr,e];var Ft=a(fe),Ne=a(Ft),Fa=a(Ne);{var Pa=s=>{var o=Dr();l(s,o)};c(Fa,s=>{e.model_type==="text"&&s(Pa)})}r(Ne),i(2),r(Ft),i(2),r(fe);var Se=t(fe,2);Se.__click=[Ur,e];var Pt=a(Se),Qe=a(Pt),Da=a(Qe);{var Ua=s=>{var o=$r();l(s,o)};c(Da,s=>{e.model_type==="vision"&&s(Ua)})}r(Qe),i(2),r(Pt),i(2),r(Se),r(Qt),r(Ve);var Fe=t(Ve,2),Dt=t(a(Fe),2);p(Dt),r(Fe);var Pe=t(Fe,2),xe=t(a(Pe),2),$a=a(xe);{var Ga=s=>{var o=Gr();o.value=o.__value="",l(s,o)},Ja=s=>{var o=be(),_=X(o);{var y=d=>{var v=be(),w=X(v);za(w,17,()=>n(re),ja,(x,f)=>{var u=Jr(),q=a(u);r(u);var g={};H(()=>{O(q,`${n(f).name??""} (${n(f).parameters??""})`),g!==(g=n(f).id)&&(u.value=(u.__value=n(f).id)??"")}),l(x,u)}),l(d,v)},k=d=>{var v=be(),w=X(v);za(w,17,()=>n(se),ja,(x,f)=>{var u=Hr(),q=a(u);r(u);var g={};H(()=>{O(q,`${n(f).name??""} (${n(f).parameters??""})`),g!==(g=n(f).id)&&(u.value=(u.__value=n(f).id)??"")}),l(x,u)}),l(d,v)};c(_,d=>{e.model_type==="text"?d(y):d(k,!1)},!0)}l(s,o)};c($a,s=>{n(ye)?s(Ga):s(Ja,!1)})}r(xe);var Ut=t(xe,2);{var Ha=s=>{var o=Ir(),_=a(o);r(o),H(()=>O(_,`‚ö†Ô∏è Using fallback models: ${n(Ce)??""}`)),l(s,o)};c(Ut,s=>{n(Ce)&&s(Ha)})}var $t=t(Ut,2);{var Ia=s=>{var o=Wr();l(s,o)};c($t,s=>{e.model_type==="vision"&&s(Ia)})}var Wa=t($t,2);{var Ka=s=>{var o=Zr(),_=a(o),y=a(_),k=a(y),d=a(k);r(k);var v=t(k,2),w=a(v,!0);r(v);var x=t(v,2);{var f=g=>{var L=Yr(),B=a(L),j=t(a(B));r(B);var F=t(B,2);{var $=P=>{var z=Kr(),D=t(a(z));r(z),H(U=>O(D,` ${U??""}
                              tokens`),[()=>n(C).capabilities.context_window.toLocaleString()]),l(P,z)};c(F,P=>{n(C).capabilities?.context_window&&P($)})}r(L),H(()=>O(j,` ${n(C).requirements.min_vram_gb??""}GB
                            minimum,
                            ${n(C).requirements.recommended_vram_gb??""}GB recommended`)),l(g,L)};c(x,g=>{n(C).requirements&&g(f)})}var u=t(x,2);{var q=g=>{var L=Xr(),B=t(a(L));r(L),H(j=>O(B,` ${j??""}`),[()=>n(C).recommended_for.join(", ")]),l(g,L)};c(u,g=>{n(C).recommended_for&&n(C).recommended_for.length>0&&g(q)})}r(y),r(_),r(o),H(()=>{O(d,`üìä ${n(C).name??""}`),O(w,n(C).description)}),l(s,o)};c(Wa,s=>{n(C)&&!n(ye)&&s(Ka)})}r(Pe);var De=t(Pe,2),Le=t(a(De),2);p(Le);var Ue=t(Le,2),Gt=a(Ue);p(Gt),i(2),r(Ue);var Jt=t(Ue,2),Ya=a(Jt);{var Xa=s=>{var o=es();i(2),l(s,o)},Za=s=>{var o=be(),_=X(o);{var y=d=>{var v=ee(`Path to your JSONL dataset with image paths/base64 or local
                  file`);l(d,v)},k=d=>{var v=ee("Path to your JSONL dataset file");l(d,v)};c(_,d=>{e.model_type==="vision"?d(y):d(k,!1)},!0)}l(s,o)};c(Ya,s=>{e.from_hub?s(Xa):s(Za,!1)})}r(Jt),r(De);var $e=t(De,2),Me=t(a($e),2);p(Me);var Ge=t(Me,2),Ht=a(Ge);p(Ht),i(2),r(Ge);var It=t(Ge,2),er=t(a(It),3);{var tr=s=>{var o=ee(`Use HuggingFace format: "username/repo" or
                  "username/repo::validation.jsonl"`);l(s,o)};c(er,s=>{e.validation_from_hub&&s(tr)})}r(It),r($e);var Wt=t($e,2);{var ar=s=>{var o=rs(),_=t(a(o),2);{var y=d=>{var v=ts(),w=t(X(v),2),x=a(w);x.textContent='{"messages": [{"role": "user", "content": [{"type": "image", "image": "data:image/jpeg;base64,..."}, {"type": "text", "text": "What is shown?"}]}]}',r(w),i(2),l(d,v)},k=d=>{var v=as(),w=t(X(v),2),x=a(w);x.textContent='{"text": "What is in this image?", "image": "/path/to/image.jpg", "response": "A cat sitting on a table"}',r(w),i(2),l(d,v)};c(_,d=>{e.from_hub?d(y):d(k,!1)})}r(o),l(s,o)};c(Wt,s=>{e.model_type==="vision"&&s(ar)})}var Kt=t(Wt,2),Je=t(a(Kt),2);p(Je);var Yt=t(Je,2),rr=a(Yt);r(Yt),r(Kt),r(Nt),r(Oe);var He=t(Oe,2),Ie=a(He),sr=t(a(Ie),2);{var ir=s=>{var o=ss();l(s,o)};c(sr,s=>{n(C)?.training_defaults&&s(ir)})}r(Ie);var Xt=t(Ie,2);{var or=s=>{var o=is();l(s,o)};c(Xt,s=>{e.model_type==="vision"&&s(or)})}var We=t(Xt,2),Zt=t(a(We),2),Ke=a(Zt),Ye=t(a(Ke),2);p(Ye);var ea=t(Ye,2),lr=a(ea);{var nr=s=>{var o=ee(`2e-5 recommended for
                    vision models`);l(s,o)},dr=s=>{var o=ee("2e-4 typical for text models");l(s,o)};c(lr,s=>{e.model_type==="vision"?s(nr):s(dr,!1)})}r(ea),r(Ke);var Xe=t(Ke,2),ta=t(a(Xe),2);p(ta),i(2),r(Xe);var Ze=t(Xe,2),et=t(a(Ze),2);p(et);var aa=t(et,2),pr=a(aa);{var mr=s=>{var o=ee("Use 1 for vision models");l(s,o)},vr=s=>{var o=ee(`2-4
                    typical for text models`);l(s,o)};c(pr,s=>{e.model_type==="vision"?s(mr):s(vr,!1)})}r(aa),r(Ze);var tt=t(Ze,2),ra=t(a(tt),2);p(ra),i(2),r(tt);var at=t(tt,2),sa=t(a(at),2);p(sa),i(2),r(at);var ia=t(at,2),rt=t(a(ia),2),st=a(rt);st.value=st.__value="adamw_8bit";var it=t(st);it.value=it.__value="adamw_torch";var ot=t(it);ot.value=ot.__value="adamw_torch_fused";var lt=t(ot);lt.value=lt.__value="adafactor";var oa=t(lt);oa.value=oa.__value="sgd",r(rt),i(2),r(ia),r(Zt),r(We);var nt=t(We,2),la=t(a(nt),2),dt=a(la),na=t(a(dt),2);p(na),i(2),r(dt);var pt=t(dt,2),da=t(a(pt),2);p(da),i(2),r(pt);var pa=t(pt,2),ma=t(a(pa),2);p(ma),i(2),r(pa),r(la),r(nt);var va=t(nt,2);{var _r=s=>{var o=ls(),_=X(o),y=t(a(_),2),k=a(y),d=t(a(k),2),v=a(d);v.value=v.__value="steps";var w=t(v);w.value=w.__value="epoch";var x=t(w);x.value=x.__value="no",r(d),r(k);var f=t(k,2),u=t(a(f),2);p(u),i(2),r(f);var q=t(f,2),g=t(a(q),2),L=a(g);L.value=L.__value="eval_loss";var B=t(L);B.value=B.__value="eval_accuracy";var j=t(B);j.value=j.__value="eval_f1",r(g),r(q);var F=t(q,2),$=a(F),P=a($);p(P),i(2),r($),i(2),r(F),r(y),r(_);var z=t(_,2),D=t(a(z),4),U=a(D),G=a(U),J=a(G);p(J),i(2),r(G),i(2),r(U);var Y=t(U,2);{var I=M=>{var W=os(),K=a(W),S=t(a(K),2);p(S),i(2),r(K);var me=t(K,2),A=t(a(me),2);p(A),i(2),r(me),i(2),r(W),b(S,()=>e.early_stopping_patience,Z=>e.early_stopping_patience=Z),b(A,()=>e.early_stopping_threshold,Z=>e.early_stopping_threshold=Z),l(M,W)};c(Y,M=>{e.early_stopping_enabled&&M(I)})}r(D),r(z),te(d,()=>e.hyperparameters.eval_strategy,M=>e.hyperparameters.eval_strategy=M),b(u,()=>e.hyperparameters.eval_steps,M=>e.hyperparameters.eval_steps=M),te(g,()=>e.hyperparameters.metric_for_best_model,M=>e.hyperparameters.metric_for_best_model=M),V(P,()=>e.hyperparameters.load_best_model_at_end,M=>e.hyperparameters.load_best_model_at_end=M),V(J,()=>e.early_stopping_enabled,M=>e.early_stopping_enabled=M),l(s,o)};c(va,s=>{e.validation_dataset_path&&s(_r)})}var mt=t(va,2),vt=a(mt);vt.__click=[ns,Ee];var _a=a(vt),cr=a(_a,!0);r(_a),i(),r(vt),r(mt);var ur=t(mt,2);{var gr=s=>{var o=ds(),_=t(a(o),2),y=a(_),k=t(a(y),2);p(k),i(2),r(y);var d=t(y,2),v=t(a(d),2),w=a(v);w.value=w.__value="linear";var x=t(w);x.value=x.__value="cosine";var f=t(x);f.value=f.__value="constant";var u=t(f);u.value=u.__value="constant_with_warmup";var q=t(u);q.value=q.__value="polynomial",r(v),i(2),r(d);var g=t(d,2),L=t(a(g),2);p(L),i(2),r(g);var B=t(g,2),j=t(a(B),2);p(j),i(2),r(B),r(_);var F=t(_,4),$=a(F),P=t(a($),2);p(P),i(2),r($);var z=t($,2),D=t(a(z),2);p(D),i(2),r(z);var U=t(z,2),G=t(a(U),2);p(G),i(2),r(U),r(F);var J=t(F,4),Y=a(J),I=t(a(Y),2);p(I),i(2),r(Y);var M=t(Y,2),W=a(M),K=a(W);p(K),i(2),r(W),i(2),r(M),r(J),r(o),b(k,()=>e.hyperparameters.weight_decay,S=>e.hyperparameters.weight_decay=S),te(v,()=>e.hyperparameters.lr_scheduler_type,S=>e.hyperparameters.lr_scheduler_type=S),b(L,()=>e.hyperparameters.warmup_steps,S=>e.hyperparameters.warmup_steps=S),b(j,()=>e.hyperparameters.max_grad_norm,S=>e.hyperparameters.max_grad_norm=S),b(P,()=>e.hyperparameters.adam_beta1,S=>e.hyperparameters.adam_beta1=S),b(D,()=>e.hyperparameters.adam_beta2,S=>e.hyperparameters.adam_beta2=S),b(G,()=>e.hyperparameters.adam_epsilon,S=>e.hyperparameters.adam_epsilon=S),b(I,()=>e.hyperparameters.dataloader_num_workers,S=>e.hyperparameters.dataloader_num_workers=S),V(K,()=>e.hyperparameters.dataloader_pin_memory,S=>e.hyperparameters.dataloader_pin_memory=S),l(s,o)};c(ur,s=>{n(Ee)&&s(gr)})}r(He);var _t=t(He,2),ca=t(a(_t),4),ct=a(ca),ua=a(ct),ga=a(ua),ba=a(ga),ya=a(ba);p(ya),i(2),r(ba),i(4),r(ga),r(ua),r(ct);var fa=t(ct,2),xa=t(a(fa),4),ut=a(xa),gt=a(ut);p(gt),i(2),r(ut);var bt=t(ut,2),yt=a(bt);p(yt),i(2),r(bt);var br=t(bt,2);{var yr=s=>{var o=ps();l(s,o)};c(br,s=>{!e.quality_mode&&!e.load_in_16bit&&!e.load_in_8bit&&s(yr)})}r(xa),r(fa),r(ca),r(_t);var ft=t(_t,2),xt=a(ft),fr=t(a(xt),2);{var xr=s=>{var o=ms();l(s,o)};c(fr,s=>{n(C)?.training_defaults?.lora_config&&s(xr)})}r(xt);var ht=t(xt,2),kt=a(ht),ha=t(a(kt),2);p(ha),i(2),r(kt);var wt=t(kt,2),ka=t(a(wt),2);p(ka),i(2),r(wt);var wa=t(wt,2),Sa=t(a(wa),2);p(Sa),i(2),r(wa),r(ht);var St=t(ht,2),Lt=a(St);Lt.__click=[vs,Te];var La=a(Lt),hr=a(La,!0);r(La),i(),r(Lt),r(St);var kr=t(St,2);{var wr=s=>{var o=us(),_=a(o),y=a(_),k=t(a(y),2),d=a(k);d.value=d.__value="none";var v=t(d);v.value=v.__value="all";var w=t(v);w.value=w.__value="lora_only",r(k),i(2),r(y);var x=t(y,2),f=t(a(x),2),u=a(f);u.value=u.__value="unsloth";var q=t(u);q.value=q.__value="true";var g=t(q);g.value=g.__value="false",r(f),i(2),r(x),r(_);var L=t(_,2),B=a(L),j=a(B),F=a(j);p(F),i(2),r(j),i(2),r(B);var $=t(B,2),P=t(a($),2);p(P),i(2),r($),r(L);var z=t(L,2),D=a(z),U=t(a(D),2),G=a(U);G.value=G.__value="CAUSAL_LM";var J=t(G);J.value=J.__value="SEQ_2_SEQ_LM";var Y=t(J);Y.value=Y.__value="TOKEN_CLS";var I=t(Y);I.value=I.__value="SEQ_CLS";var M=t(I);M.value=M.__value="QUESTION_ANS",r(U),i(2),r(D);var W=t(D,2),K=t(a(W),2);p(K),K.__input=[_s,e],i(2),r(W),r(z);var S=t(z,2);{var me=A=>{var Z=cs(),he=t(a(Z),4),ve=a(he),_e=a(ve);p(_e),i(2),r(ve);var ce=t(ve,2),Re=a(ce);p(Re),i(2),r(ce);var ue=t(ce,2),ke=a(ue);p(ke),i(2),r(ue);var qe=t(ue,2),h=a(qe);p(h),i(2),r(qe),r(he),i(2),r(Z),V(_e,()=>e.lora_config.finetune_vision_layers,R=>e.lora_config.finetune_vision_layers=R),V(Re,()=>e.lora_config.finetune_language_layers,R=>e.lora_config.finetune_language_layers=R),V(ke,()=>e.lora_config.finetune_attention_modules,R=>e.lora_config.finetune_attention_modules=R),V(h,()=>e.lora_config.finetune_mlp_modules,R=>e.lora_config.finetune_mlp_modules=R),l(A,Z)};c(S,A=>{e.model_type==="vision"&&A(me)})}i(2),r(o),H(A=>Vr(K,A),[()=>e.lora_config.target_modules?.join(", ")||""]),te(k,()=>e.lora_config.lora_bias,A=>e.lora_config.lora_bias=A),te(f,()=>e.lora_config.use_gradient_checkpointing,A=>e.lora_config.use_gradient_checkpointing=A),V(F,()=>e.lora_config.use_rslora,A=>e.lora_config.use_rslora=A),b(P,()=>e.lora_config.random_state,A=>e.lora_config.random_state=A),te(U,()=>e.lora_config.task_type,A=>e.lora_config.task_type=A),l(s,o)};c(kr,s=>{n(Te)&&s(wr)})}r(ft);var Mt=t(ft,2),Ma=t(a(Mt),2),Ae=t(a(Ma),2),At=a(Ae);At.value=At.__value="merged_16bit";var Rt=t(At);Rt.value=Rt.__value="merged_4bit";var Aa=t(Rt);Aa.value=Aa.__value="lora",r(Ae);var Ra=t(Ae,2),qa=a(Ra),Sr=a(qa);{var Lr=s=>{var o=gs();i(),l(s,o)},Mr=s=>{var o=be(),_=X(o);{var y=d=>{var v=bs();i(),l(d,v)},k=d=>{var v=ys();i(),l(d,v)};c(_,d=>{e.save_method==="merged_4bit"?d(y):d(k,!1)},!0)}l(s,o)};c(Sr,s=>{e.save_method==="merged_16bit"?s(Lr):s(Mr,!1)})}r(qa),r(Ra),r(Ma),r(Mt);var Ba=t(Mt,2);{var Ar=s=>{var o=Ms(),_=t(a(o),4),y=a(_),k=a(y),d=a(k);p(d),i(2),r(k),i(2),r(y);var v=t(y,2);{var w=x=>{var f=Ls(),u=a(f),q=t(a(u),2),g=a(q);g.value=g.__value="conservative";var L=t(g);L.value=L.__value="moderate";var B=t(L);B.value=B.__value="aggressive",r(q);var j=t(q,2),F=a(j),$=a(F);{var P=h=>{var R=fs(),oe=t(X(R),2);oe.textContent='{, }, [, ], :, ,, "',i(2),l(h,R)},z=h=>{var R=be(),oe=X(R);{var we=ge=>{var qt=xs();i(3),l(ge,qt)},qr=ge=>{var qt=hs();i(),l(ge,qt)};c(oe,ge=>{e.selective_loss_level==="moderate"?ge(we):ge(qr,!1)},!0)}l(h,R)};c($,h=>{e.selective_loss_level==="conservative"?h(P):h(z,!1)})}r(F),r(j),r(u);var D=t(u,2);{var U=h=>{var R=ks(),oe=t(a(R),2);p(oe),i(4),r(R),b(oe,()=>e.selective_loss_schema_keys,we=>e.selective_loss_schema_keys=we),l(h,R)};c(D,h=>{e.selective_loss_level==="aggressive"&&h(U)})}var G=t(D,2),J=a(G),Y=a(J);r(J);var I=t(J,2);p(I);var M=t(I,4),W=a(M),K=t(a(W),2);{var S=h=>{var R=ws();i(),l(h,R)},me=h=>{var R=Ss(),oe=t(X(R)),we=a(oe);r(oe),H(()=>O(we,`Currently: Model learns structure for ${e.selective_loss_masking_start_step??""}
                            steps, then masking begins`)),l(h,R)};c(K,h=>{e.selective_loss_masking_start_step===0?h(S):h(me,!1)})}r(W),r(M),r(G);var A=t(G,2),Z=a(A),he=a(Z);p(he),i(2),r(Z),i(2),r(A);var ve=t(A,2),_e=t(a(ve),2),ce=a(_e),Re=t(a(ce));Re.textContent="{ } [ ] : ,",i(),r(ce),i(8),r(_e);var ue=t(_e,2),ke=t(a(ue),2);ke.textContent='{"name": "John", "age": 30}';var qe=t(ke,2);qe.textContent='{ } : , "',i(2),r(ue),r(ve),r(f),H(()=>O(Y,`Masking Start Step: ${e.selective_loss_masking_start_step??""}`)),te(q,()=>e.selective_loss_level,h=>e.selective_loss_level=h),b(I,()=>e.selective_loss_masking_start_step,h=>e.selective_loss_masking_start_step=h),V(he,()=>e.selective_loss_verbose,h=>e.selective_loss_verbose=h),l(x,f)};c(v,x=>{e.selective_loss&&x(w)})}r(_),r(o),V(d,()=>e.selective_loss,x=>e.selective_loss=x),l(s,o)};c(Ba,s=>{e.model_type==="vision"&&s(Ar)})}var Ca=t(Ba,2),Ea=a(Ca);Tt(Ea,{type:"submit",variant:"primary",get loading(){return n(ae)},get disabled(){return n(ae)},children:(s,o)=>{i();var _=ee();H(()=>O(_,n(ae)?"Creating...":"Start Training")),l(s,_)},$$slots:{default:!0}});var Rr=t(Ea,2);Tt(Rr,{href:"/training",variant:"secondary",children:(s,o)=>{i();var _=ee("Cancel");l(s,_)},$$slots:{default:!0}}),r(Ca),r(ie),H(()=>{Be(fe,1,`p-4 border-2 rounded-lg text-left transition-all ${e.model_type==="text"?"border-primary-500 bg-primary-50":"border-gray-300 hover:border-gray-400"}`),Be(Ne,1,`w-4 h-4 rounded-full border-2 ${e.model_type==="text"?"border-primary-500 bg-primary-500":"border-gray-400"}`),Be(Se,1,`p-4 border-2 rounded-lg text-left transition-all ${e.model_type==="vision"?"border-primary-500 bg-primary-50":"border-gray-300 hover:border-gray-400"}`),Be(Qe,1,`w-4 h-4 rounded-full border-2 ${e.model_type==="vision"?"border-primary-500 bg-primary-500":"border-gray-400"}`),xe.disabled=n(ye),Ta(Le,"placeholder",e.from_hub?"username/dataset-name":e.model_type==="vision"?"./data/vision_dataset.jsonl":"./data/my-dataset.jsonl"),Ta(Me,"placeholder",e.validation_from_hub?"username/val-dataset-name":e.model_type==="vision"?"./data/vision_val_dataset.jsonl":"./data/my-val-dataset.jsonl"),O(rr,`Model will be saved to models/${(e.output_dir||"my-model")??""}`),O(cr,n(Ee)?"‚ñº":"‚ñ∂"),gt.disabled=e.quality_mode,yt.disabled=e.quality_mode||e.load_in_16bit,O(hr,n(Te)?"‚ñº":"‚ñ∂")}),Or("submit",ie,Oa),b(Dt,()=>e.name,s=>e.name=s),te(xe,()=>e.base_model,s=>e.base_model=s),b(Le,()=>e.dataset_path,s=>e.dataset_path=s),V(Gt,()=>e.from_hub,s=>e.from_hub=s),b(Me,()=>e.validation_dataset_path,s=>e.validation_dataset_path=s),V(Ht,()=>e.validation_from_hub,s=>e.validation_from_hub=s),b(Je,()=>e.output_dir,s=>e.output_dir=s),b(Ye,()=>e.hyperparameters.learning_rate,s=>e.hyperparameters.learning_rate=s),b(ta,()=>e.hyperparameters.num_epochs,s=>e.hyperparameters.num_epochs=s),b(et,()=>e.hyperparameters.batch_size,s=>e.hyperparameters.batch_size=s),b(ra,()=>e.hyperparameters.gradient_accumulation_steps,s=>e.hyperparameters.gradient_accumulation_steps=s),b(sa,()=>e.hyperparameters.max_steps,s=>e.hyperparameters.max_steps=s),te(rt,()=>e.hyperparameters.optim,s=>e.hyperparameters.optim=s),b(na,()=>e.hyperparameters.logging_steps,s=>e.hyperparameters.logging_steps=s),b(da,()=>e.hyperparameters.save_steps,s=>e.hyperparameters.save_steps=s),b(ma,()=>e.hyperparameters.save_total_limit,s=>e.hyperparameters.save_total_limit=s),V(ya,()=>e.quality_mode,s=>e.quality_mode=s),V(gt,()=>e.load_in_16bit,s=>e.load_in_16bit=s),V(yt,()=>e.load_in_8bit,s=>e.load_in_8bit=s),b(ha,()=>e.lora_config.r,s=>e.lora_config.r=s),b(ka,()=>e.lora_config.lora_alpha,s=>e.lora_config.lora_alpha=s),b(Sa,()=>e.lora_config.lora_dropout,s=>e.lora_config.lora_dropout=s),te(Ae,()=>e.save_method,s=>e.save_method=s),l(Q,ie)},$$slots:{default:!0}}),r(Vt),r(ze),l(ne,ze),zr()}Br(["click","input"]);export{Ns as component};
