import"../chunks/DsnmJJEf.js";import{q as ot,p as st,a as _a,s as ee,o as it,E as dr,i as l,d as E,f as _,h as lt,b as d,c as dt,$ as nt,t as G,e as t,g as e,l as Q,w as pt,n as i,r as o,m as P,j as pe,k as ae}from"../chunks/D_fozEd9.js";import{i as u}from"../chunks/C2ngLJft.js";import{r as v,s as ye,a as nr,b as mt,e as pr,i as mr}from"../chunks/489nzvkF.js";import{b as k,c as se}from"../chunks/aZwOC-1j.js";import{b as J}from"../chunks/DV7skBy0.js";import{g as vt}from"../chunks/B2b5DBSX.js";import{a as ca}from"../chunks/GrWgsx-T.js";import{B as ua,C as _t}from"../chunks/DWJusdRQ.js";function ct(re,A){A.name&&!A.output_dir&&(A.output_dir=`./models/${A.name.toLowerCase().replace(/[^a-z0-9]/g,"-")}`)}var ut=_('<div class="p-4 bg-red-50 border border-red-200 rounded-lg"><p class="text-red-700"> </p></div>'),gt=(re,A)=>A.model_type="text",bt=_('<div class="w-full h-full rounded-full bg-white scale-50"></div>'),yt=(re,A)=>A.model_type="vision",ft=_('<div class="w-full h-full rounded-full bg-white scale-50"></div>'),xt=_("<option>Loading models...</option>"),ht=_("<option> </option>"),kt=_("<option> </option>"),wt=_('<p class="text-xs text-yellow-600 mt-1"> </p>'),Lt=_('<p class="text-xs text-gray-500 mt-1">üé® Vision-language models can analyze images and text together</p>'),St=_('<p class="text-xs text-blue-700"><strong>Context:</strong> </p>'),At=_('<div class="space-y-1"><p class="text-xs text-blue-700"><strong>VRAM:</strong> </p> <!></div>'),Mt=_('<p class="text-xs text-blue-700 mt-2"><strong>Best for:</strong> </p>'),Bt=_('<div class="mt-3 p-3 bg-blue-50 border border-blue-200 rounded-lg"><div class="flex items-start justify-between"><div class="flex-1"><h4 class="text-sm font-semibold text-blue-900 mb-1"> </h4> <p class="text-xs text-blue-800 mb-2"> </p> <!> <!></div></div></div>'),Rt=_(`Enter a HuggingFace dataset identifier (e.g.,
                  "username/dataset-name")<br/> For specific files, use: "username/repo::train.jsonl"`,1),Ct=_(`<p class="text-sm text-blue-800 mb-2">HuggingFace datasets should use OpenAI messages format with
                    base64 images:</p> <pre class="text-xs bg-blue-100 p-2 rounded overflow-x-auto"><code></code></pre> <p class="text-xs text-blue-700 mt-2"><strong>Example:</strong> <code>Barth371/train_pop_valet_no_wrong_doc</code></p>`,1),Et=_(`<p class="text-sm text-blue-800 mb-2">Your dataset should be in JSONL format with:</p> <pre class="text-xs bg-blue-100 p-2 rounded overflow-x-auto"><code></code></pre> <p class="text-xs text-blue-700 mt-2"><strong>Tip:</strong> Use <code>model-garden create-vision-dataset</code> CLI to generate
                    sample data</p>`,1),jt=_('<div class="p-4 bg-blue-50 border border-blue-200 rounded-lg"><h4 class="text-sm font-semibold text-blue-900 mb-2">üìã Vision Dataset Format</h4> <!></div>'),Ot=_('<span class="text-xs text-green-600 bg-green-50 px-2 py-1 rounded">‚úì Using registry defaults</span>'),Tt=_(`<div class="mb-4 p-3 bg-yellow-50 border border-yellow-200 rounded-lg"><p class="text-sm text-yellow-800">‚ö†Ô∏è <strong>Vision models require:</strong> Lower batch size (1-2),
                higher gradient accumulation (8+), and lower learning rate (2e-5)</p></div>`),Nt=_('<div class="mb-6"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üìä Evaluation Settings</h4> <div class="grid grid-cols-2 gap-4"><div><label for="eval_strategy" class="block text-sm font-medium text-gray-700 mb-1">Evaluation Strategy</label> <select id="eval_strategy" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Every N steps</option><option>Every epoch</option><option>No evaluation</option></select></div> <div><label for="eval_steps" class="block text-sm font-medium text-gray-700 mb-1">Evaluation Steps</label> <input type="number" id="eval_steps" placeholder="Auto (same as save_steps)" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Evaluate every N steps (leave empty for auto)</p></div> <div><label for="metric_for_best_model" class="block text-sm font-medium text-gray-700 mb-1">Best Model Metric</label> <select id="metric_for_best_model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Validation Loss (lower is better)</option><option>Accuracy (higher is better)</option><option>F1 Score (higher is better)</option></select></div> <div><div class="flex items-center mt-6"><input type="checkbox" id="load_best_model_at_end" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="load_best_model_at_end" class="ml-2 block text-sm text-gray-700">Load best model at end</label></div> <p class="text-xs text-gray-500 mt-1">Automatically load checkpoint with best validation metric</p></div></div></div>'),zt=(re,A)=>E(A,!l(A)),Ft=_('<div class="mb-6 p-4 bg-gray-50 border border-gray-200 rounded-lg"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">‚öôÔ∏è Optimizer Settings</h4> <div class="grid grid-cols-2 gap-4 mb-6"><div><label for="weight_decay" class="block text-sm font-medium text-gray-700 mb-1">Weight Decay</label> <input type="number" id="weight_decay" step="0.001" min="0" max="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">L2 regularization strength (0.01 typical)</p></div> <div><label for="lr_scheduler_type" class="block text-sm font-medium text-gray-700 mb-1">LR Scheduler</label> <select id="lr_scheduler_type" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Linear (default)</option><option>Cosine (good for vision)</option><option>Constant</option><option>Constant with Warmup</option><option>Polynomial</option></select> <p class="text-xs text-gray-500 mt-1">Learning rate schedule type</p></div> <div><label for="warmup_steps" class="block text-sm font-medium text-gray-700 mb-1">Warmup Steps</label> <input type="number" id="warmup_steps" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Steps to warmup learning rate from 0</p></div> <div><label for="max_grad_norm" class="block text-sm font-medium text-gray-700 mb-1">Max Gradient Norm</label> <input type="number" id="max_grad_norm" step="0.1" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Gradient clipping threshold (1.0 standard)</p></div></div> <h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üéõÔ∏è Adam Optimizer Parameters</h4> <div class="grid grid-cols-3 gap-4 mb-6"><div><label for="adam_beta1" class="block text-sm font-medium text-gray-700 mb-1">Adam Beta1</label> <input type="number" id="adam_beta1" step="0.01" min="0" max="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Exponential decay rate for 1st moment (0.9 default)</p></div> <div><label for="adam_beta2" class="block text-sm font-medium text-gray-700 mb-1">Adam Beta2</label> <input type="number" id="adam_beta2" step="0.001" min="0" max="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Exponential decay rate for 2nd moment (0.999 default)</p></div> <div><label for="adam_epsilon" class="block text-sm font-medium text-gray-700 mb-1">Adam Epsilon</label> <input type="number" id="adam_epsilon" step="1e-9" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Small constant for numerical stability (1e-8 default)</p></div></div> <h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üîÑ Data Loading Settings</h4> <div class="grid grid-cols-2 gap-4"><div><label for="dataloader_num_workers" class="block text-sm font-medium text-gray-700 mb-1">Dataloader Workers</label> <input type="number" id="dataloader_num_workers" min="0" max="16" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Number of worker processes (0 = main process only)</p></div> <div><div class="flex items-center mt-6"><input type="checkbox" id="dataloader_pin_memory" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="dataloader_pin_memory" class="ml-2 block text-sm text-gray-700">Pin memory to GPU</label></div> <p class="text-xs text-gray-500 mt-1">Faster data transfer to GPU (recommended)</p></div></div></div>'),Pt=_('<span class="text-xs text-green-600 bg-green-50 px-2 py-1 rounded">‚úì Using registry defaults</span>'),qt=(re,A)=>E(A,!l(A)),Qt=(re,A)=>{const a=re.currentTarget.value.trim();a?A.lora_config.target_modules=a.split(",").map(H=>H.trim()).filter(H=>H.length>0):A.lora_config.target_modules=null},Vt=_(`<div class="p-4 bg-gray-50 border border-gray-200 rounded-lg"><div class="grid grid-cols-2 gap-4 mb-4"><div><label for="lora_bias" class="block text-sm font-medium text-gray-700 mb-1">LoRA Bias</label> <select id="lora_bias" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>None (default)</option><option>All bias terms</option><option>LoRA layers only</option></select> <p class="text-xs text-gray-500 mt-1">How to handle bias parameters in LoRA layers</p></div> <div><label for="use_gradient_checkpointing" class="block text-sm font-medium text-gray-700 mb-1">Gradient Checkpointing</label> <select id="use_gradient_checkpointing" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Unsloth (recommended)</option><option>Standard PyTorch</option><option>Disabled</option></select> <p class="text-xs text-gray-500 mt-1">Reduces memory at cost of compute time</p></div></div> <div class="grid grid-cols-2 gap-4 mb-4"><div><div class="flex items-center mt-2"><input type="checkbox" id="use_rslora" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="use_rslora" class="ml-2 block text-sm text-gray-700">Use RSLoRA (Rank-Stabilized LoRA)</label></div> <p class="text-xs text-gray-500 mt-1">Better stability for high ranks (r > 16)</p></div> <div><label for="random_state" class="block text-sm font-medium text-gray-700 mb-1">Random Seed</label> <input type="number" id="random_state" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Seed for reproducible results (42 is popular)</p></div></div> <div class="grid grid-cols-2 gap-4 mb-4"><div><label for="task_type" class="block text-sm font-medium text-gray-700 mb-1">Task Type</label> <select id="task_type" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Causal LM (Text Generation)</option><option>Sequence-to-Sequence</option><option>Token Classification</option><option>Sequence Classification</option><option>Question Answering</option></select> <p class="text-xs text-gray-500 mt-1">Type of task for PEFT optimization</p></div> <div><label for="target_modules_input" class="block text-sm font-medium text-gray-700 mb-1">Target Modules (Advanced)</label> <input type="text" id="target_modules_input" placeholder="q_proj, k_proj, v_proj (leave empty for auto)" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Comma-separated list of layers to apply LoRA (auto-detected
                    if empty)</p></div></div> <div class="p-3 bg-blue-50 border border-blue-200 rounded-lg"><h4 class="text-sm font-semibold text-blue-900 mb-2">üí° LoRA Tips</h4> <ul class="text-xs text-blue-800 space-y-1"><li><strong>Rank (r):</strong> Start with 16, increase to 64+ for
                    complex tasks or large datasets</li> <li><strong>Alpha:</strong> Usually equal to rank. Higher alpha =
                    stronger adaptation</li> <li><strong>Dropout:</strong> Add 0.1-0.3 if overfitting, keep 0
                    for small datasets</li> <li><strong>RSLoRA:</strong> Enable for ranks > 16 to improve training
                    stability</li> <li><strong>Target Modules:</strong> Leave empty for auto-detection.
                    Common: "q_proj,k_proj,v_proj,o_proj" for attention layers</li> <li><strong>Task Type:</strong> Use "CAUSAL_LM" for text generation,
                    "SEQ_2_SEQ_LM" for translation/summarization</li></ul></div></div>`),Ut=_(`<strong>‚úÖ Merged 16-bit (Recommended):</strong> Full model with
                  LoRA weights merged using Unsloth. Creates split files for vLLM
                  compatibility.`,1),$t=_(`<strong>üì¶ Merged 4-bit:</strong> Full model with LoRA weights
                  merged in 4-bit quantized format. Smaller file size.`,1),Gt=_(`<strong>üîß LoRA Adapters Only (Advanced):</strong> Saves only the
                  adapter weights. Requires the base model to load.`,1),Jt=_(`<strong>Conservative:</strong> Masks JSON structural
                          characters: <code></code> and
                          whitespace. Masks ~31% of tokens. <em>Recommended for most cases.</em>`,1),Ht=_("<strong>Moderate:</strong> Conservative + masks <code>null</code> keyword. Good when null values are predictable.",1),Dt=_(`<strong>Aggressive:</strong> Moderate + masks schema field
                          names. Maximum focus on semantic content. Requires specifying
                          schema keys below.`,1),Wt=_(`<div><label for="selective_loss_schema_keys" class="block text-sm font-medium text-gray-700 mb-1">Schema Keys to Mask</label> <input type="text" id="selective_loss_schema_keys" placeholder="Marque,Modele,contents,confidence_score" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Comma-separated list of JSON field names to mask (e.g.,
                        "name,address,phone")</p> <div class="mt-2 p-2 bg-yellow-50 border border-yellow-200 rounded"><p class="text-xs text-yellow-800">‚ö†Ô∏è Only mask keys that are predictable and don't carry
                          semantic meaning. The model should still learn what
                          values go with each key.</p></div></div>`),It=_(`<div class="ml-6 space-y-4 p-4 bg-white border border-gray-200 rounded-lg"><div><label for="selective_loss_level" class="block text-sm font-medium text-gray-700 mb-2">Masking Level</label> <select id="selective_loss_level" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Conservative (Structure Only)</option><option>Moderate (Structure + null)</option><option>Aggressive (Structure + null + Schema Keys)</option></select> <div class="mt-2 p-3 bg-gray-50 rounded-lg"><p class="text-xs text-gray-700"><!></p></div></div> <!> <div><div class="flex items-center"><input type="checkbox" id="selective_loss_verbose" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="selective_loss_verbose" class="ml-2 block text-sm text-gray-700">Verbose mode (print masking statistics)</label></div> <p class="text-xs text-gray-500 mt-1">Display detailed token masking stats during training</p></div> <div class="p-3 bg-blue-50 border border-blue-200 rounded-lg"><h4 class="text-sm font-semibold text-blue-900 mb-2">üìä What Gets Masked?</h4> <ul class="text-xs text-blue-800 space-y-1"><li>‚úì Structural: <code></code> and whitespace
                        (spaces, newlines, tabs)</li> <li>‚úì Quotes: <code>"</code> (string delimiters - purely structural)</li> <li>‚úì Null keyword: <code>null</code> (moderate/aggressive only)</li> <li>‚úó NOT masked: <code>true</code>, <code>false</code> (can
                        be semantic)</li> <li>‚úì Schema keys: Field names like <code>name</code> (aggressive
                        only)</li></ul> <p class="text-xs text-blue-700 mt-2"><strong>Example:</strong> In <code></code>, conservative
                      mode masks <code></code> and spaces (~31% of tokens),
                      trains on <code>name John age 30</code></p></div></div>`),Kt=_(`<div><h3 class="text-lg font-semibold text-gray-900 mb-4">üéØ Selective Loss (Structured Outputs)</h3> <div class="p-4 bg-gradient-to-r from-purple-50 to-blue-50 border border-purple-200 rounded-lg mb-4"><p class="text-sm text-gray-800 mb-2"><strong>üî¨ Experimental Feature:</strong> Optimize training for structured
                outputs (JSON, forms, etc.)</p> <p class="text-xs text-gray-700">Masks structural tokens (braces, colons, whitespace) so the
                model focuses on semantic content. Useful for form extraction,
                structured data generation, and similar tasks.</p></div> <div class="space-y-4"><div><div class="flex items-center"><input type="checkbox" id="selective_loss" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="selective_loss" class="ml-2 block text-sm font-medium text-gray-700">Enable Selective Loss Masking</label></div> <p class="text-xs text-gray-500 mt-1 ml-6">Automatically mask JSON structural tokens during training</p></div> <!></div></div>`),Yt=_(`<form class="space-y-6"><!> <div><h3 class="text-lg font-semibold text-gray-900 mb-4">Basic Configuration</h3> <div class="grid grid-cols-1 gap-4"><div><div class="block text-sm font-medium text-gray-700 mb-2">Model Type *</div> <div class="grid grid-cols-2 gap-3"><button type="button"><div class="flex items-center gap-2"><div><!></div> <span class="font-medium">Text-Only (LLM)</span></div> <p class="text-sm text-gray-600 mt-2 ml-6">Fine-tune language models for text generation tasks</p></button> <button type="button"><div class="flex items-center gap-2"><div><!></div> <span class="font-medium">Vision-Language (VLM)</span></div> <p class="text-sm text-gray-600 mt-2 ml-6">Fine-tune multimodal models for image + text tasks</p></button></div></div> <div><label for="name" class="block text-sm font-medium text-gray-700 mb-1">Model Name *</label> <input type="text" id="name" placeholder="my-finance-model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500" required/></div> <div><label for="base_model" class="block text-sm font-medium text-gray-700 mb-1">Base Model *</label> <select id="base_model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500" required><!></select> <!> <!> <!></div> <div><label for="dataset_path" class="block text-sm font-medium text-gray-700 mb-1">Dataset Path *</label> <input type="text" id="dataset_path" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500" required/> <div class="mt-2 flex items-center"><input type="checkbox" id="from_hub" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="from_hub" class="ml-2 block text-sm text-gray-700">Load from HuggingFace Hub</label></div> <p class="text-xs text-gray-500 mt-1"><!></p></div> <div><label for="validation_dataset_path" class="block text-sm font-medium text-gray-700 mb-1">Validation Dataset Path (Optional)</label> <input type="text" id="validation_dataset_path" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <div class="mt-2 flex items-center"><input type="checkbox" id="validation_from_hub" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="validation_from_hub" class="ml-2 block text-sm text-gray-700">Load validation dataset from HuggingFace Hub</label></div> <p class="text-xs text-gray-500 mt-1">üìä Optional: Provide a validation dataset to track validation
                loss during training<br/> <!></p></div> <!> <div><label for="output_dir" class="block text-sm font-medium text-gray-700 mb-1">Output Directory</label> <input type="text" id="output_dir" placeholder="./models/my-model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/></div></div></div> <div><div class="flex items-center justify-between mb-4"><h3 class="text-lg font-semibold text-gray-900">Training Hyperparameters</h3> <!></div> <!> <div class="mb-6"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üéØ Essential Parameters</h4> <div class="grid grid-cols-2 gap-4"><div><label for="learning_rate" class="block text-sm font-medium text-gray-700 mb-1">Learning Rate</label> <input type="number" id="learning_rate" step="0.00001" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1"><!></p></div> <div><label for="num_epochs" class="block text-sm font-medium text-gray-700 mb-1">Number of Epochs</label> <input type="number" id="num_epochs" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Number of complete passes through dataset</p></div> <div><label for="batch_size" class="block text-sm font-medium text-gray-700 mb-1">Batch Size per GPU</label> <input type="number" id="batch_size" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1"><!></p></div> <div><label for="gradient_accumulation" class="block text-sm font-medium text-gray-700 mb-1">Gradient Accumulation Steps</label> <input type="number" id="gradient_accumulation" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Effective batch size = batch_size √ó
                  gradient_accumulation_steps</p></div> <div><label for="max_steps" class="block text-sm font-medium text-gray-700 mb-1">Max Steps (Optional)</label> <input type="number" id="max_steps" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Override epochs with exact step count (-1 for full epochs)</p></div> <div><label for="optim" class="block text-sm font-medium text-gray-700 mb-1">Optimizer</label> <select id="optim" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>AdamW 8-bit (Recommended - Memory Efficient)</option><option>AdamW (PyTorch)</option><option>AdamW Fused (Faster)</option><option>Adafactor (Very Memory Efficient)</option><option>SGD</option></select> <p class="text-xs text-gray-500 mt-1">8-bit AdamW reduces memory usage significantly</p></div></div></div> <div class="mb-6"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üíæ Checkpoints & Logging</h4> <div class="grid grid-cols-3 gap-4"><div><label for="logging_steps" class="block text-sm font-medium text-gray-700 mb-1">Logging Steps</label> <input type="number" id="logging_steps" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Log metrics every N steps</p></div> <div><label for="save_steps" class="block text-sm font-medium text-gray-700 mb-1">Save Steps</label> <input type="number" id="save_steps" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Save checkpoint every N steps</p></div> <div><label for="save_total_limit" class="block text-sm font-medium text-gray-700 mb-1">Max Checkpoints</label> <input type="number" id="save_total_limit" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Keep only N most recent checkpoints</p></div></div></div> <!> <div class="mb-4"><button type="button" class="flex items-center gap-2 px-4 py-2 text-sm font-medium text-primary-700 bg-primary-50 border border-primary-200 rounded-lg hover:bg-primary-100 transition-colors"><span> </span> Advanced Hyperparameters</button></div> <!></div> <div><div class="flex items-center justify-between mb-4"><h3 class="text-lg font-semibold text-gray-900">LoRA Configuration</h3> <!></div> <div class="grid grid-cols-3 gap-4 mb-4"><div><label for="lora_r" class="block text-sm font-medium text-gray-700 mb-1">LoRA Rank (r)</label> <input type="number" id="lora_r" min="1" max="256" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Higher = more parameters (16 typical, 64+ for complex tasks)</p></div> <div><label for="lora_alpha" class="block text-sm font-medium text-gray-700 mb-1">LoRA Alpha</label> <input type="number" id="lora_alpha" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Scaling factor (typically equal to rank)</p></div> <div><label for="lora_dropout" class="block text-sm font-medium text-gray-700 mb-1">LoRA Dropout</label> <input type="number" id="lora_dropout" min="0" max="0.5" step="0.05" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Regularization (0.0-0.3, 0 = no dropout)</p></div></div> <div class="mb-4"><button type="button" class="flex items-center gap-2 px-4 py-2 text-sm font-medium text-primary-700 bg-primary-50 border border-primary-200 rounded-lg hover:bg-primary-100 transition-colors"><span> </span> Advanced LoRA Settings</button></div> <!></div> <div><h3 class="text-lg font-semibold text-gray-900 mb-4">Model Save Options</h3> <div><label for="save_method" class="block text-sm font-medium text-gray-700 mb-2">Save Method</label> <select id="save_method" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Save Merged Model (16-bit) - Recommended</option><option>Save Merged Model (4-bit) - Smaller Size</option><option>Save LoRA Adapters Only - Advanced</option></select> <div class="mt-3 p-3 bg-blue-50 border border-blue-200 rounded-lg"><p class="text-sm text-blue-800"><!></p></div></div></div> <!> <div class="flex gap-4 pt-4"><!> <!></div></form>`),Xt=_('<div class="min-h-screen bg-gray-50"><div class="bg-white shadow"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex justify-between items-center py-6"><div class="flex items-center"><!> <h1 class="text-3xl font-bold text-gray-900 ml-4">New Training Job</h1></div></div></div></div> <div class="max-w-3xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><!></div></div>');function no(re,A){st(A,!0);let a=_a({name:"",model_type:"text",base_model:"unsloth/tinyllama-bnb-4bit",dataset_path:"./data/sample.jsonl",validation_dataset_path:"",output_dir:"",hyperparameters:{learning_rate:2e-4,num_epochs:3,batch_size:2,max_steps:-1,gradient_accumulation_steps:4,warmup_steps:10,logging_steps:10,save_steps:100,eval_steps:null,optim:"adamw_8bit",weight_decay:.01,lr_scheduler_type:"linear",max_grad_norm:1,adam_beta1:.9,adam_beta2:.999,adam_epsilon:1e-8,dataloader_num_workers:0,dataloader_pin_memory:!0,eval_strategy:"steps",load_best_model_at_end:!0,metric_for_best_model:"eval_loss",save_total_limit:3},lora_config:{r:16,lora_alpha:16,lora_dropout:0,lora_bias:"none",use_rslora:!1,use_gradient_checkpointing:"unsloth",random_state:42,target_modules:null,task_type:"CAUSAL_LM",loftq_config:null},from_hub:!1,validation_from_hub:!1,save_method:"merged_16bit",selective_loss:!1,selective_loss_level:"conservative",selective_loss_schema_keys:"",selective_loss_verbose:!1}),H=ee(!1),ie=ee(""),D=ee(_a([])),W=ee(_a([])),B=ee(null),me=ee(!0),fe=ee("");it(async()=>{try{E(me,!0);const[O,R]=await Promise.all([ca.getRegistryModels("text-llm"),ca.getRegistryModels("vision-vlm")]);E(D,O.models,!0),E(W,R.models,!0),a.model_type==="text"&&l(D).length>0?(E(B,l(D)[0],!0),a.base_model=l(D)[0].id):a.model_type==="vision"&&l(W).length>0&&(E(B,l(W)[0],!0),a.base_model=l(W)[0].id)}catch(O){E(fe,O instanceof Error?O.message:"Failed to load models from registry",!0),console.error("Failed to load registry models:",O),E(D,[{id:"unsloth/tinyllama-bnb-4bit",name:"TinyLlama 1.1B (4-bit)",parameters:"1.1B"},{id:"unsloth/phi-2-bnb-4bit",name:"Phi-2 2.7B (4-bit)",parameters:"2.7B"},{id:"unsloth/mistral-7b-bnb-4bit",name:"Mistral 7B (4-bit)",parameters:"7B"},{id:"unsloth/llama-2-7b-bnb-4bit",name:"Llama 2 7B (4-bit)",parameters:"7B"},{id:"unsloth/llama-3-8b-bnb-4bit",name:"Llama 3 8B (4-bit)",parameters:"8B"}],!0),E(W,[{id:"Qwen/Qwen2.5-VL-3B-Instruct",name:"Qwen2.5-VL 3B",parameters:"3B"},{id:"Qwen/Qwen2.5-VL-7B-Instruct",name:"Qwen2.5-VL 7B",parameters:"7B"},{id:"Qwen/Qwen2.5-VL-72B-Instruct",name:"Qwen2.5-VL 72B",parameters:"72B"},{id:"unsloth/Qwen2.5-VL-3B-Instruct-bnb-4bit",name:"Qwen2.5-VL 3B (4-bit)",parameters:"3B"},{id:"unsloth/Qwen2.5-VL-7B-Instruct-bnb-4bit",name:"Qwen2.5-VL 7B (4-bit)",parameters:"7B"}],!0)}finally{E(me,!1)}}),dr(()=>{const O=a.model_type==="vision"?l(W):l(D);if(E(B,O.find(R=>R.id===a.base_model)||null,!0),l(B)?.training_defaults){const R=l(B).training_defaults;R.hyperparameters&&(a.hyperparameters={...a.hyperparameters,...R.hyperparameters}),R.lora_config&&(a.lora_config={...a.lora_config,...R.lora_config}),R.save_method&&(a.save_method=R.save_method)}}),dr(()=>{a.model_type==="vision"?(l(W).length>0&&(a.base_model=l(W)[0].id),a.dataset_path="./data/vision_dataset.jsonl"):(l(D).length>0&&(a.base_model=l(D)[0].id),a.dataset_path="./data/sample.jsonl")});let xe=ee(!1),he=ee(!1);async function vr(O){if(O.preventDefault(),!a.name||!a.base_model||!a.dataset_path){E(ie,"Please fill in all required fields");return}E(H,!0),E(ie,"");try{let R=null;a.selective_loss_schema_keys&&a.selective_loss_schema_keys.trim()&&(R=a.selective_loss_schema_keys.split(",").map(le=>le.trim()).filter(le=>le.length>0));const I=await ca.createTrainingJob({...a,is_vision:a.model_type==="vision",selective_loss:a.selective_loss,selective_loss_level:a.selective_loss_level,selective_loss_schema_keys:R,selective_loss_verbose:a.selective_loss_verbose});I.success?vt(`/training/${I.data.job_id}`):E(ie,"Failed to create training job")}catch(R){E(ie,R instanceof Error?R.message:"Failed to create training job",!0)}finally{E(H,!1)}}var ke=Xt();lt(O=>{nt.title="New Training Job - Model Garden"});var we=t(ke),ga=t(we),ba=t(ga),ya=t(ba),_r=t(ya);ua(_r,{href:"/training",variant:"ghost",size:"sm",children:(O,R)=>{i();var I=G("‚Üê Training Jobs");d(O,I)},$$slots:{default:!0}}),i(2),o(ya),o(ba),o(ga),o(we);var fa=e(we,2),cr=t(fa);_t(cr,{children:(O,R)=>{var I=Yt(),le=t(I);{var ur=r=>{var s=ut(),m=t(s),b=t(m,!0);o(m),o(s),Q(()=>P(b,l(ie))),d(r,s)};u(le,r=>{l(ie)&&r(ur)})}var Le=e(le,2),xa=e(t(Le),2),Se=t(xa),ha=e(t(Se),2),ve=t(ha);ve.__click=[gt,a];var ka=t(ve),Ae=t(ka),gr=t(Ae);{var br=r=>{var s=bt();d(r,s)};u(gr,r=>{a.model_type==="text"&&r(br)})}o(Ae),i(2),o(ka),i(2),o(ve);var ce=e(ve,2);ce.__click=[yt,a];var wa=t(ce),Me=t(wa),yr=t(Me);{var fr=r=>{var s=ft();d(r,s)};u(yr,r=>{a.model_type==="vision"&&r(fr)})}o(Me),i(2),o(wa),i(2),o(ce),o(ha),o(Se);var Be=e(Se,2),Re=e(t(Be),2);v(Re),Re.__input=[ct,a],o(Be);var Ce=e(Be,2),_e=e(t(Ce),2),xr=t(_e);{var hr=r=>{var s=xt();s.value=s.__value="",d(r,s)},kr=r=>{var s=pe(),m=ae(s);{var b=n=>{var p=pe(),w=ae(p);pr(w,17,()=>l(D),mr,(f,x)=>{var g=ht(),S=t(g);o(g);var y={};Q(()=>{P(S,`${l(x).name??""} (${l(x).parameters??""})`),y!==(y=l(x).id)&&(g.value=(g.__value=l(x).id)??"")}),d(f,g)}),d(n,p)},h=n=>{var p=pe(),w=ae(p);pr(w,17,()=>l(W),mr,(f,x)=>{var g=kt(),S=t(g);o(g);var y={};Q(()=>{P(S,`${l(x).name??""} (${l(x).parameters??""})`),y!==(y=l(x).id)&&(g.value=(g.__value=l(x).id)??"")}),d(f,g)}),d(n,p)};u(m,n=>{a.model_type==="text"?n(b):n(h,!1)},!0)}d(r,s)};u(xr,r=>{l(me)?r(hr):r(kr,!1)})}o(_e);var La=e(_e,2);{var wr=r=>{var s=wt(),m=t(s);o(s),Q(()=>P(m,`‚ö†Ô∏è Using fallback models: ${l(fe)??""}`)),d(r,s)};u(La,r=>{l(fe)&&r(wr)})}var Sa=e(La,2);{var Lr=r=>{var s=Lt();d(r,s)};u(Sa,r=>{a.model_type==="vision"&&r(Lr)})}var Sr=e(Sa,2);{var Ar=r=>{var s=Bt(),m=t(s),b=t(m),h=t(b),n=t(h);o(h);var p=e(h,2),w=t(p,!0);o(p);var f=e(p,2);{var x=y=>{var L=At(),C=t(L),j=e(t(C));o(C);var T=e(C,2);{var z=M=>{var F=St(),q=e(t(F));o(F),Q(V=>P(q,` ${V??""} tokens`),[()=>l(B).capabilities.context_window.toLocaleString()]),d(M,F)};u(T,M=>{l(B).capabilities?.context_window&&M(z)})}o(L),Q(()=>P(j,` ${l(B).requirements.min_vram_gb??""}GB minimum, 
                            ${l(B).requirements.recommended_vram_gb??""}GB recommended`)),d(y,L)};u(f,y=>{l(B).requirements&&y(x)})}var g=e(f,2);{var S=y=>{var L=Mt(),C=e(t(L));o(L),Q(j=>P(C,` ${j??""}`),[()=>l(B).recommended_for.join(", ")]),d(y,L)};u(g,y=>{l(B).recommended_for&&l(B).recommended_for.length>0&&y(S)})}o(b),o(m),o(s),Q(()=>{P(n,`üìä ${l(B).name??""}`),P(w,l(B).description)}),d(r,s)};u(Sr,r=>{l(B)&&!l(me)&&r(Ar)})}o(Ce);var Ee=e(Ce,2),ue=e(t(Ee),2);v(ue);var je=e(ue,2),Aa=t(je);v(Aa),i(2),o(je);var Ma=e(je,2),Mr=t(Ma);{var Br=r=>{var s=Rt();i(2),d(r,s)},Rr=r=>{var s=pe(),m=ae(s);{var b=n=>{var p=G(`Path to your JSONL dataset with image paths/base64 or local
                  file`);d(n,p)},h=n=>{var p=G("Path to your JSONL dataset file");d(n,p)};u(m,n=>{a.model_type==="vision"?n(b):n(h,!1)},!0)}d(r,s)};u(Mr,r=>{a.from_hub?r(Br):r(Rr,!1)})}o(Ma),o(Ee);var Oe=e(Ee,2),ge=e(t(Oe),2);v(ge);var Te=e(ge,2),Ba=t(Te);v(Ba),i(2),o(Te);var Ra=e(Te,2),Cr=e(t(Ra),3);{var Er=r=>{var s=G(`Use HuggingFace format: "username/repo" or
                  "username/repo::validation.jsonl"`);d(r,s)};u(Cr,r=>{a.validation_from_hub&&r(Er)})}o(Ra),o(Oe);var Ca=e(Oe,2);{var jr=r=>{var s=jt(),m=e(t(s),2);{var b=n=>{var p=Ct(),w=e(ae(p),2),f=t(w);f.textContent='{"messages": [{"role": "user", "content": [{"type": "image", "image": "data:image/jpeg;base64,..."}, {"type": "text", "text": "What is shown?"}]}]}',o(w),i(2),d(n,p)},h=n=>{var p=Et(),w=e(ae(p),2),f=t(w);f.textContent='{"text": "What is in this image?", "image": "/path/to/image.jpg", "response": "A cat sitting on a table"}',o(w),i(2),d(n,p)};u(m,n=>{a.from_hub?n(b):n(h,!1)})}o(s),d(r,s)};u(Ca,r=>{a.model_type==="vision"&&r(jr)})}var Ea=e(Ca,2),ja=e(t(Ea),2);v(ja),o(Ea),o(xa),o(Le);var Ne=e(Le,2),ze=t(Ne),Or=e(t(ze),2);{var Tr=r=>{var s=Ot();d(r,s)};u(Or,r=>{l(B)?.training_defaults&&r(Tr)})}o(ze);var Oa=e(ze,2);{var Nr=r=>{var s=Tt();d(r,s)};u(Oa,r=>{a.model_type==="vision"&&r(Nr)})}var Fe=e(Oa,2),Ta=e(t(Fe),2),Pe=t(Ta),qe=e(t(Pe),2);v(qe);var Na=e(qe,2),zr=t(Na);{var Fr=r=>{var s=G(`2e-5 recommended for
                    vision models`);d(r,s)},Pr=r=>{var s=G("2e-4 typical for text models");d(r,s)};u(zr,r=>{a.model_type==="vision"?r(Fr):r(Pr,!1)})}o(Na),o(Pe);var Qe=e(Pe,2),za=e(t(Qe),2);v(za),i(2),o(Qe);var Ve=e(Qe,2),Ue=e(t(Ve),2);v(Ue);var Fa=e(Ue,2),qr=t(Fa);{var Qr=r=>{var s=G("Use 1 for vision models");d(r,s)},Vr=r=>{var s=G(`2-4
                    typical for text models`);d(r,s)};u(qr,r=>{a.model_type==="vision"?r(Qr):r(Vr,!1)})}o(Fa),o(Ve);var $e=e(Ve,2),Pa=e(t($e),2);v(Pa),i(2),o($e);var Ge=e($e,2),qa=e(t(Ge),2);v(qa),i(2),o(Ge);var Qa=e(Ge,2),Je=e(t(Qa),2),He=t(Je);He.value=He.__value="adamw_8bit";var De=e(He);De.value=De.__value="adamw_torch";var We=e(De);We.value=We.__value="adamw_torch_fused";var Ie=e(We);Ie.value=Ie.__value="adafactor";var Va=e(Ie);Va.value=Va.__value="sgd",o(Je),i(2),o(Qa),o(Ta),o(Fe);var Ke=e(Fe,2),Ua=e(t(Ke),2),Ye=t(Ua),$a=e(t(Ye),2);v($a),i(2),o(Ye);var Xe=e(Ye,2),Ga=e(t(Xe),2);v(Ga),i(2),o(Xe);var Ja=e(Xe,2),Ha=e(t(Ja),2);v(Ha),i(2),o(Ja),o(Ua),o(Ke);var Da=e(Ke,2);{var Ur=r=>{var s=Nt(),m=e(t(s),2),b=t(m),h=e(t(b),2),n=t(h);n.value=n.__value="steps";var p=e(n);p.value=p.__value="epoch";var w=e(p);w.value=w.__value="no",o(h),o(b);var f=e(b,2),x=e(t(f),2);v(x),i(2),o(f);var g=e(f,2),S=e(t(g),2),y=t(S);y.value=y.__value="eval_loss";var L=e(y);L.value=L.__value="eval_accuracy";var C=e(L);C.value=C.__value="eval_f1",o(S),o(g);var j=e(g,2),T=t(j),z=t(T);v(z),i(2),o(T),i(2),o(j),o(m),o(s),J(h,()=>a.hyperparameters.eval_strategy,M=>a.hyperparameters.eval_strategy=M),k(x,()=>a.hyperparameters.eval_steps,M=>a.hyperparameters.eval_steps=M),J(S,()=>a.hyperparameters.metric_for_best_model,M=>a.hyperparameters.metric_for_best_model=M),se(z,()=>a.hyperparameters.load_best_model_at_end,M=>a.hyperparameters.load_best_model_at_end=M),d(r,s)};u(Da,r=>{a.validation_dataset_path&&r(Ur)})}var Ze=e(Da,2),ea=t(Ze);ea.__click=[zt,xe];var Wa=t(ea),$r=t(Wa,!0);o(Wa),i(),o(ea),o(Ze);var Gr=e(Ze,2);{var Jr=r=>{var s=Ft(),m=e(t(s),2),b=t(m),h=e(t(b),2);v(h),i(2),o(b);var n=e(b,2),p=e(t(n),2),w=t(p);w.value=w.__value="linear";var f=e(w);f.value=f.__value="cosine";var x=e(f);x.value=x.__value="constant";var g=e(x);g.value=g.__value="constant_with_warmup";var S=e(g);S.value=S.__value="polynomial",o(p),i(2),o(n);var y=e(n,2),L=e(t(y),2);v(L),i(2),o(y);var C=e(y,2),j=e(t(C),2);v(j),i(2),o(C),o(m);var T=e(m,4),z=t(T),M=e(t(z),2);v(M),i(2),o(z);var F=e(z,2),q=e(t(F),2);v(q),i(2),o(F);var V=e(F,2),U=e(t(V),2);v(U),i(2),o(V),o(T);var K=e(T,4),$=t(K),Y=e(t($),2);v(Y),i(2),o($);var X=e($,2),te=t(X),oe=t(te);v(oe),i(2),o(te),i(2),o(X),o(K),o(s),k(h,()=>a.hyperparameters.weight_decay,c=>a.hyperparameters.weight_decay=c),J(p,()=>a.hyperparameters.lr_scheduler_type,c=>a.hyperparameters.lr_scheduler_type=c),k(L,()=>a.hyperparameters.warmup_steps,c=>a.hyperparameters.warmup_steps=c),k(j,()=>a.hyperparameters.max_grad_norm,c=>a.hyperparameters.max_grad_norm=c),k(M,()=>a.hyperparameters.adam_beta1,c=>a.hyperparameters.adam_beta1=c),k(q,()=>a.hyperparameters.adam_beta2,c=>a.hyperparameters.adam_beta2=c),k(U,()=>a.hyperparameters.adam_epsilon,c=>a.hyperparameters.adam_epsilon=c),k(Y,()=>a.hyperparameters.dataloader_num_workers,c=>a.hyperparameters.dataloader_num_workers=c),se(oe,()=>a.hyperparameters.dataloader_pin_memory,c=>a.hyperparameters.dataloader_pin_memory=c),d(r,s)};u(Gr,r=>{l(xe)&&r(Jr)})}o(Ne);var aa=e(Ne,2),ra=t(aa),Hr=e(t(ra),2);{var Dr=r=>{var s=Pt();d(r,s)};u(Hr,r=>{l(B)?.training_defaults?.lora_config&&r(Dr)})}o(ra);var ta=e(ra,2),oa=t(ta),Ia=e(t(oa),2);v(Ia),i(2),o(oa);var sa=e(oa,2),Ka=e(t(sa),2);v(Ka),i(2),o(sa);var Ya=e(sa,2),Xa=e(t(Ya),2);v(Xa),i(2),o(Ya),o(ta);var ia=e(ta,2),la=t(ia);la.__click=[qt,he];var Za=t(la),Wr=t(Za,!0);o(Za),i(),o(la),o(ia);var Ir=e(ia,2);{var Kr=r=>{var s=Vt(),m=t(s),b=t(m),h=e(t(b),2),n=t(h);n.value=n.__value="none";var p=e(n);p.value=p.__value="all";var w=e(p);w.value=w.__value="lora_only",o(h),i(2),o(b);var f=e(b,2),x=e(t(f),2),g=t(x);g.value=g.__value="unsloth";var S=e(g);S.value=S.__value="true";var y=e(S);y.value=y.__value="false",o(x),i(2),o(f),o(m);var L=e(m,2),C=t(L),j=t(C),T=t(j);v(T),i(2),o(j),i(2),o(C);var z=e(C,2),M=e(t(z),2);v(M),i(2),o(z),o(L);var F=e(L,2),q=t(F),V=e(t(q),2),U=t(V);U.value=U.__value="CAUSAL_LM";var K=e(U);K.value=K.__value="SEQ_2_SEQ_LM";var $=e(K);$.value=$.__value="TOKEN_CLS";var Y=e($);Y.value=Y.__value="SEQ_CLS";var X=e(Y);X.value=X.__value="QUESTION_ANS",o(V),i(2),o(q);var te=e(q,2),oe=e(t(te),2);v(oe),oe.__input=[Qt,a],i(2),o(te),o(F),i(2),o(s),Q(c=>mt(oe,c),[()=>a.lora_config.target_modules?.join(", ")||""]),J(h,()=>a.lora_config.lora_bias,c=>a.lora_config.lora_bias=c),J(x,()=>a.lora_config.use_gradient_checkpointing,c=>a.lora_config.use_gradient_checkpointing=c),se(T,()=>a.lora_config.use_rslora,c=>a.lora_config.use_rslora=c),k(M,()=>a.lora_config.random_state,c=>a.lora_config.random_state=c),J(V,()=>a.lora_config.task_type,c=>a.lora_config.task_type=c),d(r,s)};u(Ir,r=>{l(he)&&r(Kr)})}o(aa);var da=e(aa,2),er=e(t(da),2),be=e(t(er),2),na=t(be);na.value=na.__value="merged_16bit";var pa=e(na);pa.value=pa.__value="merged_4bit";var ar=e(pa);ar.value=ar.__value="lora",o(be);var rr=e(be,2),tr=t(rr),Yr=t(tr);{var Xr=r=>{var s=Ut();i(),d(r,s)},Zr=r=>{var s=pe(),m=ae(s);{var b=n=>{var p=$t();i(),d(n,p)},h=n=>{var p=Gt();i(),d(n,p)};u(m,n=>{a.save_method==="merged_4bit"?n(b):n(h,!1)},!0)}d(r,s)};u(Yr,r=>{a.save_method==="merged_16bit"?r(Xr):r(Zr,!1)})}o(tr),o(rr),o(er),o(da);var or=e(da,2);{var et=r=>{var s=Kt(),m=e(t(s),4),b=t(m),h=t(b),n=t(h);v(n),i(2),o(h),i(2),o(b);var p=e(b,2);{var w=f=>{var x=It(),g=t(x),S=e(t(g),2),y=t(S);y.value=y.__value="conservative";var L=e(y);L.value=L.__value="moderate";var C=e(L);C.value=C.__value="aggressive",o(S);var j=e(S,2),T=t(j),z=t(T);{var M=N=>{var Z=Jt(),de=e(ae(Z),2);de.textContent='{, }, [, ], :, ,, "',i(2),d(N,Z)},F=N=>{var Z=pe(),de=ae(Z);{var ma=ne=>{var va=Ht();i(3),d(ne,va)},tt=ne=>{var va=Dt();i(),d(ne,va)};u(de,ne=>{a.selective_loss_level==="moderate"?ne(ma):ne(tt,!1)},!0)}d(N,Z)};u(z,N=>{a.selective_loss_level==="conservative"?N(M):N(F,!1)})}o(T),o(j),o(g);var q=e(g,2);{var V=N=>{var Z=Wt(),de=e(t(Z),2);v(de),i(4),o(Z),k(de,()=>a.selective_loss_schema_keys,ma=>a.selective_loss_schema_keys=ma),d(N,Z)};u(q,N=>{a.selective_loss_level==="aggressive"&&N(V)})}var U=e(q,2),K=t(U),$=t(K);v($),i(2),o(K),i(2),o(U);var Y=e(U,2),X=e(t(Y),2),te=t(X),oe=e(t(te));oe.textContent="{ } [ ] : ,",i(),o(te),i(8),o(X);var c=e(X,2),lr=e(t(c),2);lr.textContent='{"name": "John", "age": 30}';var rt=e(lr,2);rt.textContent='{ } : , "',i(2),o(c),o(Y),o(x),J(S,()=>a.selective_loss_level,N=>a.selective_loss_level=N),se($,()=>a.selective_loss_verbose,N=>a.selective_loss_verbose=N),d(f,x)};u(p,f=>{a.selective_loss&&f(w)})}o(m),o(s),se(n,()=>a.selective_loss,f=>a.selective_loss=f),d(r,s)};u(or,r=>{a.model_type==="vision"&&r(et)})}var sr=e(or,2),ir=t(sr);ua(ir,{type:"submit",variant:"primary",get loading(){return l(H)},get disabled(){return l(H)},children:(r,s)=>{i();var m=G();Q(()=>P(m,l(H)?"Creating...":"Start Training")),d(r,m)},$$slots:{default:!0}});var at=e(ir,2);ua(at,{href:"/training",variant:"secondary",children:(r,s)=>{i();var m=G("Cancel");d(r,m)},$$slots:{default:!0}}),o(sr),o(I),Q(()=>{ye(ve,1,`p-4 border-2 rounded-lg text-left transition-all ${a.model_type==="text"?"border-primary-500 bg-primary-50":"border-gray-300 hover:border-gray-400"}`),ye(Ae,1,`w-4 h-4 rounded-full border-2 ${a.model_type==="text"?"border-primary-500 bg-primary-500":"border-gray-400"}`),ye(ce,1,`p-4 border-2 rounded-lg text-left transition-all ${a.model_type==="vision"?"border-primary-500 bg-primary-50":"border-gray-300 hover:border-gray-400"}`),ye(Me,1,`w-4 h-4 rounded-full border-2 ${a.model_type==="vision"?"border-primary-500 bg-primary-500":"border-gray-400"}`),_e.disabled=l(me),nr(ue,"placeholder",a.from_hub?"username/dataset-name":a.model_type==="vision"?"./data/vision_dataset.jsonl":"./data/my-dataset.jsonl"),nr(ge,"placeholder",a.validation_from_hub?"username/val-dataset-name":a.model_type==="vision"?"./data/vision_val_dataset.jsonl":"./data/my-val-dataset.jsonl"),P($r,l(xe)?"‚ñº":"‚ñ∂"),P(Wr,l(he)?"‚ñº":"‚ñ∂")}),pt("submit",I,vr),k(Re,()=>a.name,r=>a.name=r),J(_e,()=>a.base_model,r=>a.base_model=r),k(ue,()=>a.dataset_path,r=>a.dataset_path=r),se(Aa,()=>a.from_hub,r=>a.from_hub=r),k(ge,()=>a.validation_dataset_path,r=>a.validation_dataset_path=r),se(Ba,()=>a.validation_from_hub,r=>a.validation_from_hub=r),k(ja,()=>a.output_dir,r=>a.output_dir=r),k(qe,()=>a.hyperparameters.learning_rate,r=>a.hyperparameters.learning_rate=r),k(za,()=>a.hyperparameters.num_epochs,r=>a.hyperparameters.num_epochs=r),k(Ue,()=>a.hyperparameters.batch_size,r=>a.hyperparameters.batch_size=r),k(Pa,()=>a.hyperparameters.gradient_accumulation_steps,r=>a.hyperparameters.gradient_accumulation_steps=r),k(qa,()=>a.hyperparameters.max_steps,r=>a.hyperparameters.max_steps=r),J(Je,()=>a.hyperparameters.optim,r=>a.hyperparameters.optim=r),k($a,()=>a.hyperparameters.logging_steps,r=>a.hyperparameters.logging_steps=r),k(Ga,()=>a.hyperparameters.save_steps,r=>a.hyperparameters.save_steps=r),k(Ha,()=>a.hyperparameters.save_total_limit,r=>a.hyperparameters.save_total_limit=r),k(Ia,()=>a.lora_config.r,r=>a.lora_config.r=r),k(Ka,()=>a.lora_config.lora_alpha,r=>a.lora_config.lora_alpha=r),k(Xa,()=>a.lora_config.lora_dropout,r=>a.lora_config.lora_dropout=r),J(be,()=>a.save_method,r=>a.save_method=r),d(O,I)},$$slots:{default:!0}}),o(fa),o(ke),d(re,ke),dt()}ot(["click","input"]);export{no as component};
