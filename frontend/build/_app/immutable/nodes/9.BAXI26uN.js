import"../chunks/DsnmJJEf.js";import{p as Aa,s as g,a as Sa,o as Ia,f as c,h as Ha,b as i,c as Ca,$ as ja,t as M,e as r,g as a,d as l,i as e,n as v,r as t,k as fe,j as ia,u as da,l as w,m as f,w as Qa}from"../chunks/D_fozEd9.js";import{i as b}from"../chunks/C2ngLJft.js";import{r as j,e as Ea,s as Na,i as Ra}from"../chunks/489nzvkF.js";import{a as Ce,b as ge}from"../chunks/aZwOC-1j.js";import{b as na}from"../chunks/DV7skBy0.js";import{s as Wa,a as Ka}from"../chunks/CR33jhwB.js";import{g as Oa}from"../chunks/2k1G2s8Z.js";import{p as Ja}from"../chunks/DxW5Nd96.js";import{a as le}from"../chunks/GrWgsx-T.js";import{B as je}from"../chunks/CtEMOJqH.js";import{B as _e,C as Qe}from"../chunks/DWJusdRQ.js";var Va=c('<div class="text-center py-12"><div class="inline-block w-8 h-8 border-4 border-primary-600 border-t-transparent rounded-full animate-spin"></div> <p class="mt-2 text-gray-600">Loading...</p></div>'),Xa=c("<p><strong>Max Length:</strong> </p>"),Ya=c("<p><strong>Quantization:</strong> </p>"),Za=c('<div class="flex items-start justify-between"><div class="flex-1"><div class="flex items-center gap-2 mb-2"><!> <h3 class="text-lg font-semibold text-gray-900">Model Currently Loaded</h3></div> <div class="space-y-1 text-sm text-gray-600"><p><strong>Path:</strong> </p> <p><strong>Tensor Parallel Size:</strong> </p> <p><strong>GPU Memory:</strong> </p> <!> <p><strong>Data Type:</strong> </p> <!></div></div> <!></div>'),et=c('<div class="flex items-center gap-2"><!> <p class="text-gray-700">Load a model below to start using inference.</p></div>'),at=c('<div class="mb-6 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700"> </div>'),tt=c(`<div><label for="huggingface_model" class="block text-sm font-medium text-gray-700 mb-2">HuggingFace Model ID *</label> <input type="text" id="huggingface_model" placeholder="microsoft/DialoGPT-large" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500" required/> <p class="mt-1 text-xs text-gray-500">Enter a model ID from HuggingFace Hub (e.g.,
                microsoft/DialoGPT-large, meta-llama/Llama-2-7b-chat-hf)</p> <div class="mt-2 p-3 bg-blue-50 border border-blue-200 rounded-lg"><p class="text-xs text-blue-800">💡 <strong>Popular models to try:</strong></p> <div class="mt-1 text-xs text-blue-700 space-y-1"><div>• <code class="bg-blue-100 px-1 rounded">microsoft/DialoGPT-large</code> - Conversational AI</div> <div>• <code class="bg-blue-100 px-1 rounded">microsoft/DialoGPT-medium</code> - Smaller conversational model</div> <div>• <code class="bg-blue-100 px-1 rounded">gpt2</code> - Classic
                    GPT-2 base model</div> <div>• <code class="bg-blue-100 px-1 rounded">gpt2-medium</code> -
                    Medium-sized GPT-2</div></div></div></div>`),rt=c('<p class="text-sm text-gray-500">No local models available. <a href="/training/new" class="text-primary-600 hover:text-primary-700">Train a model first</a>.</p>'),ot=c('<div class="text-sm font-medium text-gray-700"> </div>'),lt=c('<label><input type="radio" name="model" class="w-4 h-4 text-primary-600 focus:ring-primary-500"/> <div class="ml-3 flex-1"><div class="flex items-center justify-between"><div><div class="font-medium text-gray-900"> </div> <div class="text-sm text-gray-500"> </div> <div class="text-xs text-gray-400 mt-1"> </div></div> <div class="text-right"><!> <!></div></div></div></label>'),st=c('<div class="grid grid-cols-1 gap-3"></div>'),it=c('<div><div class="block text-sm font-medium text-gray-700 mb-2">Select Local Model</div> <!></div>'),dt=c(`<span class="text-green-600 font-medium">🔧 Auto mode:</span> Automatically calculates optimal memory usage based on model
                    size and GPU capacity`,1),nt=c('<div class="flex items-center gap-2"><div class="w-4 h-4 border-2 border-white border-t-transparent rounded-full animate-spin"></div> <span>Loading Model...</span></div>'),vt=c('<h2 class="text-xl font-semibold text-gray-900 mb-6"> </h2> <form class="space-y-6"><div><div class="block text-sm font-medium text-gray-700 mb-3">Model Source</div> <div class="flex items-center space-x-6"><label class="flex items-center"><input type="radio" class="w-4 h-4 text-primary-600 focus:ring-primary-500 border-gray-300"/> <span class="ml-2 text-sm text-gray-700">Local Models</span></label> <label class="flex items-center"><input type="radio" class="w-4 h-4 text-primary-600 focus:ring-primary-500 border-gray-300"/> <span class="ml-2 text-sm text-gray-700">🤗 HuggingFace Hub</span></label></div></div> <!> <details class="border border-gray-200 rounded-lg p-4"><summary class="font-medium text-gray-900 cursor-pointer">Advanced Settings</summary> <div class="mt-4 space-y-4"><div><label for="tensor-parallel" class="block text-sm font-medium text-gray-700 mb-1">Tensor Parallel Size</label> <input id="tensor-parallel" type="number" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-primary-500"/> <p class="mt-1 text-xs text-gray-500">Number of GPUs to use for tensor parallelism (default: 1)</p></div> <div><label for="gpu-memory" class="block text-sm font-medium text-gray-700 mb-1">GPU Memory Utilization</label> <div class="flex items-center gap-3"><input id="gpu-memory" type="range" min="0.0" max="0.99" step="0.05" class="flex-1"/> <span class="text-sm font-medium text-gray-700 w-20 text-right"><!></span></div> <p class="mt-1 text-xs text-gray-500"><!></p></div> <div><label for="max-length" class="block text-sm font-medium text-gray-700 mb-1">Max Model Length (tokens)</label> <input id="max-length" type="number" min="128" step="128" placeholder="Auto (from model config)" class="w-full px-3 py-2 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-primary-500"/> <p class="mt-1 text-xs text-gray-500">Maximum sequence length. Leave empty for auto-detection.</p></div> <div><label for="dtype" class="block text-sm font-medium text-gray-700 mb-1">Data Type</label> <select id="dtype" class="w-full px-3 py-2 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-primary-500"><option>Auto</option><option>Float16</option><option>BFloat16</option><option>Float32</option></select> <p class="mt-1 text-xs text-gray-500">Precision for model weights (default: auto)</p></div> <div><label for="quantization" class="block text-sm font-medium text-gray-700 mb-1">Quantization</label> <select id="quantization" class="w-full px-3 py-2 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-primary-500"><option>None (Auto-detect)</option><option>AWQ</option><option>GPTQ</option><option>SqueezeLLM</option><option>FP8</option><option>BitsAndBytes</option></select> <p class="mt-1 text-xs text-gray-500">Quantization method (default: auto-detect from model)</p></div></div></details> <div class="flex gap-3 pt-4"><!> <!></div></form>',1),ut=c(`<!> <!> <!> <div class="mt-6 p-4 bg-blue-50 border border-blue-200 rounded-lg"><h3 class="font-medium text-blue-900 mb-2">💡 Tips</h3> <ul class="text-sm text-blue-800 space-y-1"><li>• Only one model can be loaded at a time for inference</li> <li>• Loading a new model will automatically unload the current one</li> <li>• 🤗 <strong>HuggingFace Hub:</strong> Load models directly from the
            hub using model IDs (e.g., gpt2, microsoft/DialoGPT-large)</li> <li>• <strong>Local Models:</strong> Use models you've trained or downloaded
            locally</li> <li>• Larger models require more GPU memory - adjust GPU Memory
            Utilization if needed</li> <li>• Auto-detection works well for most models - advanced settings are
            optional</li> <li>• After loading, visit the <a href="/inference" class="underline font-medium">Inference page</a> to generate text</li></ul></div>`,1),mt=c('<div class="min-h-screen bg-gray-50"><div class="bg-white shadow"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex justify-between items-center py-6"><div class="flex items-center"><!> <h1 class="text-3xl font-bold text-gray-900 ml-4">Load Model for Inference</h1></div></div></div></div> <div class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><!></div></div>');function Pt(va,ua){Aa(ua,!0);const Ee=()=>Ka(Ja,"$page",ma),[ma,ca]=Wa(),Ne=[],pa=[];let xe=g(Sa([])),be=g(!0),y=g(""),G=g(!1),d=g(null),U=g(""),z=g(!1),Q=g(""),se=g(1),k=g(0),ie=g(null),de=g("auto"),ne=g(null);Ia(async()=>{await ye();const s=Ee().url.searchParams.get("model"),u=Ee().url.searchParams.get("hf_model");u?(l(z,!0),l(Q,decodeURIComponent(u),!0)):s&&!e(d)?.loaded&&(l(z,!1),l(U,decodeURIComponent(s),!0))});async function ye(){try{l(be,!0);const s=await le.getModels();l(xe,s.items,!0),l(d,await le.getInferenceStatus(),!0),e(d).loaded&&e(d).model_info&&(l(U,e(d).model_info.model_path,!0),l(se,e(d).model_info.tensor_parallel_size,!0),l(k,e(d).model_info.gpu_memory_utilization,!0),l(ie,e(d).model_info.max_model_len,!0),l(de,e(d).model_info.dtype,!0),l(ne,e(d).model_info.quantization,!0))}catch(s){l(y,s instanceof Error?s.message:"Failed to load data",!0)}finally{l(be,!1)}}async function fa(){let s="";if(e(z)){if(!e(Q).trim()){l(y,"Please enter a HuggingFace model ID (e.g., microsoft/DialoGPT-large)");return}s=e(Q).trim()}else{if(!e(U)){l(y,"Please select a model");return}s=e(U)}try{l(G,!0),l(y,""),e(d)?.loaded&&await le.unloadModel();const u=await le.loadModel({model_path:s,tensor_parallel_size:e(se),gpu_memory_utilization:e(k),max_model_len:e(ie),dtype:e(de),quantization:e(ne)});u.success?(await ye(),Oa("/inference")):l(y,u.message||"Failed to load model",!0)}catch(u){l(y,u instanceof Error?u.message:"Failed to load model",!0)}finally{l(G,!1)}}async function ga(){try{l(G,!0),l(y,"");const s=await le.unloadModel();s.success?await ye():l(y,s.message||"Failed to unload model",!0)}catch(s){l(y,s instanceof Error?s.message:"Failed to unload model",!0)}finally{l(G,!1)}}function _a(s){if(s===0)return"0 Bytes";const u=1024,E=["Bytes","KB","MB","GB"],ve=Math.floor(Math.log(s)/Math.log(u));return parseFloat((s/Math.pow(u,ve)).toFixed(2))+" "+E[ve]}var he=mt();Ha(s=>{ja.title="Load Model - Model Garden"});var $e=r(he),Re=r($e),We=r(Re),Ke=r(We),xa=r(Ke);_e(xa,{href:"/models",variant:"ghost",size:"sm",children:(s,u)=>{v();var E=M("← Models");i(s,E)},$$slots:{default:!0}}),v(2),t(Ke),t(We),t(Re),t($e);var Oe=a($e,2),ba=r(Oe);{var ya=s=>{var u=Va();i(s,u)},ha=s=>{var u=ut(),E=fe(u);{var ve=_=>{Qe(_,{class:"mb-6 bg-green-50 border-green-200",children:(T,N)=>{var h=Za(),B=r(h),L=r(B),R=r(L);je(R,{variant:"success",children:(m,x)=>{v();var P=M("Loaded");i(m,P)},$$slots:{default:!0}}),v(2),t(L);var A=a(L,2),S=r(A),W=a(r(S));t(S);var K=a(S,2),O=a(r(K));t(K);var J=a(K,2),Me=a(r(J));t(J);var ue=a(J,2);{var ee=m=>{var x=Xa(),P=a(r(x));t(x),w(()=>f(P,` ${e(d).model_info.max_model_len??""} tokens`)),i(m,x)};b(ue,m=>{e(d).model_info.max_model_len&&m(ee)})}var V=a(ue,2),ae=a(r(V));t(V);var me=a(V,2);{var te=m=>{var x=Ya(),P=a(r(x));t(x),w(()=>f(P,` ${e(d).model_info.quantization??""}`)),i(m,x)};b(me,m=>{e(d).model_info.quantization&&m(te)})}t(A),t(B);var re=a(B,2);_e(re,{variant:"danger",onclick:ga,get disabled(){return e(G)},children:(m,x)=>{v();var P=M();w(()=>f(P,e(G)?"Unloading...":"Unload Model")),i(m,P)},$$slots:{default:!0}}),t(h),w(m=>{f(W,` ${e(d).model_info.model_path??""}`),f(O,` ${e(d).model_info.tensor_parallel_size??""}`),f(Me,` ${m??""}%`),f(ae,` ${e(d).model_info.dtype??""}`)},[()=>(e(d).model_info.gpu_memory_utilization*100).toFixed(0)]),i(T,h)},$$slots:{default:!0}})},$a=_=>{Qe(_,{class:"mb-6 bg-yellow-50 border-yellow-200",children:(T,N)=>{var h=et(),B=r(h);je(B,{variant:"warning",children:(L,R)=>{v();var A=M("No Model Loaded");i(L,A)},$$slots:{default:!0}}),v(2),t(h),i(T,h)},$$slots:{default:!0}})};b(E,_=>{e(d)?.loaded?_(ve):_($a,!1)})}var Je=a(E,2);{var Ma=_=>{var T=at(),N=r(T,!0);t(T),w(()=>f(N,e(y))),i(_,T)};b(Je,_=>{e(y)&&_(Ma)})}var wa=a(Je,2);Qe(wa,{children:(_,T)=>{var N=vt(),h=fe(N),B=r(h,!0);t(h);var L=a(h,2),R=r(L),A=a(r(R),2),S=r(A),W=r(S);j(W),W.value=W.__value=!1,v(2),t(S);var K=a(S,2),O=r(K);j(O),O.value=O.__value=!0,v(2),t(K),t(A),t(R);var J=a(R,2);{var Me=o=>{var n=tt(),$=a(r(n),2);j($),v(4),t(n),ge($,()=>e(Q),X=>l(Q,X)),i(o,n)},ue=o=>{var n=it(),$=a(r(n),2);{var X=D=>{var I=rt();i(D,I)},Ae=D=>{var I=st();Ea(I,21,()=>e(xe),Ra,(q,p)=>{var Y=lt(),H=r(Y);j(H);var ce,F=a(H,2),Z=r(F),Se=r(Z),Ie=r(Se),ka=r(Ie,!0);t(Ie);var He=a(Ie,2),Ta=r(He,!0);t(He);var ra=a(He,2),Da=r(ra,!0);t(ra),t(Se);var oa=a(Se,2),la=r(oa);{var qa=C=>{var oe=ot(),sa=r(oe,!0);t(oe),w(pe=>f(sa,pe),[()=>_a(e(p).size_bytes)]),i(C,oe)};b(la,C=>{e(p).size_bytes&&C(qa)})}var Ba=a(la,2);{let C=da(()=>e(p).status==="available"?"success":"warning");je(Ba,{get variant(){return e(C)},class:"mt-1",children:(oe,sa)=>{v();var pe=M();w(()=>f(pe,e(p).status)),i(oe,pe)},$$slots:{default:!0}})}t(oa),t(Z),t(F),t(Y),w(()=>{Na(Y,1,`relative flex items-center p-4 border rounded-lg cursor-pointer hover:bg-gray-50 transition-colors ${e(U)===e(p).path?"border-primary-600 bg-primary-50":"border-gray-300"}`),ce!==(ce=e(p).path)&&(H.value=(H.__value=e(p).path)??""),f(ka,e(p).name),f(Ta,e(p).base_model),f(Da,e(p).path)}),Ce(pa,[],H,()=>(e(p).path,e(U)),C=>l(U,C)),i(q,Y)}),t(I),i(D,I)};b($,D=>{e(xe).length===0?D(X):D(Ae,!1)})}t(n),i(o,n)};b(J,o=>{e(z)?o(Me):o(ue,!1)})}var ee=a(J,2),V=a(r(ee),2),ae=r(V),me=a(r(ae),2);j(me),v(2),t(ae);var te=a(ae,2),re=a(r(te),2),m=r(re);j(m);var x=a(m,2),P=r(x);{var Pa=o=>{var n=M("Auto");i(o,n)},za=o=>{var n=M();w($=>f(n,`${$??""}%`),[()=>(e(k)*100).toFixed(0)]),i(o,n)};b(P,o=>{e(k)===0?o(Pa):o(za,!1)})}t(x),t(re);var Ve=a(re,2),La=r(Ve);{var Fa=o=>{var n=dt();v(),i(o,n)},Ga=o=>{var n=M();w($=>f(n,`Manual mode: Using ${$??""}% of GPU memory. Set to 0 for auto mode.`),[()=>(e(k)*100).toFixed(0)]),i(o,n)};b(La,o=>{e(k)===0?o(Fa):o(Ga,!1)})}t(Ve),t(te);var we=a(te,2),Xe=a(r(we),2);j(Xe),v(2),t(we);var Pe=a(we,2),ze=a(r(Pe),2),Le=r(ze);Le.value=Le.__value="auto";var Fe=a(Le);Fe.value=Fe.__value="float16";var Ge=a(Fe);Ge.value=Ge.__value="bfloat16";var Ye=a(Ge);Ye.value=Ye.__value="float32",t(ze),v(2),t(Pe);var Ze=a(Pe,2),Ue=a(r(Ze),2),ke=r(Ue);ke.value=(ke.__value=null)??"";var Te=a(ke);Te.value=Te.__value="awq";var De=a(Te);De.value=De.__value="gptq";var qe=a(De);qe.value=qe.__value="squeezellm";var Be=a(qe);Be.value=Be.__value="fp8";var ea=a(Be);ea.value=ea.__value="bitsandbytes",t(Ue),v(2),t(Ze),t(V),t(ee);var aa=a(ee,2),ta=r(aa);{let o=da(()=>e(G)||(e(z)?!e(Q).trim():!e(U)));_e(ta,{type:"submit",variant:"primary",fullWidth:!0,get disabled(){return e(o)},children:(n,$)=>{var X=ia(),Ae=fe(X);{var D=q=>{var p=nt();i(q,p)},I=q=>{var p=ia(),Y=fe(p);{var H=F=>{var Z=M("Switch to This Model");i(F,Z)},ce=F=>{var Z=M("Load Model");i(F,Z)};b(Y,F=>{e(d)?.loaded?F(H):F(ce,!1)},!0)}i(q,p)};b(Ae,q=>{e(G)?q(D):q(I,!1)})}i(n,X)},$$slots:{default:!0}})}var Ua=a(ta,2);_e(Ua,{href:"/models",variant:"secondary",children:(o,n)=>{v();var $=M("Cancel");i(o,$)},$$slots:{default:!0}}),t(aa),t(L),w(()=>f(B,e(d)?.loaded?"Load Different Model":"Load Model")),Qa("submit",L,o=>{o.preventDefault(),fa()}),Ce(Ne,[],W,()=>e(z),o=>l(z,o)),Ce(Ne,[],O,()=>e(z),o=>l(z,o)),ge(me,()=>e(se),o=>l(se,o)),ge(m,()=>e(k),o=>l(k,o)),ge(Xe,()=>e(ie),o=>l(ie,o)),na(ze,()=>e(de),o=>l(de,o)),na(Ue,()=>e(ne),o=>l(ne,o)),i(_,N)},$$slots:{default:!0}}),v(2),i(s,u)};b(ba,s=>{e(be)?s(ya):s(ha,!1)})}t(Oe),t(he),i(va,he),Ca(),ca()}export{Pt as component};
