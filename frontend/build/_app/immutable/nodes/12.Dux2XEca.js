import"../chunks/DsnmJJEf.js";import{q as Vr,p as Jr,a as Gr,E as Hr,f as g,h as Dr,b as d,c as Wr,$ as Ir,t as j,e as t,g as a,d as K,s as ce,l as oe,i as h,w as $r,n as s,r as o,m as se,j as le,k as $}from"../chunks/D_fozEd9.js";import{i as y}from"../chunks/C2ngLJft.js";import{r as n,s as _e,a as Za,e as er,i as ar,b as Kr}from"../chunks/489nzvkF.js";import{b as u,c as X}from"../chunks/aZwOC-1j.js";import{b as F}from"../chunks/DV7skBy0.js";import{g as Yr}from"../chunks/Dj72KCC9.js";import{a as Xr}from"../chunks/DpHo5pdb.js";import{B as ia,C as Zr}from"../chunks/DWJusdRQ.js";function et(G,x){x.name&&!x.output_dir&&(x.output_dir=`./models/${x.name.toLowerCase().replace(/[^a-z0-9]/g,"-")}`)}var at=g('<div class="p-4 bg-red-50 border border-red-200 rounded-lg"><p class="text-red-700"> </p></div>'),rt=(G,x)=>x.model_type="text",tt=g('<div class="w-full h-full rounded-full bg-white scale-50"></div>'),ot=(G,x)=>x.model_type="vision",st=g('<div class="w-full h-full rounded-full bg-white scale-50"></div>'),it=g("<option> </option>"),lt=g("<option> </option>"),dt=g('<p class="text-xs text-gray-500 mt-1">üé® Vision-language models can analyze images and text together</p>'),nt=g(`Enter a HuggingFace dataset identifier (e.g.,
                  "username/dataset-name")<br/> For specific files, use: "username/repo::train.jsonl"`,1),pt=g(`<p class="text-sm text-blue-800 mb-2">HuggingFace datasets should use OpenAI messages format with
                    base64 images:</p> <pre class="text-xs bg-blue-100 p-2 rounded overflow-x-auto"><code></code></pre> <p class="text-xs text-blue-700 mt-2"><strong>Example:</strong> <code>Barth371/train_pop_valet_no_wrong_doc</code></p>`,1),mt=g(`<p class="text-sm text-blue-800 mb-2">Your dataset should be in JSONL format with:</p> <pre class="text-xs bg-blue-100 p-2 rounded overflow-x-auto"><code></code></pre> <p class="text-xs text-blue-700 mt-2"><strong>Tip:</strong> Use <code>model-garden create-vision-dataset</code> CLI to generate
                    sample data</p>`,1),vt=g('<div class="p-4 bg-blue-50 border border-blue-200 rounded-lg"><h4 class="text-sm font-semibold text-blue-900 mb-2">üìã Vision Dataset Format</h4> <!></div>'),ct=g(`<div class="mb-4 p-3 bg-yellow-50 border border-yellow-200 rounded-lg"><p class="text-sm text-yellow-800">‚ö†Ô∏è <strong>Vision models require:</strong> Lower batch size (1-2),
                higher gradient accumulation (8+), and lower learning rate (2e-5)</p></div>`),_t=g('<div class="mb-6"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üìä Evaluation Settings</h4> <div class="grid grid-cols-2 gap-4"><div><label for="eval_strategy" class="block text-sm font-medium text-gray-700 mb-1">Evaluation Strategy</label> <select id="eval_strategy" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Every N steps</option><option>Every epoch</option><option>No evaluation</option></select></div> <div><label for="eval_steps" class="block text-sm font-medium text-gray-700 mb-1">Evaluation Steps</label> <input type="number" id="eval_steps" placeholder="Auto (same as save_steps)" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Evaluate every N steps (leave empty for auto)</p></div> <div><label for="metric_for_best_model" class="block text-sm font-medium text-gray-700 mb-1">Best Model Metric</label> <select id="metric_for_best_model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Validation Loss (lower is better)</option><option>Accuracy (higher is better)</option><option>F1 Score (higher is better)</option></select></div> <div><div class="flex items-center mt-6"><input type="checkbox" id="load_best_model_at_end" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="load_best_model_at_end" class="ml-2 block text-sm text-gray-700">Load best model at end</label></div> <p class="text-xs text-gray-500 mt-1">Automatically load checkpoint with best validation metric</p></div></div></div>'),ut=(G,x)=>K(x,!h(x)),gt=g('<div class="mb-6 p-4 bg-gray-50 border border-gray-200 rounded-lg"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">‚öôÔ∏è Optimizer Settings</h4> <div class="grid grid-cols-2 gap-4 mb-6"><div><label for="weight_decay" class="block text-sm font-medium text-gray-700 mb-1">Weight Decay</label> <input type="number" id="weight_decay" step="0.001" min="0" max="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">L2 regularization strength (0.01 typical)</p></div> <div><label for="lr_scheduler_type" class="block text-sm font-medium text-gray-700 mb-1">LR Scheduler</label> <select id="lr_scheduler_type" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Linear (default)</option><option>Cosine (good for vision)</option><option>Constant</option><option>Constant with Warmup</option><option>Polynomial</option></select> <p class="text-xs text-gray-500 mt-1">Learning rate schedule type</p></div> <div><label for="warmup_steps" class="block text-sm font-medium text-gray-700 mb-1">Warmup Steps</label> <input type="number" id="warmup_steps" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Steps to warmup learning rate from 0</p></div> <div><label for="max_grad_norm" class="block text-sm font-medium text-gray-700 mb-1">Max Gradient Norm</label> <input type="number" id="max_grad_norm" step="0.1" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Gradient clipping threshold (1.0 standard)</p></div></div> <h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üéõÔ∏è Adam Optimizer Parameters</h4> <div class="grid grid-cols-3 gap-4 mb-6"><div><label for="adam_beta1" class="block text-sm font-medium text-gray-700 mb-1">Adam Beta1</label> <input type="number" id="adam_beta1" step="0.01" min="0" max="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Exponential decay rate for 1st moment (0.9 default)</p></div> <div><label for="adam_beta2" class="block text-sm font-medium text-gray-700 mb-1">Adam Beta2</label> <input type="number" id="adam_beta2" step="0.001" min="0" max="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Exponential decay rate for 2nd moment (0.999 default)</p></div> <div><label for="adam_epsilon" class="block text-sm font-medium text-gray-700 mb-1">Adam Epsilon</label> <input type="number" id="adam_epsilon" step="1e-9" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Small constant for numerical stability (1e-8 default)</p></div></div> <h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üîÑ Data Loading Settings</h4> <div class="grid grid-cols-2 gap-4"><div><label for="dataloader_num_workers" class="block text-sm font-medium text-gray-700 mb-1">Dataloader Workers</label> <input type="number" id="dataloader_num_workers" min="0" max="16" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Number of worker processes (0 = main process only)</p></div> <div><div class="flex items-center mt-6"><input type="checkbox" id="dataloader_pin_memory" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="dataloader_pin_memory" class="ml-2 block text-sm text-gray-700">Pin memory to GPU</label></div> <p class="text-xs text-gray-500 mt-1">Faster data transfer to GPU (recommended)</p></div></div></div>'),bt=(G,x)=>K(x,!h(x)),yt=(G,x)=>{const e=G.currentTarget.value.trim();e?x.lora_config.target_modules=e.split(",").map(P=>P.trim()).filter(P=>P.length>0):x.lora_config.target_modules=null},ft=g(`<div class="p-4 bg-gray-50 border border-gray-200 rounded-lg"><div class="grid grid-cols-2 gap-4 mb-4"><div><label for="lora_bias" class="block text-sm font-medium text-gray-700 mb-1">LoRA Bias</label> <select id="lora_bias" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>None (default)</option><option>All bias terms</option><option>LoRA layers only</option></select> <p class="text-xs text-gray-500 mt-1">How to handle bias parameters in LoRA layers</p></div> <div><label for="use_gradient_checkpointing" class="block text-sm font-medium text-gray-700 mb-1">Gradient Checkpointing</label> <select id="use_gradient_checkpointing" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Unsloth (recommended)</option><option>Standard PyTorch</option><option>Disabled</option></select> <p class="text-xs text-gray-500 mt-1">Reduces memory at cost of compute time</p></div></div> <div class="grid grid-cols-2 gap-4 mb-4"><div><div class="flex items-center mt-2"><input type="checkbox" id="use_rslora" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="use_rslora" class="ml-2 block text-sm text-gray-700">Use RSLoRA (Rank-Stabilized LoRA)</label></div> <p class="text-xs text-gray-500 mt-1">Better stability for high ranks (r > 16)</p></div> <div><label for="random_state" class="block text-sm font-medium text-gray-700 mb-1">Random Seed</label> <input type="number" id="random_state" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Seed for reproducible results (42 is popular)</p></div></div> <div class="grid grid-cols-2 gap-4 mb-4"><div><label for="task_type" class="block text-sm font-medium text-gray-700 mb-1">Task Type</label> <select id="task_type" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Causal LM (Text Generation)</option><option>Sequence-to-Sequence</option><option>Token Classification</option><option>Sequence Classification</option><option>Question Answering</option></select> <p class="text-xs text-gray-500 mt-1">Type of task for PEFT optimization</p></div> <div><label for="target_modules_input" class="block text-sm font-medium text-gray-700 mb-1">Target Modules (Advanced)</label> <input type="text" id="target_modules_input" placeholder="q_proj, k_proj, v_proj (leave empty for auto)" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Comma-separated list of layers to apply LoRA (auto-detected
                    if empty)</p></div></div> <div class="p-3 bg-blue-50 border border-blue-200 rounded-lg"><h4 class="text-sm font-semibold text-blue-900 mb-2">üí° LoRA Tips</h4> <ul class="text-xs text-blue-800 space-y-1"><li><strong>Rank (r):</strong> Start with 16, increase to 64+ for
                    complex tasks or large datasets</li> <li><strong>Alpha:</strong> Usually equal to rank. Higher alpha =
                    stronger adaptation</li> <li><strong>Dropout:</strong> Add 0.1-0.3 if overfitting, keep 0
                    for small datasets</li> <li><strong>RSLoRA:</strong> Enable for ranks > 16 to improve training
                    stability</li> <li><strong>Target Modules:</strong> Leave empty for auto-detection.
                    Common: "q_proj,k_proj,v_proj,o_proj" for attention layers</li> <li><strong>Task Type:</strong> Use "CAUSAL_LM" for text generation,
                    "SEQ_2_SEQ_LM" for translation/summarization</li></ul></div></div>`),xt=g(`<strong>‚úÖ Merged 16-bit (Recommended):</strong> Full model with
                  LoRA weights merged using Unsloth. Creates split files for vLLM
                  compatibility.`,1),ht=g(`<strong>üì¶ Merged 4-bit:</strong> Full model with LoRA weights
                  merged in 4-bit quantized format. Smaller file size.`,1),kt=g(`<strong>üîß LoRA Adapters Only (Advanced):</strong> Saves only the
                  adapter weights. Requires the base model to load.`,1),wt=g(`<strong>Conservative:</strong> Masks JSON structural
                          characters: <code></code> and
                          whitespace. Masks ~31% of tokens. <em>Recommended for most cases.</em>`,1),St=g("<strong>Moderate:</strong> Conservative + masks <code>null</code> keyword. Good when null values are predictable.",1),Lt=g(`<strong>Aggressive:</strong> Moderate + masks schema field
                          names. Maximum focus on semantic content. Requires specifying
                          schema keys below.`,1),At=g(`<div><label for="selective_loss_schema_keys" class="block text-sm font-medium text-gray-700 mb-1">Schema Keys to Mask</label> <input type="text" id="selective_loss_schema_keys" placeholder="Marque,Modele,contents,confidence_score" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Comma-separated list of JSON field names to mask (e.g.,
                        "name,address,phone")</p> <div class="mt-2 p-2 bg-yellow-50 border border-yellow-200 rounded"><p class="text-xs text-yellow-800">‚ö†Ô∏è Only mask keys that are predictable and don't carry
                          semantic meaning. The model should still learn what
                          values go with each key.</p></div></div>`),Mt=g(`<div class="ml-6 space-y-4 p-4 bg-white border border-gray-200 rounded-lg"><div><label for="selective_loss_level" class="block text-sm font-medium text-gray-700 mb-2">Masking Level</label> <select id="selective_loss_level" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Conservative (Structure Only)</option><option>Moderate (Structure + null)</option><option>Aggressive (Structure + null + Schema Keys)</option></select> <div class="mt-2 p-3 bg-gray-50 rounded-lg"><p class="text-xs text-gray-700"><!></p></div></div> <!> <div><div class="flex items-center"><input type="checkbox" id="selective_loss_verbose" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="selective_loss_verbose" class="ml-2 block text-sm text-gray-700">Verbose mode (print masking statistics)</label></div> <p class="text-xs text-gray-500 mt-1">Display detailed token masking stats during training</p></div> <div class="p-3 bg-blue-50 border border-blue-200 rounded-lg"><h4 class="text-sm font-semibold text-blue-900 mb-2">üìä What Gets Masked?</h4> <ul class="text-xs text-blue-800 space-y-1"><li>‚úì Structural: <code></code> and whitespace
                        (spaces, newlines, tabs)</li> <li>‚úì Quotes: <code>"</code> (string delimiters - purely structural)</li> <li>‚úì Null keyword: <code>null</code> (moderate/aggressive only)</li> <li>‚úó NOT masked: <code>true</code>, <code>false</code> (can
                        be semantic)</li> <li>‚úì Schema keys: Field names like <code>name</code> (aggressive
                        only)</li></ul> <p class="text-xs text-blue-700 mt-2"><strong>Example:</strong> In <code></code>, conservative
                      mode masks <code></code> and spaces (~31% of tokens),
                      trains on <code>name John age 30</code></p></div></div>`),Ct=g(`<div><h3 class="text-lg font-semibold text-gray-900 mb-4">üéØ Selective Loss (Structured Outputs)</h3> <div class="p-4 bg-gradient-to-r from-purple-50 to-blue-50 border border-purple-200 rounded-lg mb-4"><p class="text-sm text-gray-800 mb-2"><strong>üî¨ Experimental Feature:</strong> Optimize training for structured
                outputs (JSON, forms, etc.)</p> <p class="text-xs text-gray-700">Masks structural tokens (braces, colons, whitespace) so the
                model focuses on semantic content. Useful for form extraction,
                structured data generation, and similar tasks.</p></div> <div class="space-y-4"><div><div class="flex items-center"><input type="checkbox" id="selective_loss" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="selective_loss" class="ml-2 block text-sm font-medium text-gray-700">Enable Selective Loss Masking</label></div> <p class="text-xs text-gray-500 mt-1 ml-6">Automatically mask JSON structural tokens during training</p></div> <!></div></div>`),Rt=g(`<form class="space-y-6"><!> <div><h3 class="text-lg font-semibold text-gray-900 mb-4">Basic Configuration</h3> <div class="grid grid-cols-1 gap-4"><div><div class="block text-sm font-medium text-gray-700 mb-2">Model Type *</div> <div class="grid grid-cols-2 gap-3"><button type="button"><div class="flex items-center gap-2"><div><!></div> <span class="font-medium">Text-Only (LLM)</span></div> <p class="text-sm text-gray-600 mt-2 ml-6">Fine-tune language models for text generation tasks</p></button> <button type="button"><div class="flex items-center gap-2"><div><!></div> <span class="font-medium">Vision-Language (VLM)</span></div> <p class="text-sm text-gray-600 mt-2 ml-6">Fine-tune multimodal models for image + text tasks</p></button></div></div> <div><label for="name" class="block text-sm font-medium text-gray-700 mb-1">Model Name *</label> <input type="text" id="name" placeholder="my-finance-model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500" required/></div> <div><label for="base_model" class="block text-sm font-medium text-gray-700 mb-1">Base Model *</label> <select id="base_model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500" required><!></select> <!></div> <div><label for="dataset_path" class="block text-sm font-medium text-gray-700 mb-1">Dataset Path *</label> <input type="text" id="dataset_path" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500" required/> <div class="mt-2 flex items-center"><input type="checkbox" id="from_hub" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="from_hub" class="ml-2 block text-sm text-gray-700">Load from HuggingFace Hub</label></div> <p class="text-xs text-gray-500 mt-1"><!></p></div> <div><label for="validation_dataset_path" class="block text-sm font-medium text-gray-700 mb-1">Validation Dataset Path (Optional)</label> <input type="text" id="validation_dataset_path" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <div class="mt-2 flex items-center"><input type="checkbox" id="validation_from_hub" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="validation_from_hub" class="ml-2 block text-sm text-gray-700">Load validation dataset from HuggingFace Hub</label></div> <p class="text-xs text-gray-500 mt-1">üìä Optional: Provide a validation dataset to track validation
                loss during training<br/> <!></p></div> <!> <div><label for="output_dir" class="block text-sm font-medium text-gray-700 mb-1">Output Directory</label> <input type="text" id="output_dir" placeholder="./models/my-model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/></div></div></div> <div><h3 class="text-lg font-semibold text-gray-900 mb-4">Training Hyperparameters</h3> <!> <div class="mb-6"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üéØ Essential Parameters</h4> <div class="grid grid-cols-2 gap-4"><div><label for="learning_rate" class="block text-sm font-medium text-gray-700 mb-1">Learning Rate</label> <input type="number" id="learning_rate" step="0.00001" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1"><!></p></div> <div><label for="num_epochs" class="block text-sm font-medium text-gray-700 mb-1">Number of Epochs</label> <input type="number" id="num_epochs" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Number of complete passes through dataset</p></div> <div><label for="batch_size" class="block text-sm font-medium text-gray-700 mb-1">Batch Size per GPU</label> <input type="number" id="batch_size" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1"><!></p></div> <div><label for="gradient_accumulation" class="block text-sm font-medium text-gray-700 mb-1">Gradient Accumulation Steps</label> <input type="number" id="gradient_accumulation" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Effective batch size = batch_size √ó
                  gradient_accumulation_steps</p></div> <div><label for="max_steps" class="block text-sm font-medium text-gray-700 mb-1">Max Steps (Optional)</label> <input type="number" id="max_steps" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Override epochs with exact step count (-1 for full epochs)</p></div> <div><label for="optim" class="block text-sm font-medium text-gray-700 mb-1">Optimizer</label> <select id="optim" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>AdamW 8-bit (Recommended - Memory Efficient)</option><option>AdamW (PyTorch)</option><option>AdamW Fused (Faster)</option><option>Adafactor (Very Memory Efficient)</option><option>SGD</option></select> <p class="text-xs text-gray-500 mt-1">8-bit AdamW reduces memory usage significantly</p></div></div></div> <div class="mb-6"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üíæ Checkpoints & Logging</h4> <div class="grid grid-cols-3 gap-4"><div><label for="logging_steps" class="block text-sm font-medium text-gray-700 mb-1">Logging Steps</label> <input type="number" id="logging_steps" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Log metrics every N steps</p></div> <div><label for="save_steps" class="block text-sm font-medium text-gray-700 mb-1">Save Steps</label> <input type="number" id="save_steps" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Save checkpoint every N steps</p></div> <div><label for="save_total_limit" class="block text-sm font-medium text-gray-700 mb-1">Max Checkpoints</label> <input type="number" id="save_total_limit" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Keep only N most recent checkpoints</p></div></div></div> <!> <div class="mb-4"><button type="button" class="flex items-center gap-2 px-4 py-2 text-sm font-medium text-primary-700 bg-primary-50 border border-primary-200 rounded-lg hover:bg-primary-100 transition-colors"><span> </span> Advanced Hyperparameters</button></div> <!></div> <div><h3 class="text-lg font-semibold text-gray-900 mb-4">LoRA Configuration</h3> <div class="grid grid-cols-3 gap-4 mb-4"><div><label for="lora_r" class="block text-sm font-medium text-gray-700 mb-1">LoRA Rank (r)</label> <input type="number" id="lora_r" min="1" max="256" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Higher = more parameters (16 typical, 64+ for complex tasks)</p></div> <div><label for="lora_alpha" class="block text-sm font-medium text-gray-700 mb-1">LoRA Alpha</label> <input type="number" id="lora_alpha" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Scaling factor (typically equal to rank)</p></div> <div><label for="lora_dropout" class="block text-sm font-medium text-gray-700 mb-1">LoRA Dropout</label> <input type="number" id="lora_dropout" min="0" max="0.5" step="0.05" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Regularization (0.0-0.3, 0 = no dropout)</p></div></div> <div class="mb-4"><button type="button" class="flex items-center gap-2 px-4 py-2 text-sm font-medium text-primary-700 bg-primary-50 border border-primary-200 rounded-lg hover:bg-primary-100 transition-colors"><span> </span> Advanced LoRA Settings</button></div> <!></div> <div><h3 class="text-lg font-semibold text-gray-900 mb-4">Model Save Options</h3> <div><label for="save_method" class="block text-sm font-medium text-gray-700 mb-2">Save Method</label> <select id="save_method" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Save Merged Model (16-bit) - Recommended</option><option>Save Merged Model (4-bit) - Smaller Size</option><option>Save LoRA Adapters Only - Advanced</option></select> <div class="mt-3 p-3 bg-blue-50 border border-blue-200 rounded-lg"><p class="text-sm text-blue-800"><!></p></div></div></div> <!> <div class="flex gap-4 pt-4"><!> <!></div></form>`),Et=g('<div class="min-h-screen bg-gray-50"><div class="bg-white shadow"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex justify-between items-center py-6"><div class="flex items-center"><!> <h1 class="text-3xl font-bold text-gray-900 ml-4">New Training Job</h1></div></div></div></div> <div class="max-w-3xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><!></div></div>');function Qt(G,x){Jr(x,!0);let e=Gr({name:"",model_type:"text",base_model:"unsloth/tinyllama-bnb-4bit",dataset_path:"./data/sample.jsonl",validation_dataset_path:"",output_dir:"",hyperparameters:{learning_rate:2e-4,num_epochs:3,batch_size:2,max_steps:-1,gradient_accumulation_steps:4,warmup_steps:10,logging_steps:10,save_steps:100,eval_steps:null,optim:"adamw_8bit",weight_decay:.01,lr_scheduler_type:"linear",max_grad_norm:1,adam_beta1:.9,adam_beta2:.999,adam_epsilon:1e-8,dataloader_num_workers:0,dataloader_pin_memory:!0,eval_strategy:"steps",load_best_model_at_end:!0,metric_for_best_model:"eval_loss",save_total_limit:3},lora_config:{r:16,lora_alpha:16,lora_dropout:0,lora_bias:"none",use_rslora:!1,use_gradient_checkpointing:"unsloth",random_state:42,target_modules:null,task_type:"CAUSAL_LM",loftq_config:null},from_hub:!1,validation_from_hub:!1,save_method:"merged_16bit",selective_loss:!1,selective_loss_level:"conservative",selective_loss_schema_keys:"",selective_loss_verbose:!1}),P=ce(!1),Z=ce("");const la=["unsloth/tinyllama-bnb-4bit","unsloth/phi-2-bnb-4bit","unsloth/mistral-7b-bnb-4bit","unsloth/llama-2-7b-bnb-4bit","unsloth/llama-3-8b-bnb-4bit"],da=["Qwen/Qwen2.5-VL-3B-Instruct","Qwen/Qwen2.5-VL-7B-Instruct","Qwen/Qwen2.5-VL-72B-Instruct","unsloth/Qwen2.5-VL-3B-Instruct-bnb-4bit","unsloth/Qwen2.5-VL-7B-Instruct-bnb-4bit"];Hr(()=>{e.model_type==="vision"?(e.base_model=da[0],e.dataset_path="./data/vision_dataset.jsonl",e.hyperparameters.batch_size=1,e.hyperparameters.gradient_accumulation_steps=8,e.hyperparameters.learning_rate=2e-5,e.hyperparameters.lr_scheduler_type="cosine"):(e.base_model=la[0],e.dataset_path="./data/sample.jsonl",e.hyperparameters.batch_size=2,e.hyperparameters.gradient_accumulation_steps=4,e.hyperparameters.learning_rate=2e-4,e.hyperparameters.lr_scheduler_type="linear")});let ue=ce(!1),ge=ce(!1);async function rr(ee){if(ee.preventDefault(),!e.name||!e.base_model||!e.dataset_path){K(Z,"Please fill in all required fields");return}K(P,!0),K(Z,"");try{let Y=null;e.selective_loss_schema_keys&&e.selective_loss_schema_keys.trim()&&(Y=e.selective_loss_schema_keys.split(",").map(ae=>ae.trim()).filter(ae=>ae.length>0));const q=await Xr.createTrainingJob({...e,is_vision:e.model_type==="vision",selective_loss:e.selective_loss,selective_loss_level:e.selective_loss_level,selective_loss_schema_keys:Y,selective_loss_verbose:e.selective_loss_verbose});q.success?Yr(`/training/${q.data.job_id}`):K(Z,"Failed to create training job")}catch(Y){K(Z,Y instanceof Error?Y.message:"Failed to create training job",!0)}finally{K(P,!1)}}var be=Et();Dr(ee=>{Ir.title="New Training Job - Model Garden"});var ye=t(be),na=t(ye),pa=t(na),ma=t(pa),tr=t(ma);ia(tr,{href:"/training",variant:"ghost",size:"sm",children:(ee,Y)=>{s();var q=j("‚Üê Training Jobs");d(ee,q)},$$slots:{default:!0}}),s(2),o(ma),o(pa),o(na),o(ye);var va=a(ye,2),or=t(va);Zr(or,{children:(ee,Y)=>{var q=Rt(),ae=t(q);{var sr=r=>{var i=at(),m=t(i),c=t(m,!0);o(m),o(i),oe(()=>se(c,h(Z))),d(r,i)};y(ae,r=>{h(Z)&&r(sr)})}var fe=a(ae,2),ca=a(t(fe),2),xe=t(ca),_a=a(t(xe),2),ie=t(_a);ie.__click=[rt,e];var ua=t(ie),he=t(ua),ir=t(he);{var lr=r=>{var i=tt();d(r,i)};y(ir,r=>{e.model_type==="text"&&r(lr)})}o(he),s(2),o(ua),s(2),o(ie);var de=a(ie,2);de.__click=[ot,e];var ga=t(de),ke=t(ga),dr=t(ke);{var nr=r=>{var i=st();d(r,i)};y(dr,r=>{e.model_type==="vision"&&r(nr)})}o(ke),s(2),o(ga),s(2),o(de),o(_a),o(xe);var we=a(xe,2),Se=a(t(we),2);n(Se),Se.__input=[et,e],o(we);var Le=a(we,2),ne=a(t(Le),2),pr=t(ne);{var mr=r=>{var i=le(),m=$(i);er(m,17,()=>la,ar,(c,_)=>{var l=it(),v=t(l,!0);o(l);var b={};oe(()=>{se(v,h(_)),b!==(b=h(_))&&(l.value=(l.__value=h(_))??"")}),d(c,l)}),d(r,i)},vr=r=>{var i=le(),m=$(i);er(m,17,()=>da,ar,(c,_)=>{var l=lt(),v=t(l,!0);o(l);var b={};oe(()=>{se(v,h(_)),b!==(b=h(_))&&(l.value=(l.__value=h(_))??"")}),d(c,l)}),d(r,i)};y(pr,r=>{e.model_type==="text"?r(mr):r(vr,!1)})}o(ne);var cr=a(ne,2);{var _r=r=>{var i=dt();d(r,i)};y(cr,r=>{e.model_type==="vision"&&r(_r)})}o(Le);var Ae=a(Le,2),pe=a(t(Ae),2);n(pe);var Me=a(pe,2),ba=t(Me);n(ba),s(2),o(Me);var ya=a(Me,2),ur=t(ya);{var gr=r=>{var i=nt();s(2),d(r,i)},br=r=>{var i=le(),m=$(i);{var c=l=>{var v=j(`Path to your JSONL dataset with image paths/base64 or local
                  file`);d(l,v)},_=l=>{var v=j("Path to your JSONL dataset file");d(l,v)};y(m,l=>{e.model_type==="vision"?l(c):l(_,!1)},!0)}d(r,i)};y(ur,r=>{e.from_hub?r(gr):r(br,!1)})}o(ya),o(Ae);var Ce=a(Ae,2),me=a(t(Ce),2);n(me);var Re=a(me,2),fa=t(Re);n(fa),s(2),o(Re);var xa=a(Re,2),yr=a(t(xa),3);{var fr=r=>{var i=j(`Use HuggingFace format: "username/repo" or
                  "username/repo::validation.jsonl"`);d(r,i)};y(yr,r=>{e.validation_from_hub&&r(fr)})}o(xa),o(Ce);var ha=a(Ce,2);{var xr=r=>{var i=vt(),m=a(t(i),2);{var c=l=>{var v=pt(),b=a($(v),2),f=t(b);f.textContent='{"messages": [{"role": "user", "content": [{"type": "image", "image": "data:image/jpeg;base64,..."}, {"type": "text", "text": "What is shown?"}]}]}',o(b),s(2),d(l,v)},_=l=>{var v=mt(),b=a($(v),2),f=t(b);f.textContent='{"text": "What is in this image?", "image": "/path/to/image.jpg", "response": "A cat sitting on a table"}',o(b),s(2),d(l,v)};y(m,l=>{e.from_hub?l(c):l(_,!1)})}o(i),d(r,i)};y(ha,r=>{e.model_type==="vision"&&r(xr)})}var ka=a(ha,2),wa=a(t(ka),2);n(wa),o(ka),o(ca),o(fe);var Ee=a(fe,2),Sa=a(t(Ee),2);{var hr=r=>{var i=ct();d(r,i)};y(Sa,r=>{e.model_type==="vision"&&r(hr)})}var Oe=a(Sa,2),La=a(t(Oe),2),Te=t(La),ze=a(t(Te),2);n(ze);var Aa=a(ze,2),kr=t(Aa);{var wr=r=>{var i=j(`2e-5 recommended for
                    vision models`);d(r,i)},Sr=r=>{var i=j("2e-4 typical for text models");d(r,i)};y(kr,r=>{e.model_type==="vision"?r(wr):r(Sr,!1)})}o(Aa),o(Te);var Ne=a(Te,2),Ma=a(t(Ne),2);n(Ma),s(2),o(Ne);var je=a(Ne,2),Fe=a(t(je),2);n(Fe);var Ca=a(Fe,2),Lr=t(Ca);{var Ar=r=>{var i=j("Use 1 for vision models");d(r,i)},Mr=r=>{var i=j(`2-4
                    typical for text models`);d(r,i)};y(Lr,r=>{e.model_type==="vision"?r(Ar):r(Mr,!1)})}o(Ca),o(je);var Pe=a(je,2),Ra=a(t(Pe),2);n(Ra),s(2),o(Pe);var qe=a(Pe,2),Ea=a(t(qe),2);n(Ea),s(2),o(qe);var Oa=a(qe,2),Be=a(t(Oa),2),Qe=t(Be);Qe.value=Qe.__value="adamw_8bit";var Ue=a(Qe);Ue.value=Ue.__value="adamw_torch";var Ve=a(Ue);Ve.value=Ve.__value="adamw_torch_fused";var Je=a(Ve);Je.value=Je.__value="adafactor";var Ta=a(Je);Ta.value=Ta.__value="sgd",o(Be),s(2),o(Oa),o(La),o(Oe);var Ge=a(Oe,2),za=a(t(Ge),2),He=t(za),Na=a(t(He),2);n(Na),s(2),o(He);var De=a(He,2),ja=a(t(De),2);n(ja),s(2),o(De);var Fa=a(De,2),Pa=a(t(Fa),2);n(Pa),s(2),o(Fa),o(za),o(Ge);var qa=a(Ge,2);{var Cr=r=>{var i=_t(),m=a(t(i),2),c=t(m),_=a(t(c),2),l=t(_);l.value=l.__value="steps";var v=a(l);v.value=v.__value="epoch";var b=a(v);b.value=b.__value="no",o(_),o(c);var f=a(c,2),L=a(t(f),2);n(L),s(2),o(f);var k=a(f,2),w=a(t(k),2),A=t(w);A.value=A.__value="eval_loss";var M=a(A);M.value=M.__value="eval_accuracy";var R=a(M);R.value=R.__value="eval_f1",o(w),o(k);var O=a(k,2),E=t(O),T=t(E);n(T),s(2),o(E),s(2),o(O),o(m),o(i),F(_,()=>e.hyperparameters.eval_strategy,S=>e.hyperparameters.eval_strategy=S),u(L,()=>e.hyperparameters.eval_steps,S=>e.hyperparameters.eval_steps=S),F(w,()=>e.hyperparameters.metric_for_best_model,S=>e.hyperparameters.metric_for_best_model=S),X(T,()=>e.hyperparameters.load_best_model_at_end,S=>e.hyperparameters.load_best_model_at_end=S),d(r,i)};y(qa,r=>{e.validation_dataset_path&&r(Cr)})}var We=a(qa,2),Ie=t(We);Ie.__click=[ut,ue];var Ba=t(Ie),Rr=t(Ba,!0);o(Ba),s(),o(Ie),o(We);var Er=a(We,2);{var Or=r=>{var i=gt(),m=a(t(i),2),c=t(m),_=a(t(c),2);n(_),s(2),o(c);var l=a(c,2),v=a(t(l),2),b=t(v);b.value=b.__value="linear";var f=a(b);f.value=f.__value="cosine";var L=a(f);L.value=L.__value="constant";var k=a(L);k.value=k.__value="constant_with_warmup";var w=a(k);w.value=w.__value="polynomial",o(v),s(2),o(l);var A=a(l,2),M=a(t(A),2);n(M),s(2),o(A);var R=a(A,2),O=a(t(R),2);n(O),s(2),o(R),o(m);var E=a(m,4),T=t(E),S=a(t(T),2);n(S),s(2),o(T);var H=a(T,2),B=a(t(H),2);n(B),s(2),o(H);var D=a(H,2),z=a(t(D),2);n(z),s(2),o(D),o(E);var Q=a(E,4),N=t(Q),U=a(t(N),2);n(U),s(2),o(N);var V=a(N,2),W=t(V),I=t(W);n(I),s(2),o(W),s(2),o(V),o(Q),o(i),u(_,()=>e.hyperparameters.weight_decay,p=>e.hyperparameters.weight_decay=p),F(v,()=>e.hyperparameters.lr_scheduler_type,p=>e.hyperparameters.lr_scheduler_type=p),u(M,()=>e.hyperparameters.warmup_steps,p=>e.hyperparameters.warmup_steps=p),u(O,()=>e.hyperparameters.max_grad_norm,p=>e.hyperparameters.max_grad_norm=p),u(S,()=>e.hyperparameters.adam_beta1,p=>e.hyperparameters.adam_beta1=p),u(B,()=>e.hyperparameters.adam_beta2,p=>e.hyperparameters.adam_beta2=p),u(z,()=>e.hyperparameters.adam_epsilon,p=>e.hyperparameters.adam_epsilon=p),u(U,()=>e.hyperparameters.dataloader_num_workers,p=>e.hyperparameters.dataloader_num_workers=p),X(I,()=>e.hyperparameters.dataloader_pin_memory,p=>e.hyperparameters.dataloader_pin_memory=p),d(r,i)};y(Er,r=>{h(ue)&&r(Or)})}o(Ee);var $e=a(Ee,2),Ke=a(t($e),2),Ye=t(Ke),Qa=a(t(Ye),2);n(Qa),s(2),o(Ye);var Xe=a(Ye,2),Ua=a(t(Xe),2);n(Ua),s(2),o(Xe);var Va=a(Xe,2),Ja=a(t(Va),2);n(Ja),s(2),o(Va),o(Ke);var Ze=a(Ke,2),ea=t(Ze);ea.__click=[bt,ge];var Ga=t(ea),Tr=t(Ga,!0);o(Ga),s(),o(ea),o(Ze);var zr=a(Ze,2);{var Nr=r=>{var i=ft(),m=t(i),c=t(m),_=a(t(c),2),l=t(_);l.value=l.__value="none";var v=a(l);v.value=v.__value="all";var b=a(v);b.value=b.__value="lora_only",o(_),s(2),o(c);var f=a(c,2),L=a(t(f),2),k=t(L);k.value=k.__value="unsloth";var w=a(k);w.value=w.__value="true";var A=a(w);A.value=A.__value="false",o(L),s(2),o(f),o(m);var M=a(m,2),R=t(M),O=t(R),E=t(O);n(E),s(2),o(O),s(2),o(R);var T=a(R,2),S=a(t(T),2);n(S),s(2),o(T),o(M);var H=a(M,2),B=t(H),D=a(t(B),2),z=t(D);z.value=z.__value="CAUSAL_LM";var Q=a(z);Q.value=Q.__value="SEQ_2_SEQ_LM";var N=a(Q);N.value=N.__value="TOKEN_CLS";var U=a(N);U.value=U.__value="SEQ_CLS";var V=a(U);V.value=V.__value="QUESTION_ANS",o(D),s(2),o(B);var W=a(B,2),I=a(t(W),2);n(I),I.__input=[yt,e],s(2),o(W),o(H),s(2),o(i),oe(p=>Kr(I,p),[()=>e.lora_config.target_modules?.join(", ")||""]),F(_,()=>e.lora_config.lora_bias,p=>e.lora_config.lora_bias=p),F(L,()=>e.lora_config.use_gradient_checkpointing,p=>e.lora_config.use_gradient_checkpointing=p),X(E,()=>e.lora_config.use_rslora,p=>e.lora_config.use_rslora=p),u(S,()=>e.lora_config.random_state,p=>e.lora_config.random_state=p),F(D,()=>e.lora_config.task_type,p=>e.lora_config.task_type=p),d(r,i)};y(zr,r=>{h(ge)&&r(Nr)})}o($e);var aa=a($e,2),Ha=a(t(aa),2),ve=a(t(Ha),2),ra=t(ve);ra.value=ra.__value="merged_16bit";var ta=a(ra);ta.value=ta.__value="merged_4bit";var Da=a(ta);Da.value=Da.__value="lora",o(ve);var Wa=a(ve,2),Ia=t(Wa),jr=t(Ia);{var Fr=r=>{var i=xt();s(),d(r,i)},Pr=r=>{var i=le(),m=$(i);{var c=l=>{var v=ht();s(),d(l,v)},_=l=>{var v=kt();s(),d(l,v)};y(m,l=>{e.save_method==="merged_4bit"?l(c):l(_,!1)},!0)}d(r,i)};y(jr,r=>{e.save_method==="merged_16bit"?r(Fr):r(Pr,!1)})}o(Ia),o(Wa),o(Ha),o(aa);var $a=a(aa,2);{var qr=r=>{var i=Ct(),m=a(t(i),4),c=t(m),_=t(c),l=t(_);n(l),s(2),o(_),s(2),o(c);var v=a(c,2);{var b=f=>{var L=Mt(),k=t(L),w=a(t(k),2),A=t(w);A.value=A.__value="conservative";var M=a(A);M.value=M.__value="moderate";var R=a(M);R.value=R.__value="aggressive",o(w);var O=a(w,2),E=t(O),T=t(E);{var S=C=>{var J=wt(),re=a($(J),2);re.textContent='{, }, [, ], :, ,, "',s(2),d(C,J)},H=C=>{var J=le(),re=$(J);{var oa=te=>{var sa=St();s(3),d(te,sa)},Ur=te=>{var sa=Lt();s(),d(te,sa)};y(re,te=>{e.selective_loss_level==="moderate"?te(oa):te(Ur,!1)},!0)}d(C,J)};y(T,C=>{e.selective_loss_level==="conservative"?C(S):C(H,!1)})}o(E),o(O),o(k);var B=a(k,2);{var D=C=>{var J=At(),re=a(t(J),2);n(re),s(4),o(J),u(re,()=>e.selective_loss_schema_keys,oa=>e.selective_loss_schema_keys=oa),d(C,J)};y(B,C=>{e.selective_loss_level==="aggressive"&&C(D)})}var z=a(B,2),Q=t(z),N=t(Q);n(N),s(2),o(Q),s(2),o(z);var U=a(z,2),V=a(t(U),2),W=t(V),I=a(t(W));I.textContent="{ } [ ] : ,",s(),o(W),s(8),o(V);var p=a(V,2),Xa=a(t(p),2);Xa.textContent='{"name": "John", "age": 30}';var Qr=a(Xa,2);Qr.textContent='{ } : , "',s(2),o(p),o(U),o(L),F(w,()=>e.selective_loss_level,C=>e.selective_loss_level=C),X(N,()=>e.selective_loss_verbose,C=>e.selective_loss_verbose=C),d(f,L)};y(v,f=>{e.selective_loss&&f(b)})}o(m),o(i),X(l,()=>e.selective_loss,f=>e.selective_loss=f),d(r,i)};y($a,r=>{e.model_type==="vision"&&r(qr)})}var Ka=a($a,2),Ya=t(Ka);ia(Ya,{type:"submit",variant:"primary",get loading(){return h(P)},get disabled(){return h(P)},children:(r,i)=>{s();var m=j();oe(()=>se(m,h(P)?"Creating...":"Start Training")),d(r,m)},$$slots:{default:!0}});var Br=a(Ya,2);ia(Br,{href:"/training",variant:"secondary",children:(r,i)=>{s();var m=j("Cancel");d(r,m)},$$slots:{default:!0}}),o(Ka),o(q),oe(()=>{_e(ie,1,`p-4 border-2 rounded-lg text-left transition-all ${e.model_type==="text"?"border-primary-500 bg-primary-50":"border-gray-300 hover:border-gray-400"}`),_e(he,1,`w-4 h-4 rounded-full border-2 ${e.model_type==="text"?"border-primary-500 bg-primary-500":"border-gray-400"}`),_e(de,1,`p-4 border-2 rounded-lg text-left transition-all ${e.model_type==="vision"?"border-primary-500 bg-primary-50":"border-gray-300 hover:border-gray-400"}`),_e(ke,1,`w-4 h-4 rounded-full border-2 ${e.model_type==="vision"?"border-primary-500 bg-primary-500":"border-gray-400"}`),Za(pe,"placeholder",e.from_hub?"username/dataset-name":e.model_type==="vision"?"./data/vision_dataset.jsonl":"./data/my-dataset.jsonl"),Za(me,"placeholder",e.validation_from_hub?"username/val-dataset-name":e.model_type==="vision"?"./data/vision_val_dataset.jsonl":"./data/my-val-dataset.jsonl"),se(Rr,h(ue)?"‚ñº":"‚ñ∂"),se(Tr,h(ge)?"‚ñº":"‚ñ∂")}),$r("submit",q,rr),u(Se,()=>e.name,r=>e.name=r),F(ne,()=>e.base_model,r=>e.base_model=r),u(pe,()=>e.dataset_path,r=>e.dataset_path=r),X(ba,()=>e.from_hub,r=>e.from_hub=r),u(me,()=>e.validation_dataset_path,r=>e.validation_dataset_path=r),X(fa,()=>e.validation_from_hub,r=>e.validation_from_hub=r),u(wa,()=>e.output_dir,r=>e.output_dir=r),u(ze,()=>e.hyperparameters.learning_rate,r=>e.hyperparameters.learning_rate=r),u(Ma,()=>e.hyperparameters.num_epochs,r=>e.hyperparameters.num_epochs=r),u(Fe,()=>e.hyperparameters.batch_size,r=>e.hyperparameters.batch_size=r),u(Ra,()=>e.hyperparameters.gradient_accumulation_steps,r=>e.hyperparameters.gradient_accumulation_steps=r),u(Ea,()=>e.hyperparameters.max_steps,r=>e.hyperparameters.max_steps=r),F(Be,()=>e.hyperparameters.optim,r=>e.hyperparameters.optim=r),u(Na,()=>e.hyperparameters.logging_steps,r=>e.hyperparameters.logging_steps=r),u(ja,()=>e.hyperparameters.save_steps,r=>e.hyperparameters.save_steps=r),u(Pa,()=>e.hyperparameters.save_total_limit,r=>e.hyperparameters.save_total_limit=r),u(Qa,()=>e.lora_config.r,r=>e.lora_config.r=r),u(Ua,()=>e.lora_config.lora_alpha,r=>e.lora_config.lora_alpha=r),u(Ja,()=>e.lora_config.lora_dropout,r=>e.lora_config.lora_dropout=r),F(ve,()=>e.save_method,r=>e.save_method=r),d(ee,q)},$$slots:{default:!0}}),o(va),o(be),d(G,be),Wr()}Vr(["click","input"]);export{Qt as component};
