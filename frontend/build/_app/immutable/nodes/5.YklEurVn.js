import"../chunks/DsnmJJEf.js";import{q as et,p as tt,s as B,a as Ge,o as at,f as h,h as rt,b as i,c as st,$ as ot,t as F,e as t,g as r,d as u,i as e,n as C,r as a,k as U,v as Ne,l as q,m as E,u as it,j as oe}from"../chunks/D_fozEd9.js";import{i as N}from"../chunks/C2ngLJft.js";import{a as nt,e as lt,i as dt,r as Y,s as xe}from"../chunks/489nzvkF.js";import{b as Z,a as Oe,c as vt}from"../chunks/aZwOC-1j.js";import{B as Q,C as ee}from"../chunks/DWJusdRQ.js";import{B as ge}from"../chunks/CtEMOJqH.js";import{a as ct}from"../chunks/GrWgsx-T.js";function pt(te,ie){te.key==="Enter"&&!te.shiftKey&&(te.preventDefault(),ie())}var mt=h('<div class="text-center py-12"><div class="text-6xl mb-4">ðŸ’¬</div> <h3 class="text-xl font-semibold text-gray-700 mb-2">Start a Conversation</h3> <p class="text-gray-500">Select a model and type a message below</p></div>'),ut=h('<span class="inline-block w-1 h-4 bg-gray-600 animate-pulse ml-1"></span>'),ft=h('<div><div><div class="flex items-start gap-2"><div class="flex-1"><div class="text-xs opacity-70 mb-1"> </div> <div class="whitespace-pre-wrap break-words"> <!></div></div></div></div></div>'),_t=h('<div class="flex-1 overflow-y-auto p-6 space-y-4"><!></div> <div class="border-t border-gray-200 p-4"><div class="flex gap-3"><textarea rows="2" class="flex-1 px-4 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500 resize-none disabled:bg-gray-100 disabled:cursor-not-allowed"></textarea> <!></div></div>',1),xt=h('<div class="flex items-center justify-center py-4"><div class="animate-spin rounded-full h-6 w-6 border-b-2 border-primary-600"></div></div>'),gt=h('<div class="text-sm text-red-600 mb-3"> </div> <!>',1),yt=h('<div class="space-y-3"><p class="text-sm text-gray-500">No model currently loaded for inference.</p> <!></div>'),ht=h('<div><div class="text-xs text-gray-500">Max Length</div> <div class="font-medium text-gray-900"> </div></div>'),bt=h('<div><div class="text-xs text-gray-500">Quantization</div> <div class="font-medium text-gray-900"> </div></div>'),$t=h('<div class="space-y-3"><div class="flex items-center gap-2 mb-2"><!></div> <div class="space-y-2 text-sm"><div><div class="text-xs text-gray-500">Model Path</div> <div class="font-medium text-gray-900 break-all"> </div> <div class="text-xs text-gray-400 mt-0.5"> </div></div> <!> <div><div class="text-xs text-gray-500">GPU Memory</div> <div class="font-medium text-gray-900"> </div></div> <div><div class="text-xs text-gray-500">Data Type</div> <div class="font-medium text-gray-900"> </div></div> <!></div> <div class="pt-2 mt-2 border-t border-gray-200"><!></div></div>'),wt=h('<div class="p-4"><h3 class="text-lg font-semibold text-gray-900 mb-3">Model Status</h3> <!></div>'),kt=h('<div class="p-4"><h3 class="text-lg font-semibold text-gray-900 mb-3">Mode</h3> <div class="space-y-2"><label class="flex items-center"><input type="radio" class="mr-2"/> <span class="text-sm">Chat (with context)</span></label> <label class="flex items-center"><input type="radio" class="mr-2"/> <span class="text-sm">Completion (stateless)</span></label></div></div>'),Pt=h('<div class="p-4"><h3 class="text-lg font-semibold text-gray-900 mb-3">Generation Settings</h3> <div class="space-y-4"><div><label for="temperature" class="block text-sm font-medium text-gray-700 mb-1"> </label> <input type="range" id="temperature" min="0.0" max="2.0" step="0.1" class="w-full"/> <p class="text-xs text-gray-500 mt-1">Higher = more creative</p></div> <div><label for="max-tokens" class="block text-sm font-medium text-gray-700 mb-1">Max Tokens</label> <input type="number" id="max-tokens" min="1" max="2000" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 text-sm"/></div> <div><label for="top-p" class="block text-sm font-medium text-gray-700 mb-1"> </label> <input type="range" id="top-p" min="0.0" max="1.0" step="0.05" class="w-full"/></div> <div><label for="top-k" class="block text-sm font-medium text-gray-700 mb-1">Top K</label> <input type="number" id="top-k" min="1" max="100" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 text-sm"/></div> <div><label class="flex items-center"><input type="checkbox" class="mr-2"/> <span class="text-sm font-medium text-gray-700">Enable Streaming</span></label></div></div></div>'),St=h(`<div class="p-4"><h3 class="text-lg font-semibold text-gray-900 mb-3">System Prompt</h3> <textarea rows="4" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 text-sm resize-none" placeholder="Set the assistant's behavior..."></textarea></div>`),Tt=h("<!> <!>",1),Mt=h('<div class="p-4"><h3 class="text-lg font-semibold text-gray-900 mb-3">Conversation</h3> <div class="space-y-2 text-sm"><div class="flex justify-between"><span class="text-gray-600">Messages:</span> <span class="font-medium"> </span></div> <div class="flex justify-between"><span class="text-gray-600">Status:</span> <span> </span></div></div></div>'),Ct=h('<div class="min-h-screen bg-gray-50"><div class="bg-white shadow"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex justify-between items-center py-6"><div class="flex items-center gap-4"><!> <h1 class="text-3xl font-bold text-gray-900">Inference</h1> <!></div> <div class="flex gap-3"><!> <!></div></div></div></div> <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><div class="grid grid-cols-1 lg:grid-cols-4 gap-6"><div class="lg:col-span-3"><!></div> <div class="space-y-6"><!> <!> <!> <!></div></div></div></div>');function Lt(te,ie){tt(ie,!0);const ye=[];let b=B(null),V=B(!0),re=B(""),l=B(Ge([])),K=B(""),z=B(!1),O=B(""),X=B("chat"),f=Ge({temperature:.7,max_tokens:500,top_p:.9,top_k:50,stream:!0}),ne=B("You are a helpful AI assistant."),le=B(!1);async function de(){try{u(V,!0),u(re,""),u(b,await ct.getInferenceStatus(),!0)}catch(o){console.error("Failed to load inference status:",o),u(re,o instanceof Error?o.message:"Failed to load status",!0)}finally{u(V,!1)}}async function he(){if(!e(K).trim()||!e(b)?.loaded||e(z))return;const o={role:"user",content:e(K).trim(),timestamp:new Date};u(l,[...e(l),o],!0);const g=e(K);u(K,""),u(z,!0),u(O,"");try{e(X)==="chat"?await Le(g):await We(g)}catch(s){console.error("Generation error:",s),u(l,[...e(l),{role:"assistant",content:"Error: Failed to generate response. Please try again.",timestamp:new Date}],!0)}finally{u(z,!1)}}async function Le(o){const g={role:"assistant",content:"",timestamp:new Date};u(l,[...e(l),g],!0);try{const s=[{role:"system",content:e(ne)},...e(l).slice(0,-1).map(d=>({role:d.role,content:d.content})),{role:"user",content:o}],n=await fetch("/api/v1/chat/completions",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({messages:s,temperature:f.temperature,max_tokens:f.max_tokens,top_p:f.top_p,stream:f.stream})});if(!n.ok)throw new Error(`HTTP error! status: ${n.status}`);if(f.stream&&n.body){const d=n.body.getReader(),c=new TextDecoder;let _="";for(;;){const{done:v,value:m}=await d.read();if(v)break;_+=c.decode(m,{stream:!0});const x=_.split(`
`);_=x.pop()||"";for(const $ of x)if($.startsWith("data: ")){const p=$.slice(6);if(p==="[DONE]")continue;try{const w=JSON.parse(p).choices[0]?.delta?.content||"";w&&(u(O,e(O)+w),e(l)[e(l).length-1].content=e(O))}catch(y){console.error("Parse error:",y)}}}}else{const d=await n.json();e(l)[e(l).length-1].content=d.choices[0].message.content}}catch(s){throw e(l)[e(l).length-1].content="Error generating response",s}finally{u(O,"")}}async function We(o){const g={role:"assistant",content:"",timestamp:new Date};u(l,[...e(l),g],!0);try{const s=await fetch("/api/v1/inference/generate",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({prompt:o,temperature:f.temperature,max_tokens:f.max_tokens,top_p:f.top_p,top_k:f.top_k,stream:f.stream})});if(!s.ok)throw new Error(`HTTP error! status: ${s.status}`);if(f.stream&&s.body){const n=s.body.getReader(),d=new TextDecoder;let c="";for(;;){const{done:_,value:v}=await n.read();if(_)break;c+=d.decode(v,{stream:!0});const m=c.split(`
`);c=m.pop()||"";for(const x of m)if(x.startsWith("data: ")){const $=x.slice(6);if($==="[DONE]")continue;try{const y=JSON.parse($).text||"";y&&(u(O,e(O)+y),e(l)[e(l).length-1].content=e(O))}catch(p){console.error("Parse error:",p)}}}}else{const n=await s.json();e(l)[e(l).length-1].content=n.text||n.content||""}}catch(s){throw e(l)[e(l).length-1].content="Error generating response",s}finally{u(O,"")}}function Be(){confirm("Clear all messages?")&&(u(l,[],!0),u(O,""))}function Fe(o){return o.toLocaleTimeString("en-US",{hour:"2-digit",minute:"2-digit"})}at(()=>{de();const o=setInterval(de,1e4);return()=>clearInterval(o)});var ve=Ct();rt(o=>{ot.title="Inference - Model Garden"});var ce=t(ve),be=t(ce),$e=t(be),pe=t($e),we=t(pe);Q(we,{href:"/",variant:"ghost",size:"sm",children:(o,g)=>{C();var s=F("â† Dashboard");i(o,s)},$$slots:{default:!0}});var Je=r(we,4);{var qe=o=>{ge(o,{variant:"success",children:(g,s)=>{C();var n=F("Model Loaded");i(g,n)},$$slots:{default:!0}})},He=o=>{var g=oe(),s=U(g);{var n=d=>{ge(d,{variant:"warning",children:(c,_)=>{C();var v=F("No Model");i(c,v)},$$slots:{default:!0}})};N(s,d=>{e(V)||d(n)},!0)}i(o,g)};N(Je,o=>{e(b)?.loaded?o(qe):o(He,!1)})}a(pe);var ke=r(pe,2),Pe=t(ke);Q(Pe,{onclick:()=>u(le,!e(le)),variant:"secondary",children:(o,g)=>{C();var s=F("âš™ï¸ Settings");i(o,s)},$$slots:{default:!0}});var Ke=r(Pe,2);Q(Ke,{onclick:Be,variant:"secondary",children:(o,g)=>{C();var s=F("ðŸ—‘ï¸ Clear");i(o,s)},$$slots:{default:!0}}),a(ke),a($e),a(be),a(ce);var Se=r(ce,2),Te=t(Se),me=t(Te),Re=t(me);ee(Re,{class:"h-[calc(100vh-16rem)] flex flex-col",children:(o,g)=>{var s=_t(),n=U(s),d=t(n);{var c=p=>{var y=mt();i(p,y)},_=p=>{var y=oe(),w=U(y);lt(w,17,()=>e(l),dt,(I,S,T)=>{var k=ft(),M=t(k),L=t(M),W=t(L),j=t(W),H=t(j);a(j);var R=r(j,2),P=t(R,!0),ue=r(P);{var se=A=>{var ae=ut();i(A,ae)};N(ue,A=>{e(z)&&T===e(l).length-1&&e(S).role==="assistant"&&A(se)})}a(R),a(W),a(L),a(M),a(k),q(A=>{xe(k,1,`flex ${e(S).role==="user"?"justify-end":"justify-start"}`),xe(M,1,`max-w-[80%] rounded-lg px-4 py-3 ${e(S).role==="user"?"bg-primary-600 text-white":"bg-gray-100 text-gray-900"}`),E(H,`${e(S).role==="user"?"You":"Assistant"} Â· ${A??""}`),E(P,e(S).content)},[()=>Fe(e(S).timestamp)]),i(I,k)}),i(p,y)};N(d,p=>{e(l).length===0?p(c):p(_,!1)})}a(n);var v=r(n,2),m=t(v),x=t(m);Ne(x),x.__keydown=[pt,he];var $=r(x,2);{let p=it(()=>!e(K).trim()||e(z)||!e(b)?.loaded||e(V));Q($,{onclick:he,variant:"primary",get disabled(){return e(p)},get loading(){return e(z)},class:"self-end",children:(y,w)=>{C();var I=F();q(()=>E(I,e(z)?"Generating...":"Send")),i(y,I)},$$slots:{default:!0}})}a(m),a(v),q(()=>{nt(x,"placeholder",e(z)?"Generating...":e(b)?.loaded?"Type your message... (Enter to send, Shift+Enter for new line)":"Load a model first..."),x.disabled=e(z)||!e(b)?.loaded||e(V)}),Z(x,()=>e(K),p=>u(K,p)),i(o,s)},$$slots:{default:!0}}),a(me);var Me=r(me,2),Ce=t(Me);ee(Ce,{children:(o,g)=>{var s=wt(),n=r(t(s),2);{var d=_=>{var v=xt();i(_,v)},c=_=>{var v=oe(),m=U(v);{var x=p=>{var y=gt(),w=U(y),I=t(w,!0);a(w);var S=r(w,2);Q(S,{onclick:de,variant:"secondary",size:"sm",fullWidth:!0,children:(T,k)=>{C();var M=F("Retry");i(T,M)},$$slots:{default:!0}}),q(()=>E(I,e(re))),i(p,y)},$=p=>{var y=oe(),w=U(y);{var I=T=>{var k=yt(),M=r(t(k),2);Q(M,{href:"/models/load",variant:"primary",size:"sm",fullWidth:!0,children:(L,W)=>{C();var j=F("ðŸ”Œ Load Model");i(L,j)},$$slots:{default:!0}}),a(k),i(T,k)},S=T=>{var k=$t(),M=t(k),L=t(M);ge(L,{variant:"success",children:(D,G)=>{C();var J=F("Loaded");i(D,J)},$$slots:{default:!0}}),a(M);var W=r(M,2),j=t(W),H=r(t(j),2),R=t(H,!0);a(H);var P=r(H,2),ue=t(P,!0);a(P),a(j);var se=r(j,2);{var A=D=>{var G=ht(),J=r(t(G),2),_e=t(J);a(J),a(G),q(()=>E(_e,`${e(b).model_info.max_model_len??""} tokens`)),i(D,G)};N(se,D=>{e(b).model_info.max_model_len&&D(A)})}var ae=r(se,2),je=r(t(ae),2),Ye=t(je);a(je),a(ae);var fe=r(ae,2),ze=r(t(fe),2),Qe=t(ze,!0);a(ze),a(fe);var Ve=r(fe,2);{var Xe=D=>{var G=bt(),J=r(t(G),2),_e=t(J,!0);a(J),a(G),q(()=>E(_e,e(b).model_info.quantization)),i(D,G)};N(Ve,D=>{e(b).model_info.quantization&&D(Xe)})}a(W);var Ie=r(W,2),Ze=t(Ie);Q(Ze,{href:"/models/load",variant:"secondary",size:"sm",fullWidth:!0,children:(D,G)=>{C();var J=F("Switch Model");i(D,J)},$$slots:{default:!0}}),a(Ie),a(k),q((D,G)=>{E(R,D),E(ue,e(b).model_info.model_path),E(Ye,`${G??""}%`),E(Qe,e(b).model_info.dtype)},[()=>e(b).model_info.model_path.split("/").pop(),()=>(e(b).model_info.gpu_memory_utilization*100).toFixed(0)]),i(T,k)};N(w,T=>{e(b)?.loaded?T(S,!1):T(I)},!0)}i(p,y)};N(m,p=>{e(re)?p(x):p($,!1)},!0)}i(_,v)};N(n,_=>{e(V)?_(d):_(c,!1)})}a(s),i(o,s)},$$slots:{default:!0}});var Ee=r(Ce,2);ee(Ee,{children:(o,g)=>{var s=kt(),n=r(t(s),2),d=t(n),c=t(d);Y(c),c.value=c.__value="chat",C(2),a(d);var _=r(d,2),v=t(_);Y(v),v.value=v.__value="completion",C(2),a(_),a(n),a(s),Oe(ye,[],c,()=>e(X),m=>u(X,m)),Oe(ye,[],v,()=>e(X),m=>u(X,m)),i(o,s)},$$slots:{default:!0}});var De=r(Ee,2);{var Ae=o=>{var g=Tt(),s=U(g);ee(s,{children:(c,_)=>{var v=Pt(),m=r(t(v),2),x=t(m),$=t(x),p=t($);a($);var y=r($,2);Y(y),C(2),a(x);var w=r(x,2),I=r(t(w),2);Y(I),a(w);var S=r(w,2),T=t(S),k=t(T);a(T);var M=r(T,2);Y(M),a(S);var L=r(S,2),W=r(t(L),2);Y(W),a(L);var j=r(L,2),H=t(j),R=t(H);Y(R),C(2),a(H),a(j),a(m),a(v),q(()=>{E(p,`Temperature: ${f.temperature??""}`),E(k,`Top P: ${f.top_p??""}`)}),Z(y,()=>f.temperature,P=>f.temperature=P),Z(I,()=>f.max_tokens,P=>f.max_tokens=P),Z(M,()=>f.top_p,P=>f.top_p=P),Z(W,()=>f.top_k,P=>f.top_k=P),vt(R,()=>f.stream,P=>f.stream=P),i(c,v)},$$slots:{default:!0}});var n=r(s,2);{var d=c=>{ee(c,{children:(_,v)=>{var m=St(),x=r(t(m),2);Ne(x),a(m),Z(x,()=>e(ne),$=>u(ne,$)),i(_,m)},$$slots:{default:!0}})};N(n,c=>{e(X)==="chat"&&c(d)})}i(o,g)};N(De,o=>{e(le)&&o(Ae)})}var Ue=r(De,2);ee(Ue,{children:(o,g)=>{var s=Mt(),n=r(t(s),2),d=t(n),c=r(t(d),2),_=t(c,!0);a(c),a(d);var v=r(d,2),m=r(t(v),2),x=t(m,!0);a(m),a(v),a(n),a(s),q(()=>{E(_,e(l).length),xe(m,1,`font-medium ${e(z)?"text-green-600":"text-gray-900"}`),E(x,e(z)?"ðŸŸ¢ Generating":"âšª Idle")}),i(o,s)},$$slots:{default:!0}}),a(Me),a(Te),a(Se),a(ve),i(te,ve),st()}et(["keydown"]);export{Lt as component};
