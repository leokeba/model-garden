import"../chunks/DsnmJJEf.js";import{q as zr,p as Tr,a as jr,E as Nr,f as y,h as Pr,b as d,c as Or,$ as Fr,t as R,e as t,g as a,d as O,s as le,l as J,i as x,w as qr,n as s,r as o,m as K,j as de,k as Y}from"../chunks/D_fozEd9.js";import{i as f}from"../chunks/C2ngLJft.js";import{r as n,s as ne,a as Da,e as Ga,i as Wa,b as Br}from"../chunks/489nzvkF.js";import{b as u,c as ae}from"../chunks/aZwOC-1j.js";import{b as j}from"../chunks/DV7skBy0.js";import{g as Qr}from"../chunks/CG0zG8ig.js";import{a as Ur}from"../chunks/DpHo5pdb.js";import{B as Ze,C as Vr}from"../chunks/DWJusdRQ.js";function Hr(N,b){b.name&&!b.output_dir&&(b.output_dir=`./models/${b.name.toLowerCase().replace(/[^a-z0-9]/g,"-")}`)}var $r=y('<div class="p-4 bg-red-50 border border-red-200 rounded-lg"><p class="text-red-700"> </p></div>'),Dr=(N,b)=>b.model_type="text",Gr=y('<div class="w-full h-full rounded-full bg-white scale-50"></div>'),Wr=(N,b)=>b.model_type="vision",Ir=y('<div class="w-full h-full rounded-full bg-white scale-50"></div>'),Jr=y("<option> </option>"),Kr=y("<option> </option>"),Yr=y('<p class="text-xs text-gray-500 mt-1">üé® Vision-language models can analyze images and text together</p>'),Xr=y(`Enter a HuggingFace dataset identifier (e.g.,
                  "username/dataset-name")<br/> For specific files, use: "username/repo::train.jsonl"`,1),Zr=y(`<p class="text-sm text-blue-800 mb-2">HuggingFace datasets should use OpenAI messages format with
                    base64 images:</p> <pre class="text-xs bg-blue-100 p-2 rounded overflow-x-auto"><code></code></pre> <p class="text-xs text-blue-700 mt-2"><strong>Example:</strong> <code>Barth371/train_pop_valet_no_wrong_doc</code></p>`,1),et=y(`<p class="text-sm text-blue-800 mb-2">Your dataset should be in JSONL format with:</p> <pre class="text-xs bg-blue-100 p-2 rounded overflow-x-auto"><code></code></pre> <p class="text-xs text-blue-700 mt-2"><strong>Tip:</strong> Use <code>model-garden create-vision-dataset</code> CLI to generate
                    sample data</p>`,1),at=y('<div class="p-4 bg-blue-50 border border-blue-200 rounded-lg"><h4 class="text-sm font-semibold text-blue-900 mb-2">üìã Vision Dataset Format</h4> <!></div>'),rt=y(`<div class="mb-4 p-3 bg-yellow-50 border border-yellow-200 rounded-lg"><p class="text-sm text-yellow-800">‚ö†Ô∏è <strong>Vision models require:</strong> Lower batch size (1-2),
                higher gradient accumulation (8+), and lower learning rate (2e-5)</p></div>`),tt=y('<div class="mb-6"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üìä Evaluation Settings</h4> <div class="grid grid-cols-2 gap-4"><div><label for="eval_strategy" class="block text-sm font-medium text-gray-700 mb-1">Evaluation Strategy</label> <select id="eval_strategy" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Every N steps</option><option>Every epoch</option><option>No evaluation</option></select></div> <div><label for="eval_steps" class="block text-sm font-medium text-gray-700 mb-1">Evaluation Steps</label> <input type="number" id="eval_steps" placeholder="Auto (same as save_steps)" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Evaluate every N steps (leave empty for auto)</p></div> <div><label for="metric_for_best_model" class="block text-sm font-medium text-gray-700 mb-1">Best Model Metric</label> <select id="metric_for_best_model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Validation Loss (lower is better)</option><option>Accuracy (higher is better)</option><option>F1 Score (higher is better)</option></select></div> <div><div class="flex items-center mt-6"><input type="checkbox" id="load_best_model_at_end" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="load_best_model_at_end" class="ml-2 block text-sm text-gray-700">Load best model at end</label></div> <p class="text-xs text-gray-500 mt-1">Automatically load checkpoint with best validation metric</p></div></div></div>'),ot=(N,b)=>O(b,!x(b)),it=y('<div class="mb-6 p-4 bg-gray-50 border border-gray-200 rounded-lg"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">‚öôÔ∏è Optimizer Settings</h4> <div class="grid grid-cols-2 gap-4 mb-6"><div><label for="weight_decay" class="block text-sm font-medium text-gray-700 mb-1">Weight Decay</label> <input type="number" id="weight_decay" step="0.001" min="0" max="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">L2 regularization strength (0.01 typical)</p></div> <div><label for="lr_scheduler_type" class="block text-sm font-medium text-gray-700 mb-1">LR Scheduler</label> <select id="lr_scheduler_type" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Linear (default)</option><option>Cosine (good for vision)</option><option>Constant</option><option>Constant with Warmup</option><option>Polynomial</option></select> <p class="text-xs text-gray-500 mt-1">Learning rate schedule type</p></div> <div><label for="warmup_steps" class="block text-sm font-medium text-gray-700 mb-1">Warmup Steps</label> <input type="number" id="warmup_steps" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Steps to warmup learning rate from 0</p></div> <div><label for="max_grad_norm" class="block text-sm font-medium text-gray-700 mb-1">Max Gradient Norm</label> <input type="number" id="max_grad_norm" step="0.1" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Gradient clipping threshold (1.0 standard)</p></div></div> <h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üéõÔ∏è Adam Optimizer Parameters</h4> <div class="grid grid-cols-3 gap-4 mb-6"><div><label for="adam_beta1" class="block text-sm font-medium text-gray-700 mb-1">Adam Beta1</label> <input type="number" id="adam_beta1" step="0.01" min="0" max="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Exponential decay rate for 1st moment (0.9 default)</p></div> <div><label for="adam_beta2" class="block text-sm font-medium text-gray-700 mb-1">Adam Beta2</label> <input type="number" id="adam_beta2" step="0.001" min="0" max="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Exponential decay rate for 2nd moment (0.999 default)</p></div> <div><label for="adam_epsilon" class="block text-sm font-medium text-gray-700 mb-1">Adam Epsilon</label> <input type="number" id="adam_epsilon" step="1e-9" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Small constant for numerical stability (1e-8 default)</p></div></div> <h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üîÑ Data Loading Settings</h4> <div class="grid grid-cols-2 gap-4"><div><label for="dataloader_num_workers" class="block text-sm font-medium text-gray-700 mb-1">Dataloader Workers</label> <input type="number" id="dataloader_num_workers" min="0" max="16" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Number of worker processes (0 = main process only)</p></div> <div><div class="flex items-center mt-6"><input type="checkbox" id="dataloader_pin_memory" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="dataloader_pin_memory" class="ml-2 block text-sm text-gray-700">Pin memory to GPU</label></div> <p class="text-xs text-gray-500 mt-1">Faster data transfer to GPU (recommended)</p></div></div></div>'),st=(N,b)=>O(b,!x(b)),lt=(N,b)=>{const e=N.currentTarget.value.trim();e?b.lora_config.target_modules=e.split(",").map(C=>C.trim()).filter(C=>C.length>0):b.lora_config.target_modules=null},dt=y(`<div class="p-4 bg-gray-50 border border-gray-200 rounded-lg"><div class="grid grid-cols-2 gap-4 mb-4"><div><label for="lora_bias" class="block text-sm font-medium text-gray-700 mb-1">LoRA Bias</label> <select id="lora_bias" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>None (default)</option><option>All bias terms</option><option>LoRA layers only</option></select> <p class="text-xs text-gray-500 mt-1">How to handle bias parameters in LoRA layers</p></div> <div><label for="use_gradient_checkpointing" class="block text-sm font-medium text-gray-700 mb-1">Gradient Checkpointing</label> <select id="use_gradient_checkpointing" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Unsloth (recommended)</option><option>Standard PyTorch</option><option>Disabled</option></select> <p class="text-xs text-gray-500 mt-1">Reduces memory at cost of compute time</p></div></div> <div class="grid grid-cols-2 gap-4 mb-4"><div><div class="flex items-center mt-2"><input type="checkbox" id="use_rslora" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="use_rslora" class="ml-2 block text-sm text-gray-700">Use RSLoRA (Rank-Stabilized LoRA)</label></div> <p class="text-xs text-gray-500 mt-1">Better stability for high ranks (r > 16)</p></div> <div><label for="random_state" class="block text-sm font-medium text-gray-700 mb-1">Random Seed</label> <input type="number" id="random_state" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Seed for reproducible results (42 is popular)</p></div></div> <div class="grid grid-cols-2 gap-4 mb-4"><div><label for="task_type" class="block text-sm font-medium text-gray-700 mb-1">Task Type</label> <select id="task_type" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Causal LM (Text Generation)</option><option>Sequence-to-Sequence</option><option>Token Classification</option><option>Sequence Classification</option><option>Question Answering</option></select> <p class="text-xs text-gray-500 mt-1">Type of task for PEFT optimization</p></div> <div><label for="target_modules_input" class="block text-sm font-medium text-gray-700 mb-1">Target Modules (Advanced)</label> <input type="text" id="target_modules_input" placeholder="q_proj, k_proj, v_proj (leave empty for auto)" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Comma-separated list of layers to apply LoRA (auto-detected
                    if empty)</p></div></div> <div class="p-3 bg-blue-50 border border-blue-200 rounded-lg"><h4 class="text-sm font-semibold text-blue-900 mb-2">üí° LoRA Tips</h4> <ul class="text-xs text-blue-800 space-y-1"><li><strong>Rank (r):</strong> Start with 16, increase to 64+ for
                    complex tasks or large datasets</li> <li><strong>Alpha:</strong> Usually equal to rank. Higher alpha =
                    stronger adaptation</li> <li><strong>Dropout:</strong> Add 0.1-0.3 if overfitting, keep 0
                    for small datasets</li> <li><strong>RSLoRA:</strong> Enable for ranks > 16 to improve training
                    stability</li> <li><strong>Target Modules:</strong> Leave empty for auto-detection.
                    Common: "q_proj,k_proj,v_proj,o_proj" for attention layers</li> <li><strong>Task Type:</strong> Use "CAUSAL_LM" for text generation,
                    "SEQ_2_SEQ_LM" for translation/summarization</li></ul></div></div>`),nt=y(`<strong>‚úÖ Merged 16-bit (Recommended):</strong> Full model with
                  LoRA weights merged using Unsloth. Creates split files for vLLM
                  compatibility.`,1),pt=y(`<strong>üì¶ Merged 4-bit:</strong> Full model with LoRA weights
                  merged in 4-bit quantized format. Smaller file size.`,1),mt=y(`<strong>üîß LoRA Adapters Only (Advanced):</strong> Saves only the
                  adapter weights. Requires the base model to load.`,1),vt=y(`<form class="space-y-6"><!> <div><h3 class="text-lg font-semibold text-gray-900 mb-4">Basic Configuration</h3> <div class="grid grid-cols-1 gap-4"><div><div class="block text-sm font-medium text-gray-700 mb-2">Model Type *</div> <div class="grid grid-cols-2 gap-3"><button type="button"><div class="flex items-center gap-2"><div><!></div> <span class="font-medium">Text-Only (LLM)</span></div> <p class="text-sm text-gray-600 mt-2 ml-6">Fine-tune language models for text generation tasks</p></button> <button type="button"><div class="flex items-center gap-2"><div><!></div> <span class="font-medium">Vision-Language (VLM)</span></div> <p class="text-sm text-gray-600 mt-2 ml-6">Fine-tune multimodal models for image + text tasks</p></button></div></div> <div><label for="name" class="block text-sm font-medium text-gray-700 mb-1">Model Name *</label> <input type="text" id="name" placeholder="my-finance-model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500" required/></div> <div><label for="base_model" class="block text-sm font-medium text-gray-700 mb-1">Base Model *</label> <select id="base_model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500" required><!></select> <!></div> <div><label for="dataset_path" class="block text-sm font-medium text-gray-700 mb-1">Dataset Path *</label> <input type="text" id="dataset_path" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500" required/> <div class="mt-2 flex items-center"><input type="checkbox" id="from_hub" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="from_hub" class="ml-2 block text-sm text-gray-700">Load from HuggingFace Hub</label></div> <p class="text-xs text-gray-500 mt-1"><!></p></div> <div><label for="validation_dataset_path" class="block text-sm font-medium text-gray-700 mb-1">Validation Dataset Path (Optional)</label> <input type="text" id="validation_dataset_path" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <div class="mt-2 flex items-center"><input type="checkbox" id="validation_from_hub" class="h-4 w-4 text-primary-600 focus:ring-primary-500 border-gray-300 rounded"/> <label for="validation_from_hub" class="ml-2 block text-sm text-gray-700">Load validation dataset from HuggingFace Hub</label></div> <p class="text-xs text-gray-500 mt-1">üìä Optional: Provide a validation dataset to track validation
                loss during training<br/> <!></p></div> <!> <div><label for="output_dir" class="block text-sm font-medium text-gray-700 mb-1">Output Directory</label> <input type="text" id="output_dir" placeholder="./models/my-model" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/></div></div></div> <div><h3 class="text-lg font-semibold text-gray-900 mb-4">Training Hyperparameters</h3> <!> <div class="mb-6"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üéØ Essential Parameters</h4> <div class="grid grid-cols-2 gap-4"><div><label for="learning_rate" class="block text-sm font-medium text-gray-700 mb-1">Learning Rate</label> <input type="number" id="learning_rate" step="0.00001" min="0" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1"><!></p></div> <div><label for="num_epochs" class="block text-sm font-medium text-gray-700 mb-1">Number of Epochs</label> <input type="number" id="num_epochs" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Number of complete passes through dataset</p></div> <div><label for="batch_size" class="block text-sm font-medium text-gray-700 mb-1">Batch Size per GPU</label> <input type="number" id="batch_size" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1"><!></p></div> <div><label for="gradient_accumulation" class="block text-sm font-medium text-gray-700 mb-1">Gradient Accumulation Steps</label> <input type="number" id="gradient_accumulation" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Effective batch size = batch_size √ó
                  gradient_accumulation_steps</p></div> <div><label for="max_steps" class="block text-sm font-medium text-gray-700 mb-1">Max Steps (Optional)</label> <input type="number" id="max_steps" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Override epochs with exact step count (-1 for full epochs)</p></div> <div><label for="optim" class="block text-sm font-medium text-gray-700 mb-1">Optimizer</label> <select id="optim" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>AdamW 8-bit (Recommended - Memory Efficient)</option><option>AdamW (PyTorch)</option><option>AdamW Fused (Faster)</option><option>Adafactor (Very Memory Efficient)</option><option>SGD</option></select> <p class="text-xs text-gray-500 mt-1">8-bit AdamW reduces memory usage significantly</p></div></div></div> <div class="mb-6"><h4 class="text-md font-medium text-gray-800 mb-3 flex items-center gap-2">üíæ Checkpoints & Logging</h4> <div class="grid grid-cols-3 gap-4"><div><label for="logging_steps" class="block text-sm font-medium text-gray-700 mb-1">Logging Steps</label> <input type="number" id="logging_steps" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Log metrics every N steps</p></div> <div><label for="save_steps" class="block text-sm font-medium text-gray-700 mb-1">Save Steps</label> <input type="number" id="save_steps" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Save checkpoint every N steps</p></div> <div><label for="save_total_limit" class="block text-sm font-medium text-gray-700 mb-1">Max Checkpoints</label> <input type="number" id="save_total_limit" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Keep only N most recent checkpoints</p></div></div></div> <!> <div class="mb-4"><button type="button" class="flex items-center gap-2 px-4 py-2 text-sm font-medium text-primary-700 bg-primary-50 border border-primary-200 rounded-lg hover:bg-primary-100 transition-colors"><span> </span> Advanced Hyperparameters</button></div> <!></div> <div><h3 class="text-lg font-semibold text-gray-900 mb-4">LoRA Configuration</h3> <div class="grid grid-cols-3 gap-4 mb-4"><div><label for="lora_r" class="block text-sm font-medium text-gray-700 mb-1">LoRA Rank (r)</label> <input type="number" id="lora_r" min="1" max="256" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Higher = more parameters (16 typical, 64+ for complex tasks)</p></div> <div><label for="lora_alpha" class="block text-sm font-medium text-gray-700 mb-1">LoRA Alpha</label> <input type="number" id="lora_alpha" min="1" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Scaling factor (typically equal to rank)</p></div> <div><label for="lora_dropout" class="block text-sm font-medium text-gray-700 mb-1">LoRA Dropout</label> <input type="number" id="lora_dropout" min="0" max="0.5" step="0.05" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"/> <p class="text-xs text-gray-500 mt-1">Regularization (0.0-0.3, 0 = no dropout)</p></div></div> <div class="mb-4"><button type="button" class="flex items-center gap-2 px-4 py-2 text-sm font-medium text-primary-700 bg-primary-50 border border-primary-200 rounded-lg hover:bg-primary-100 transition-colors"><span> </span> Advanced LoRA Settings</button></div> <!></div> <div><h3 class="text-lg font-semibold text-gray-900 mb-4">Model Save Options</h3> <div><label for="save_method" class="block text-sm font-medium text-gray-700 mb-2">Save Method</label> <select id="save_method" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500"><option>Save Merged Model (16-bit) - Recommended</option><option>Save Merged Model (4-bit) - Smaller Size</option><option>Save LoRA Adapters Only - Advanced</option></select> <div class="mt-3 p-3 bg-blue-50 border border-blue-200 rounded-lg"><p class="text-sm text-blue-800"><!></p></div></div></div> <div class="flex gap-4 pt-4"><!> <!></div></form>`),_t=y('<div class="min-h-screen bg-gray-50"><div class="bg-white shadow"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex justify-between items-center py-6"><div class="flex items-center"><!> <h1 class="text-3xl font-bold text-gray-900 ml-4">New Training Job</h1></div></div></div></div> <div class="max-w-3xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><!></div></div>');function kt(N,b){Tr(b,!0);let e=jr({name:"",model_type:"text",base_model:"unsloth/tinyllama-bnb-4bit",dataset_path:"./data/sample.jsonl",validation_dataset_path:"",output_dir:"",hyperparameters:{learning_rate:2e-4,num_epochs:3,batch_size:2,max_steps:-1,gradient_accumulation_steps:4,warmup_steps:10,logging_steps:10,save_steps:100,eval_steps:null,optim:"adamw_8bit",weight_decay:.01,lr_scheduler_type:"linear",max_grad_norm:1,adam_beta1:.9,adam_beta2:.999,adam_epsilon:1e-8,dataloader_num_workers:0,dataloader_pin_memory:!0,eval_strategy:"steps",load_best_model_at_end:!0,metric_for_best_model:"eval_loss",save_total_limit:3},lora_config:{r:16,lora_alpha:16,lora_dropout:0,lora_bias:"none",use_rslora:!1,use_gradient_checkpointing:"unsloth",random_state:42,target_modules:null,task_type:"CAUSAL_LM",loftq_config:null},from_hub:!1,validation_from_hub:!1,save_method:"merged_16bit"}),C=le(!1),B=le("");const ea=["unsloth/tinyllama-bnb-4bit","unsloth/phi-2-bnb-4bit","unsloth/mistral-7b-bnb-4bit","unsloth/llama-2-7b-bnb-4bit","unsloth/llama-3-8b-bnb-4bit"],aa=["Qwen/Qwen2.5-VL-3B-Instruct","Qwen/Qwen2.5-VL-7B-Instruct","Qwen/Qwen2.5-VL-72B-Instruct","unsloth/Qwen2.5-VL-3B-Instruct-bnb-4bit","unsloth/Qwen2.5-VL-7B-Instruct-bnb-4bit"];Nr(()=>{e.model_type==="vision"?(e.base_model=aa[0],e.dataset_path="./data/vision_dataset.jsonl",e.hyperparameters.batch_size=1,e.hyperparameters.gradient_accumulation_steps=8,e.hyperparameters.learning_rate=2e-5,e.hyperparameters.lr_scheduler_type="cosine"):(e.base_model=ea[0],e.dataset_path="./data/sample.jsonl",e.hyperparameters.batch_size=2,e.hyperparameters.gradient_accumulation_steps=4,e.hyperparameters.learning_rate=2e-4,e.hyperparameters.lr_scheduler_type="linear")});let pe=le(!1),me=le(!1);async function Ia(Q){if(Q.preventDefault(),!e.name||!e.base_model||!e.dataset_path){O(B,"Please fill in all required fields");return}O(C,!0),O(B,"");try{const F=await Ur.createTrainingJob({...e,is_vision:e.model_type==="vision"});F.success?Qr(`/training/${F.data.job_id}`):O(B,"Failed to create training job")}catch(F){O(B,F instanceof Error?F.message:"Failed to create training job",!0)}finally{O(C,!1)}}var ve=_t();Pr(Q=>{Fr.title="New Training Job - Model Garden"});var _e=t(ve),ra=t(_e),ta=t(ra),oa=t(ta),Ja=t(oa);Ze(Ja,{href:"/training",variant:"ghost",size:"sm",children:(Q,F)=>{s();var U=R("‚Üê Training Jobs");d(Q,U)},$$slots:{default:!0}}),s(2),o(oa),o(ta),o(ra),o(_e);var ia=a(_e,2),Ka=t(ia);Vr(Ka,{children:(Q,F)=>{var U=vt(),sa=t(U);{var Ya=r=>{var i=$r(),v=t(i),c=t(v,!0);o(v),o(i),J(()=>K(c,x(B))),d(r,i)};f(sa,r=>{x(B)&&r(Ya)})}var ue=a(sa,2),la=a(t(ue),2),ce=t(la),da=a(t(ce),2),X=t(da);X.__click=[Dr,e];var na=t(X),ge=t(na),Xa=t(ge);{var Za=r=>{var i=Gr();d(r,i)};f(Xa,r=>{e.model_type==="text"&&r(Za)})}o(ge),s(2),o(na),s(2),o(X);var re=a(X,2);re.__click=[Wr,e];var pa=t(re),be=t(pa),er=t(be);{var ar=r=>{var i=Ir();d(r,i)};f(er,r=>{e.model_type==="vision"&&r(ar)})}o(be),s(2),o(pa),s(2),o(re),o(da),o(ce);var ye=a(ce,2),fe=a(t(ye),2);n(fe),fe.__input=[Hr,e],o(ye);var xe=a(ye,2),te=a(t(xe),2),rr=t(te);{var tr=r=>{var i=de(),v=Y(i);Ga(v,17,()=>ea,Wa,(c,_)=>{var l=Jr(),p=t(l,!0);o(l);var g={};J(()=>{K(p,x(_)),g!==(g=x(_))&&(l.value=(l.__value=x(_))??"")}),d(c,l)}),d(r,i)},or=r=>{var i=de(),v=Y(i);Ga(v,17,()=>aa,Wa,(c,_)=>{var l=Kr(),p=t(l,!0);o(l);var g={};J(()=>{K(p,x(_)),g!==(g=x(_))&&(l.value=(l.__value=x(_))??"")}),d(c,l)}),d(r,i)};f(rr,r=>{e.model_type==="text"?r(tr):r(or,!1)})}o(te);var ir=a(te,2);{var sr=r=>{var i=Yr();d(r,i)};f(ir,r=>{e.model_type==="vision"&&r(sr)})}o(xe);var he=a(xe,2),oe=a(t(he),2);n(oe);var we=a(oe,2),ma=t(we);n(ma),s(2),o(we);var va=a(we,2),lr=t(va);{var dr=r=>{var i=Xr();s(2),d(r,i)},nr=r=>{var i=de(),v=Y(i);{var c=l=>{var p=R(`Path to your JSONL dataset with image paths/base64 or local
                  file`);d(l,p)},_=l=>{var p=R("Path to your JSONL dataset file");d(l,p)};f(v,l=>{e.model_type==="vision"?l(c):l(_,!1)},!0)}d(r,i)};f(lr,r=>{e.from_hub?r(dr):r(nr,!1)})}o(va),o(he);var ke=a(he,2),ie=a(t(ke),2);n(ie);var Le=a(ie,2),_a=t(Le);n(_a),s(2),o(Le);var ua=a(Le,2),pr=a(t(ua),3);{var mr=r=>{var i=R(`Use HuggingFace format: "username/repo" or
                  "username/repo::validation.jsonl"`);d(r,i)};f(pr,r=>{e.validation_from_hub&&r(mr)})}o(ua),o(ke);var ca=a(ke,2);{var vr=r=>{var i=at(),v=a(t(i),2);{var c=l=>{var p=Zr(),g=a(Y(p),2),h=t(g);h.textContent='{"messages": [{"role": "user", "content": [{"type": "image", "image": "data:image/jpeg;base64,..."}, {"type": "text", "text": "What is shown?"}]}]}',o(g),s(2),d(l,p)},_=l=>{var p=et(),g=a(Y(p),2),h=t(g);h.textContent='{"text": "What is in this image?", "image": "/path/to/image.jpg", "response": "A cat sitting on a table"}',o(g),s(2),d(l,p)};f(v,l=>{e.from_hub?l(c):l(_,!1)})}o(i),d(r,i)};f(ca,r=>{e.model_type==="vision"&&r(vr)})}var ga=a(ca,2),ba=a(t(ga),2);n(ba),o(ga),o(la),o(ue);var Se=a(ue,2),ya=a(t(Se),2);{var _r=r=>{var i=rt();d(r,i)};f(ya,r=>{e.model_type==="vision"&&r(_r)})}var Ae=a(ya,2),fa=a(t(Ae),2),Me=t(fa),Re=a(t(Me),2);n(Re);var xa=a(Re,2),ur=t(xa);{var cr=r=>{var i=R(`2e-5 recommended for
                    vision models`);d(r,i)},gr=r=>{var i=R("2e-4 typical for text models");d(r,i)};f(ur,r=>{e.model_type==="vision"?r(cr):r(gr,!1)})}o(xa),o(Me);var Ce=a(Me,2),ha=a(t(Ce),2);n(ha),s(2),o(Ce);var Ee=a(Ce,2),ze=a(t(Ee),2);n(ze);var wa=a(ze,2),br=t(wa);{var yr=r=>{var i=R("Use 1 for vision models");d(r,i)},fr=r=>{var i=R(`2-4
                    typical for text models`);d(r,i)};f(br,r=>{e.model_type==="vision"?r(yr):r(fr,!1)})}o(wa),o(Ee);var Te=a(Ee,2),ka=a(t(Te),2);n(ka),s(2),o(Te);var je=a(Te,2),La=a(t(je),2);n(La),s(2),o(je);var Sa=a(je,2),Ne=a(t(Sa),2),Pe=t(Ne);Pe.value=Pe.__value="adamw_8bit";var Oe=a(Pe);Oe.value=Oe.__value="adamw_torch";var Fe=a(Oe);Fe.value=Fe.__value="adamw_torch_fused";var qe=a(Fe);qe.value=qe.__value="adafactor";var Aa=a(qe);Aa.value=Aa.__value="sgd",o(Ne),s(2),o(Sa),o(fa),o(Ae);var Be=a(Ae,2),Ma=a(t(Be),2),Qe=t(Ma),Ra=a(t(Qe),2);n(Ra),s(2),o(Qe);var Ue=a(Qe,2),Ca=a(t(Ue),2);n(Ca),s(2),o(Ue);var Ea=a(Ue,2),za=a(t(Ea),2);n(za),s(2),o(Ea),o(Ma),o(Be);var Ta=a(Be,2);{var xr=r=>{var i=tt(),v=a(t(i),2),c=t(v),_=a(t(c),2),l=t(_);l.value=l.__value="steps";var p=a(l);p.value=p.__value="epoch";var g=a(p);g.value=g.__value="no",o(_),o(c);var h=a(c,2),L=a(t(h),2);n(L),s(2),o(h);var k=a(h,2),S=a(t(k),2),A=t(S);A.value=A.__value="eval_loss";var M=a(A);M.value=M.__value="eval_accuracy";var E=a(M);E.value=E.__value="eval_f1",o(S),o(k);var P=a(k,2),z=t(P),T=t(z);n(T),s(2),o(z),s(2),o(P),o(v),o(i),j(_,()=>e.hyperparameters.eval_strategy,w=>e.hyperparameters.eval_strategy=w),u(L,()=>e.hyperparameters.eval_steps,w=>e.hyperparameters.eval_steps=w),j(S,()=>e.hyperparameters.metric_for_best_model,w=>e.hyperparameters.metric_for_best_model=w),ae(T,()=>e.hyperparameters.load_best_model_at_end,w=>e.hyperparameters.load_best_model_at_end=w),d(r,i)};f(Ta,r=>{e.validation_dataset_path&&r(xr)})}var Ve=a(Ta,2),He=t(Ve);He.__click=[ot,pe];var ja=t(He),hr=t(ja,!0);o(ja),s(),o(He),o(Ve);var wr=a(Ve,2);{var kr=r=>{var i=it(),v=a(t(i),2),c=t(v),_=a(t(c),2);n(_),s(2),o(c);var l=a(c,2),p=a(t(l),2),g=t(p);g.value=g.__value="linear";var h=a(g);h.value=h.__value="cosine";var L=a(h);L.value=L.__value="constant";var k=a(L);k.value=k.__value="constant_with_warmup";var S=a(k);S.value=S.__value="polynomial",o(p),s(2),o(l);var A=a(l,2),M=a(t(A),2);n(M),s(2),o(A);var E=a(A,2),P=a(t(E),2);n(P),s(2),o(E),o(v);var z=a(v,4),T=t(z),w=a(t(T),2);n(w),s(2),o(T);var V=a(T,2),H=a(t(V),2);n(H),s(2),o(V);var $=a(V,2),D=a(t($),2);n(D),s(2),o($),o(z);var G=a(z,4),q=t(G),W=a(t(q),2);n(W),s(2),o(q);var Z=a(q,2),ee=t(Z),I=t(ee);n(I),s(2),o(ee),s(2),o(Z),o(G),o(i),u(_,()=>e.hyperparameters.weight_decay,m=>e.hyperparameters.weight_decay=m),j(p,()=>e.hyperparameters.lr_scheduler_type,m=>e.hyperparameters.lr_scheduler_type=m),u(M,()=>e.hyperparameters.warmup_steps,m=>e.hyperparameters.warmup_steps=m),u(P,()=>e.hyperparameters.max_grad_norm,m=>e.hyperparameters.max_grad_norm=m),u(w,()=>e.hyperparameters.adam_beta1,m=>e.hyperparameters.adam_beta1=m),u(H,()=>e.hyperparameters.adam_beta2,m=>e.hyperparameters.adam_beta2=m),u(D,()=>e.hyperparameters.adam_epsilon,m=>e.hyperparameters.adam_epsilon=m),u(W,()=>e.hyperparameters.dataloader_num_workers,m=>e.hyperparameters.dataloader_num_workers=m),ae(I,()=>e.hyperparameters.dataloader_pin_memory,m=>e.hyperparameters.dataloader_pin_memory=m),d(r,i)};f(wr,r=>{x(pe)&&r(kr)})}o(Se);var $e=a(Se,2),De=a(t($e),2),Ge=t(De),Na=a(t(Ge),2);n(Na),s(2),o(Ge);var We=a(Ge,2),Pa=a(t(We),2);n(Pa),s(2),o(We);var Oa=a(We,2),Fa=a(t(Oa),2);n(Fa),s(2),o(Oa),o(De);var Ie=a(De,2),Je=t(Ie);Je.__click=[st,me];var qa=t(Je),Lr=t(qa,!0);o(qa),s(),o(Je),o(Ie);var Sr=a(Ie,2);{var Ar=r=>{var i=dt(),v=t(i),c=t(v),_=a(t(c),2),l=t(_);l.value=l.__value="none";var p=a(l);p.value=p.__value="all";var g=a(p);g.value=g.__value="lora_only",o(_),s(2),o(c);var h=a(c,2),L=a(t(h),2),k=t(L);k.value=k.__value="unsloth";var S=a(k);S.value=S.__value="true";var A=a(S);A.value=A.__value="false",o(L),s(2),o(h),o(v);var M=a(v,2),E=t(M),P=t(E),z=t(P);n(z),s(2),o(P),s(2),o(E);var T=a(E,2),w=a(t(T),2);n(w),s(2),o(T),o(M);var V=a(M,2),H=t(V),$=a(t(H),2),D=t($);D.value=D.__value="CAUSAL_LM";var G=a(D);G.value=G.__value="SEQ_2_SEQ_LM";var q=a(G);q.value=q.__value="TOKEN_CLS";var W=a(q);W.value=W.__value="SEQ_CLS";var Z=a(W);Z.value=Z.__value="QUESTION_ANS",o($),s(2),o(H);var ee=a(H,2),I=a(t(ee),2);n(I),I.__input=[lt,e],s(2),o(ee),o(V),s(2),o(i),J(m=>Br(I,m),[()=>e.lora_config.target_modules?.join(", ")||""]),j(_,()=>e.lora_config.lora_bias,m=>e.lora_config.lora_bias=m),j(L,()=>e.lora_config.use_gradient_checkpointing,m=>e.lora_config.use_gradient_checkpointing=m),ae(z,()=>e.lora_config.use_rslora,m=>e.lora_config.use_rslora=m),u(w,()=>e.lora_config.random_state,m=>e.lora_config.random_state=m),j($,()=>e.lora_config.task_type,m=>e.lora_config.task_type=m),d(r,i)};f(Sr,r=>{x(me)&&r(Ar)})}o($e);var Ke=a($e,2),Ba=a(t(Ke),2),se=a(t(Ba),2),Ye=t(se);Ye.value=Ye.__value="merged_16bit";var Xe=a(Ye);Xe.value=Xe.__value="merged_4bit";var Qa=a(Xe);Qa.value=Qa.__value="lora",o(se);var Ua=a(se,2),Va=t(Ua),Mr=t(Va);{var Rr=r=>{var i=nt();s(),d(r,i)},Cr=r=>{var i=de(),v=Y(i);{var c=l=>{var p=pt();s(),d(l,p)},_=l=>{var p=mt();s(),d(l,p)};f(v,l=>{e.save_method==="merged_4bit"?l(c):l(_,!1)},!0)}d(r,i)};f(Mr,r=>{e.save_method==="merged_16bit"?r(Rr):r(Cr,!1)})}o(Va),o(Ua),o(Ba),o(Ke);var Ha=a(Ke,2),$a=t(Ha);Ze($a,{type:"submit",variant:"primary",get loading(){return x(C)},get disabled(){return x(C)},children:(r,i)=>{s();var v=R();J(()=>K(v,x(C)?"Creating...":"Start Training")),d(r,v)},$$slots:{default:!0}});var Er=a($a,2);Ze(Er,{href:"/training",variant:"secondary",children:(r,i)=>{s();var v=R("Cancel");d(r,v)},$$slots:{default:!0}}),o(Ha),o(U),J(()=>{ne(X,1,`p-4 border-2 rounded-lg text-left transition-all ${e.model_type==="text"?"border-primary-500 bg-primary-50":"border-gray-300 hover:border-gray-400"}`),ne(ge,1,`w-4 h-4 rounded-full border-2 ${e.model_type==="text"?"border-primary-500 bg-primary-500":"border-gray-400"}`),ne(re,1,`p-4 border-2 rounded-lg text-left transition-all ${e.model_type==="vision"?"border-primary-500 bg-primary-50":"border-gray-300 hover:border-gray-400"}`),ne(be,1,`w-4 h-4 rounded-full border-2 ${e.model_type==="vision"?"border-primary-500 bg-primary-500":"border-gray-400"}`),Da(oe,"placeholder",e.from_hub?"username/dataset-name":e.model_type==="vision"?"./data/vision_dataset.jsonl":"./data/my-dataset.jsonl"),Da(ie,"placeholder",e.validation_from_hub?"username/val-dataset-name":e.model_type==="vision"?"./data/vision_val_dataset.jsonl":"./data/my-val-dataset.jsonl"),K(hr,x(pe)?"‚ñº":"‚ñ∂"),K(Lr,x(me)?"‚ñº":"‚ñ∂")}),qr("submit",U,Ia),u(fe,()=>e.name,r=>e.name=r),j(te,()=>e.base_model,r=>e.base_model=r),u(oe,()=>e.dataset_path,r=>e.dataset_path=r),ae(ma,()=>e.from_hub,r=>e.from_hub=r),u(ie,()=>e.validation_dataset_path,r=>e.validation_dataset_path=r),ae(_a,()=>e.validation_from_hub,r=>e.validation_from_hub=r),u(ba,()=>e.output_dir,r=>e.output_dir=r),u(Re,()=>e.hyperparameters.learning_rate,r=>e.hyperparameters.learning_rate=r),u(ha,()=>e.hyperparameters.num_epochs,r=>e.hyperparameters.num_epochs=r),u(ze,()=>e.hyperparameters.batch_size,r=>e.hyperparameters.batch_size=r),u(ka,()=>e.hyperparameters.gradient_accumulation_steps,r=>e.hyperparameters.gradient_accumulation_steps=r),u(La,()=>e.hyperparameters.max_steps,r=>e.hyperparameters.max_steps=r),j(Ne,()=>e.hyperparameters.optim,r=>e.hyperparameters.optim=r),u(Ra,()=>e.hyperparameters.logging_steps,r=>e.hyperparameters.logging_steps=r),u(Ca,()=>e.hyperparameters.save_steps,r=>e.hyperparameters.save_steps=r),u(za,()=>e.hyperparameters.save_total_limit,r=>e.hyperparameters.save_total_limit=r),u(Na,()=>e.lora_config.r,r=>e.lora_config.r=r),u(Pa,()=>e.lora_config.lora_alpha,r=>e.lora_config.lora_alpha=r),u(Fa,()=>e.lora_config.lora_dropout,r=>e.lora_config.lora_dropout=r),j(se,()=>e.save_method,r=>e.save_method=r),d(Q,U)},$$slots:{default:!0}}),o(ia),o(ve),d(N,ve),Or()}zr(["click","input"]);export{kt as component};
